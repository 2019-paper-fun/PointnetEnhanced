{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pointnet Training and Evaluate",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "g2a8I1_oejD9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup HyperOpt"
      ]
    },
    {
      "metadata": {
        "id": "Lg8G2EdReow9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "a9abf5fe-2831-4545-98bb-523981b42a08"
      },
      "cell_type": "code",
      "source": [
        "!pip install hyperopt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperopt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/9f/f6324af3fc43f352e568b5850695c30ed7dd14af06a94f97953ff9187569/hyperopt-0.1.1-py3-none-any.whl (117kB)\n",
            "\r\u001b[K    8% |██▉                             | 10kB 10.1MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 20kB 3.1MB/s eta 0:00:01\r\u001b[K    26% |████████▍                       | 30kB 4.4MB/s eta 0:00:01\r\u001b[K    34% |███████████▏                    | 40kB 3.3MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 51kB 4.1MB/s eta 0:00:01\r\u001b[K    52% |████████████████▊               | 61kB 4.8MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 71kB 5.4MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▍         | 81kB 6.0MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 92kB 5.2MB/s eta 0:00:01\r\u001b[K    87% |████████████████████████████    | 102kB 5.7MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▊ | 112kB 5.9MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 122kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.2)\n",
            "Collecting pymongo (from hyperopt)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/45/5440555b901a8416196fbf2499c4678ef74de8080c007104107a8cfdda20/pymongo-3.7.2-cp36-cp36m-manylinux1_x86_64.whl (408kB)\n",
            "\u001b[K    100% |████████████████████████████████| 409kB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.14.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.19.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.3.0)\n",
            "Installing collected packages: pymongo, hyperopt\n",
            "Successfully installed hyperopt-0.1.1 pymongo-3.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "u22w3BFiOveA"
      },
      "cell_type": "markdown",
      "source": [
        "## Running pointnet\n",
        "\n",
        "Mount the google drive and point to the folder containing the train.py and run the code from there with a slight modification.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "outputId": "ddfc035e-7dbc-463d-bea3-6667524369f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zNEHrCdY4dsO",
        "colab_type": "code",
        "outputId": "8c88282e-e7b6-4308-a91e-124de6a518b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1361
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet00/')\n",
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/')\n",
        "\n",
        "\n",
        "!python train.py --max_epoch=3 --run_mode='hyperopt' --log_dir=\"log/hyperopt88\" --max_evals=10  --max_trials=5\n",
        "# --batch_size=16 #--log_dir=\"log\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:Starting the run with the mode:hyperopt\n",
            "Namespace(batch_size=32, decay_rate=0.7, decay_step=200000, gpu=0, learning_rate=0.001, log_dir='log/hyperopt88', max_epoch=3, max_evals=10, max_trials=5, model='pointnet_cls', model_path='', momentum=0.9, mongo_mode=0, num_point=1024, optimizer='adam', run_mode='hyperopt')\n",
            "\n",
            "Starting hyperopt\n",
            "HyperOpt batch size selected:16\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
            "2018-11-07 17:18:02.933562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-07 17:18:02.934061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-11-07 17:18:02.934105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-07 17:18:03.350567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-07 17:18:03.350628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-07 17:18:03.350659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-07 17:18:03.350994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.731357\n",
            "accuracy: 0.187988\n",
            "----1-----\n",
            "mean loss: 2.854910\n",
            "accuracy: 0.272461\n",
            "----2-----\n",
            "mean loss: 2.541365\n",
            "accuracy: 0.335449\n",
            "----3-----\n",
            "mean loss: 2.312079\n",
            "accuracy: 0.381068\n",
            "----4-----\n",
            "mean loss: 2.098075\n",
            "accuracy: 0.420410\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.009507\n",
            "eval accuracy: 0.421672\n",
            "eval avg class acc: 0.368369\n",
            "--- Total running time for EPOCH 000 : 0:03:42.671871 ---\n",
            "Model saved in file: log/hyperopt88/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 1.931458\n",
            "accuracy: 0.448242\n",
            "----1-----\n",
            "mean loss: 2.078099\n",
            "accuracy: 0.414442\n",
            "----2-----\n",
            "mean loss: 1.734774\n",
            "accuracy: 0.507812\n",
            "----3-----\n",
            "mean loss: 1.659196\n",
            "accuracy: 0.528320\n",
            "----4-----\n",
            "mean loss: 1.646258\n",
            "accuracy: 0.514648\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.402746\n",
            "eval accuracy: 0.582792\n",
            "eval avg class acc: 0.482412\n",
            "--- Total running time for EPOCH 001 : 0:03:39.507895 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.523534\n",
            "accuracy: 0.549316\n",
            "----1-----\n",
            "mean loss: 1.400046\n",
            "accuracy: 0.583738\n",
            "----2-----\n",
            "mean loss: 1.409135\n",
            "accuracy: 0.577148\n",
            "----3-----\n",
            "mean loss: 1.318336\n",
            "accuracy: 0.618652\n",
            "----4-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "62mvI_VcvltV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "817e8017-82e0-4234-8de1-2062d0c08581"
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/log/hyperopt1/15')\n",
        "!ls\n",
        "trials = Trials()\n",
        "LOG_DIR = \"\"\n",
        "trialFilePath = os.path.join(LOG_DIR, \"trials.p\")\n",
        "if os.path.exists(trialFilePath):\n",
        "    trials = pickle.load(open(trialFilePath, \"rb\"))\n",
        "    print (\"Trials loaded.\")\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "#WRITER = open(\"test.txt\", \"wb\")\n",
        "for trial in trials.results:\n",
        "  print (trial)\n",
        "\n",
        "print (trials.idxs_vals[0])\n",
        "  \n",
        "import pandas as pd\n",
        "# Dataframe of results from optimization\n",
        "tpe_results = pd.DataFrame({'batch size': [x['RunParams']['batch_size'] for x in trials.results],\n",
        "                            'loss': [x['loss'] for x in trials.results],\n",
        "                            'accuracy': [x['accuracy'] for x in trials.results] \n",
        "                            })\n",
        "                            \n",
        "tpe_results.head()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint     model.ckpt.data-00000-of-00001  model.ckpt.meta\ttest   train.py\n",
            "log_train.txt  model.ckpt.index\t\t       pointnet_cls.py\ttrain  trials.p\n",
            "Trials loaded.\n",
            "{'loss': 2.96103711910062, 'status': 'ok', 'accuracy': 0.2824675324675325, 'avg_class_accuracy': 0.21025716466995537, 'eval_time': 1541610828.3504426, 'RunParams': {'optimizer': 'adam', 'batch_size': 8, 'num_point': 1024, 'momentum': 0.9, 'max_epoch': 1}}\n",
            "{'batch_size': [0]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>batch size</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.282468</td>\n",
              "      <td>8</td>\n",
              "      <td>2.961037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  batch size      loss\n",
              "0  0.282468           8  2.961037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "Dix8TX3yJSI2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48026
        },
        "outputId": "5d8c7077-63bf-4287-ae29-6a99ae72cc49"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet00/')\n",
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/')\n",
        "\n",
        "#second run since first run was interrupted at EPOCH 119\n",
        "!python train.py --max_epoch=10 --run_mode='hyperopt' --log_dir=\"log/hyperopttiny\" --max_eval=20  # --batch_size=16 #--log_dir=\"log\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:Starting the run with the mode:hyperopt\n",
            "Namespace(batch_size=32, decay_rate=0.7, decay_step=200000, gpu=0, learning_rate=0.001, log_dir='log/hyperopttiny', max_epoch=10, max_evals=20, model='pointnet_cls', model_path='', momentum=0.9, mongo_mode=0, num_point=1024, optimizer='adam', run_mode='hyperopt')\n",
            "\n",
            "Starting hyperopt\n",
            "HyperOpt batch size selected:2\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
            "2018-11-06 15:50:14.199236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-06 15:50:14.199718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-11-06 15:50:14.199766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 15:50:14.606337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 15:50:14.606406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 15:50:14.606435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 15:50:14.606774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 6.096606\n",
            "accuracy: 0.071289\n",
            "----1-----\n",
            "mean loss: 4.513527\n",
            "accuracy: 0.060680\n",
            "----2-----\n",
            "mean loss: 4.251780\n",
            "accuracy: 0.067871\n",
            "----3-----\n",
            "mean loss: 3.574832\n",
            "accuracy: 0.085938\n",
            "----4-----\n",
            "mean loss: 3.599982\n",
            "accuracy: 0.075684\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 39545.781827\n",
            "eval accuracy: 0.060778\n",
            "eval avg class acc: 0.037500\n",
            "--- Total running time for EPOCH 000 : 0:05:59.131573 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 3.700890\n",
            "accuracy: 0.080078\n",
            "----1-----\n",
            "mean loss: 3.584364\n",
            "accuracy: 0.075243\n",
            "----2-----\n",
            "mean loss: 3.487094\n",
            "accuracy: 0.074219\n",
            "----3-----\n",
            "mean loss: 3.463435\n",
            "accuracy: 0.089844\n",
            "----4-----\n",
            "mean loss: 3.457688\n",
            "accuracy: 0.104980\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1580.379692\n",
            "eval accuracy: 0.055916\n",
            "eval avg class acc: 0.034500\n",
            "--- Total running time for EPOCH 001 : 0:06:00.534982 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 3.408614\n",
            "accuracy: 0.108398\n",
            "----1-----\n",
            "mean loss: 3.491228\n",
            "accuracy: 0.088592\n",
            "----2-----\n",
            "mean loss: 3.424749\n",
            "accuracy: 0.088379\n",
            "----3-----\n",
            "mean loss: 3.377394\n",
            "accuracy: 0.092285\n",
            "----4-----\n",
            "mean loss: 3.387889\n",
            "accuracy: 0.089844\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 325.536670\n",
            "eval accuracy: 0.058347\n",
            "eval avg class acc: 0.036000\n",
            "--- Total running time for EPOCH 002 : 0:05:55.251890 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 3.407128\n",
            "accuracy: 0.102051\n",
            "----1-----\n",
            "mean loss: 3.444279\n",
            "accuracy: 0.093750\n",
            "----2-----\n",
            "mean loss: 3.450100\n",
            "accuracy: 0.081055\n",
            "----3-----\n",
            "mean loss: 3.427810\n",
            "accuracy: 0.092773\n",
            "----4-----\n",
            "mean loss: 3.433229\n",
            "accuracy: 0.085558\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1663.405989\n",
            "eval accuracy: 0.042545\n",
            "eval avg class acc: 0.026250\n",
            "--- Total running time for EPOCH 003 : 0:05:57.599925 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 3.399005\n",
            "accuracy: 0.097656\n",
            "----1-----\n",
            "mean loss: 3.406999\n",
            "accuracy: 0.093447\n",
            "----2-----\n",
            "mean loss: 3.385349\n",
            "accuracy: 0.096191\n",
            "----3-----\n",
            "mean loss: 3.408965\n",
            "accuracy: 0.093262\n",
            "----4-----\n",
            "mean loss: 3.384121\n",
            "accuracy: 0.098145\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 667089.789023\n",
            "eval accuracy: 0.074149\n",
            "eval avg class acc: 0.045750\n",
            "--- Total running time for EPOCH 004 : 0:06:33.009676 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 3.393607\n",
            "accuracy: 0.100098\n",
            "----1-----\n",
            "mean loss: 3.363031\n",
            "accuracy: 0.111816\n",
            "----2-----\n",
            "mean loss: 3.373416\n",
            "accuracy: 0.109375\n",
            "----3-----\n",
            "mean loss: 3.383319\n",
            "accuracy: 0.095267\n",
            "----4-----\n",
            "mean loss: 3.368711\n",
            "accuracy: 0.093262\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 124.702307\n",
            "eval accuracy: 0.082658\n",
            "eval avg class acc: 0.051000\n",
            "--- Total running time for EPOCH 005 : 0:06:00.916679 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 3.372526\n",
            "accuracy: 0.093262\n",
            "----1-----\n",
            "mean loss: 3.358432\n",
            "accuracy: 0.112305\n",
            "----2-----\n",
            "mean loss: 3.373476\n",
            "accuracy: 0.108887\n",
            "----3-----\n",
            "mean loss: 3.381191\n",
            "accuracy: 0.102549\n",
            "----4-----\n",
            "mean loss: 3.348213\n",
            "accuracy: 0.107422\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 8724.624057\n",
            "eval accuracy: 0.067261\n",
            "eval avg class acc: 0.041500\n",
            "--- Total running time for EPOCH 006 : 0:05:57.577008 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 3.367927\n",
            "accuracy: 0.110840\n",
            "----1-----\n",
            "mean loss: 3.346662\n",
            "accuracy: 0.107422\n",
            "----2-----\n",
            "mean loss: 3.464015\n",
            "accuracy: 0.090820\n",
            "----3-----\n",
            "mean loss: 3.408165\n",
            "accuracy: 0.103155\n",
            "----4-----\n",
            "mean loss: 3.353695\n",
            "accuracy: 0.110352\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 32496.204027\n",
            "eval accuracy: 0.040924\n",
            "eval avg class acc: 0.025250\n",
            "--- Total running time for EPOCH 007 : 0:05:58.654199 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 3.359690\n",
            "accuracy: 0.114746\n",
            "----1-----\n",
            "mean loss: 3.390571\n",
            "accuracy: 0.110840\n",
            "----2-----\n",
            "mean loss: 3.455454\n",
            "accuracy: 0.090332\n",
            "----3-----\n",
            "mean loss: 3.456888\n",
            "accuracy: 0.079490\n",
            "----4-----\n",
            "mean loss: 3.420454\n",
            "accuracy: 0.095215\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 4788.986561\n",
            "eval accuracy: 0.031199\n",
            "eval avg class acc: 0.019250\n",
            "--- Total running time for EPOCH 008 : 0:05:58.660577 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 3.398848\n",
            "accuracy: 0.104492\n",
            "----1-----\n",
            "mean loss: 3.395173\n",
            "accuracy: 0.107910\n",
            "----2-----\n",
            "mean loss: 3.381678\n",
            "accuracy: 0.109863\n",
            "----3-----\n",
            "mean loss: 3.395594\n",
            "accuracy: 0.102051\n",
            "----4-----\n",
            "mean loss: 3.406014\n",
            "accuracy: 0.087985\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 116.664289\n",
            "eval accuracy: 0.036872\n",
            "eval avg class acc: 0.022750\n",
            "--- Total running time for EPOCH 009 : 0:05:57.574652 ---\n",
            "--- Total running time for MAIN : 1:00:31.213683 ---\n",
            "HyperOpt batch size selected:32\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 16:50:41.144663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 16:50:41.144771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 16:50:41.144801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 16:50:41.144827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 16:50:41.145092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.810988\n",
            "accuracy: 0.192871\n",
            "----1-----\n",
            "mean loss: 2.790018\n",
            "accuracy: 0.323242\n",
            "----2-----\n",
            "mean loss: 2.290916\n",
            "accuracy: 0.416504\n",
            "----3-----\n",
            "mean loss: 2.147311\n",
            "accuracy: 0.417480\n",
            "----4-----\n",
            "mean loss: 1.883001\n",
            "accuracy: 0.495711\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.100857\n",
            "eval accuracy: 0.411120\n",
            "eval avg class acc: 0.311708\n",
            "--- Total running time for EPOCH 000 : 0:04:04.681564 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 1.796979\n",
            "accuracy: 0.493652\n",
            "----1-----\n",
            "mean loss: 1.574297\n",
            "accuracy: 0.537377\n",
            "----2-----\n",
            "mean loss: 1.535064\n",
            "accuracy: 0.553711\n",
            "----3-----\n",
            "mean loss: 1.469303\n",
            "accuracy: 0.577637\n",
            "----4-----\n",
            "mean loss: 1.294129\n",
            "accuracy: 0.631348\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.185844\n",
            "eval accuracy: 0.636364\n",
            "eval avg class acc: 0.554787\n",
            "--- Total running time for EPOCH 001 : 0:03:45.335458 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.227700\n",
            "accuracy: 0.631740\n",
            "----1-----\n",
            "mean loss: 1.271016\n",
            "accuracy: 0.629395\n",
            "----2-----\n",
            "mean loss: 1.185613\n",
            "accuracy: 0.646484\n",
            "----3-----\n",
            "mean loss: 1.919236\n",
            "accuracy: 0.564453\n",
            "----4-----\n",
            "mean loss: 1.792787\n",
            "accuracy: 0.484863\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.426588\n",
            "eval accuracy: 0.571023\n",
            "eval avg class acc: 0.503692\n",
            "--- Total running time for EPOCH 002 : 0:03:51.122803 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.373710\n",
            "accuracy: 0.586426\n",
            "----1-----\n",
            "mean loss: 1.295068\n",
            "accuracy: 0.609863\n",
            "----2-----\n",
            "mean loss: 1.209711\n",
            "accuracy: 0.636230\n",
            "----3-----\n",
            "mean loss: 1.115374\n",
            "accuracy: 0.648897\n",
            "----4-----\n",
            "mean loss: 1.123451\n",
            "accuracy: 0.665527\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.020607\n",
            "eval accuracy: 0.669643\n",
            "eval avg class acc: 0.600474\n",
            "--- Total running time for EPOCH 003 : 0:03:44.393779 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 1.047520\n",
            "accuracy: 0.667480\n",
            "----1-----\n",
            "mean loss: 1.042055\n",
            "accuracy: 0.694336\n",
            "----2-----\n",
            "mean loss: 1.004764\n",
            "accuracy: 0.706055\n",
            "----3-----\n",
            "mean loss: 0.998801\n",
            "accuracy: 0.702637\n",
            "----4-----\n",
            "mean loss: 0.926132\n",
            "accuracy: 0.710784\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.956563\n",
            "eval accuracy: 0.707792\n",
            "eval avg class acc: 0.641184\n",
            "--- Total running time for EPOCH 004 : 0:03:41.486878 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 0.915441\n",
            "accuracy: 0.718262\n",
            "----1-----\n",
            "mean loss: 1.059078\n",
            "accuracy: 0.682617\n",
            "----2-----\n",
            "mean loss: 0.949623\n",
            "accuracy: 0.719727\n",
            "----3-----\n",
            "mean loss: 0.949656\n",
            "accuracy: 0.704657\n",
            "----4-----\n",
            "mean loss: 0.945063\n",
            "accuracy: 0.712402\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.837519\n",
            "eval accuracy: 0.741477\n",
            "eval avg class acc: 0.679240\n",
            "--- Total running time for EPOCH 005 : 0:03:43.077797 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 0.802637\n",
            "accuracy: 0.754289\n",
            "----1-----\n",
            "mean loss: 0.883231\n",
            "accuracy: 0.721191\n",
            "----2-----\n",
            "mean loss: 0.874264\n",
            "accuracy: 0.732422\n",
            "----3-----\n",
            "mean loss: 0.863214\n",
            "accuracy: 0.737305\n",
            "----4-----\n",
            "mean loss: 0.895172\n",
            "accuracy: 0.725586\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.795400\n",
            "eval accuracy: 0.752029\n",
            "eval avg class acc: 0.683490\n",
            "--- Total running time for EPOCH 006 : 0:03:40.877562 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 0.848415\n",
            "accuracy: 0.732910\n",
            "----1-----\n",
            "mean loss: 0.809988\n",
            "accuracy: 0.756836\n",
            "----2-----\n",
            "mean loss: 0.773608\n",
            "accuracy: 0.755859\n",
            "----3-----\n",
            "mean loss: 0.799011\n",
            "accuracy: 0.757324\n",
            "----4-----\n",
            "mean loss: 0.951505\n",
            "accuracy: 0.714461\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.469094\n",
            "eval accuracy: 0.584416\n",
            "eval avg class acc: 0.531918\n",
            "--- Total running time for EPOCH 007 : 0:03:40.965578 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 1.130188\n",
            "accuracy: 0.667480\n",
            "----1-----\n",
            "mean loss: 0.889509\n",
            "accuracy: 0.727328\n",
            "----2-----\n",
            "mean loss: 0.862682\n",
            "accuracy: 0.732910\n",
            "----3-----\n",
            "mean loss: 0.818898\n",
            "accuracy: 0.752930\n",
            "----4-----\n",
            "mean loss: 0.891881\n",
            "accuracy: 0.729492\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.763111\n",
            "eval accuracy: 0.768263\n",
            "eval avg class acc: 0.709411\n",
            "--- Total running time for EPOCH 008 : 0:03:40.463170 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.777632\n",
            "accuracy: 0.759766\n",
            "----1-----\n",
            "mean loss: 0.764195\n",
            "accuracy: 0.757324\n",
            "----2-----\n",
            "mean loss: 0.771111\n",
            "accuracy: 0.759766\n",
            "----3-----\n",
            "mean loss: 0.736419\n",
            "accuracy: 0.771484\n",
            "----4-----\n",
            "mean loss: 0.722406\n",
            "accuracy: 0.772672\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.943389\n",
            "eval accuracy: 0.693994\n",
            "eval avg class acc: 0.661272\n",
            "--- Total running time for EPOCH 009 : 0:03:40.885907 ---\n",
            "--- Total running time for MAIN : 0:37:41.102572 ---\n",
            "HyperOpt batch size selected:32\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 17:28:22.141660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 17:28:22.141768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 17:28:22.141809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 17:28:22.141837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 17:28:22.142094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.887415\n",
            "accuracy: 0.187012\n",
            "----1-----\n",
            "mean loss: 2.841236\n",
            "accuracy: 0.322266\n",
            "----2-----\n",
            "mean loss: 2.305567\n",
            "accuracy: 0.411133\n",
            "----3-----\n",
            "mean loss: 2.035824\n",
            "accuracy: 0.445466\n",
            "----4-----\n",
            "mean loss: 1.941512\n",
            "accuracy: 0.465332\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.707022\n",
            "eval accuracy: 0.536526\n",
            "eval avg class acc: 0.425957\n",
            "--- Total running time for EPOCH 000 : 0:03:42.471465 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 1.652964\n",
            "accuracy: 0.522949\n",
            "----1-----\n",
            "mean loss: 1.537207\n",
            "accuracy: 0.544922\n",
            "----2-----\n",
            "mean loss: 1.413294\n",
            "accuracy: 0.585784\n",
            "----3-----\n",
            "mean loss: 1.422651\n",
            "accuracy: 0.587891\n",
            "----4-----\n",
            "mean loss: 1.368952\n",
            "accuracy: 0.589844\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.295644\n",
            "eval accuracy: 0.618506\n",
            "eval avg class acc: 0.546977\n",
            "--- Total running time for EPOCH 001 : 0:03:38.529696 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.307267\n",
            "accuracy: 0.614258\n",
            "----1-----\n",
            "mean loss: 1.419166\n",
            "accuracy: 0.607230\n",
            "----2-----\n",
            "mean loss: 1.900791\n",
            "accuracy: 0.494141\n",
            "----3-----\n",
            "mean loss: 1.477714\n",
            "accuracy: 0.555176\n",
            "----4-----\n",
            "mean loss: 1.260177\n",
            "accuracy: 0.623047\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.095686\n",
            "eval accuracy: 0.679789\n",
            "eval avg class acc: 0.595863\n",
            "--- Total running time for EPOCH 002 : 0:03:36.517114 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.180719\n",
            "accuracy: 0.656250\n",
            "----1-----\n",
            "mean loss: 1.158196\n",
            "accuracy: 0.651367\n",
            "----2-----\n",
            "mean loss: 1.152405\n",
            "accuracy: 0.654297\n",
            "----3-----\n",
            "mean loss: 1.063643\n",
            "accuracy: 0.665441\n",
            "----4-----\n",
            "mean loss: 1.046414\n",
            "accuracy: 0.686035\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.946002\n",
            "eval accuracy: 0.722808\n",
            "eval avg class acc: 0.643132\n",
            "--- Total running time for EPOCH 003 : 0:03:36.522059 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 1.037443\n",
            "accuracy: 0.695801\n",
            "----1-----\n",
            "mean loss: 0.994619\n",
            "accuracy: 0.702148\n",
            "----2-----\n",
            "mean loss: 0.950767\n",
            "accuracy: 0.710172\n",
            "----3-----\n",
            "mean loss: 0.956219\n",
            "accuracy: 0.706543\n",
            "----4-----\n",
            "mean loss: 0.921880\n",
            "accuracy: 0.716309\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.842627\n",
            "eval accuracy: 0.739448\n",
            "eval avg class acc: 0.665442\n",
            "--- Total running time for EPOCH 004 : 0:03:36.582488 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 0.935605\n",
            "accuracy: 0.710938\n",
            "----1-----\n",
            "mean loss: 0.933808\n",
            "accuracy: 0.726074\n",
            "----2-----\n",
            "mean loss: 0.939575\n",
            "accuracy: 0.717773\n",
            "----3-----\n",
            "mean loss: 0.832565\n",
            "accuracy: 0.742647\n",
            "----4-----\n",
            "mean loss: 0.869098\n",
            "accuracy: 0.744141\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.872337\n",
            "eval accuracy: 0.744318\n",
            "eval avg class acc: 0.674779\n",
            "--- Total running time for EPOCH 005 : 0:03:36.531276 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 0.803811\n",
            "accuracy: 0.750488\n",
            "----1-----\n",
            "mean loss: 0.796749\n",
            "accuracy: 0.759804\n",
            "----2-----\n",
            "mean loss: 0.865257\n",
            "accuracy: 0.729492\n",
            "----3-----\n",
            "mean loss: 0.870213\n",
            "accuracy: 0.742188\n",
            "----4-----\n",
            "mean loss: 0.841067\n",
            "accuracy: 0.741211\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.757520\n",
            "eval accuracy: 0.774351\n",
            "eval avg class acc: 0.712213\n",
            "--- Total running time for EPOCH 006 : 0:03:36.513726 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 0.851116\n",
            "accuracy: 0.741699\n",
            "----1-----\n",
            "mean loss: 0.837897\n",
            "accuracy: 0.749023\n",
            "----2-----\n",
            "mean loss: 0.732504\n",
            "accuracy: 0.773897\n",
            "----3-----\n",
            "mean loss: 0.779920\n",
            "accuracy: 0.754395\n",
            "----4-----\n",
            "mean loss: 0.806916\n",
            "accuracy: 0.756836\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.825427\n",
            "eval accuracy: 0.734172\n",
            "eval avg class acc: 0.667752\n",
            "--- Total running time for EPOCH 007 : 0:03:36.600627 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 0.806445\n",
            "accuracy: 0.758301\n",
            "----1-----\n",
            "mean loss: 0.759975\n",
            "accuracy: 0.769531\n",
            "----2-----\n",
            "mean loss: 0.770589\n",
            "accuracy: 0.762695\n",
            "----3-----\n",
            "mean loss: 0.763240\n",
            "accuracy: 0.775391\n",
            "----4-----\n",
            "mean loss: 0.691509\n",
            "accuracy: 0.791054\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.688146\n",
            "eval accuracy: 0.782873\n",
            "eval avg class acc: 0.740342\n",
            "--- Total running time for EPOCH 008 : 0:03:36.562010 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.876066\n",
            "accuracy: 0.753418\n",
            "----1-----\n",
            "mean loss: 0.838809\n",
            "accuracy: 0.756836\n",
            "----2-----\n",
            "mean loss: 0.753429\n",
            "accuracy: 0.770508\n",
            "----3-----\n",
            "mean loss: 0.686859\n",
            "accuracy: 0.783088\n",
            "----4-----\n",
            "mean loss: 0.749564\n",
            "accuracy: 0.766113\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.674386\n",
            "eval accuracy: 0.793019\n",
            "eval avg class acc: 0.725899\n",
            "--- Total running time for EPOCH 009 : 0:03:36.605739 ---\n",
            "--- Total running time for MAIN : 0:36:21.381840 ---\n",
            "HyperOpt batch size selected:2\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 18:04:43.718318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 18:04:43.718414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 18:04:43.718444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 18:04:43.718466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 18:04:43.718740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 6.918273\n",
            "accuracy: 0.058252\n",
            "----1-----\n",
            "mean loss: 4.808116\n",
            "accuracy: 0.079590\n",
            "----2-----\n",
            "mean loss: 4.204311\n",
            "accuracy: 0.072754\n",
            "----3-----\n",
            "mean loss: 3.732755\n",
            "accuracy: 0.068848\n",
            "----4-----\n",
            "mean loss: 3.721478\n",
            "accuracy: 0.083496\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 4816846.552032\n",
            "eval accuracy: 0.057942\n",
            "eval avg class acc: 0.035750\n",
            "--- Total running time for EPOCH 000 : 0:05:53.441287 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 3.882493\n",
            "accuracy: 0.091309\n",
            "----1-----\n",
            "mean loss: 3.618302\n",
            "accuracy: 0.097087\n",
            "----2-----\n",
            "mean loss: 3.427127\n",
            "accuracy: 0.093750\n",
            "----3-----\n",
            "mean loss: 3.409622\n",
            "accuracy: 0.092773\n",
            "----4-----\n",
            "mean loss: 3.431534\n",
            "accuracy: 0.112305\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 3295510.927375\n",
            "eval accuracy: 0.049028\n",
            "eval avg class acc: 0.030250\n",
            "--- Total running time for EPOCH 001 : 0:05:51.130677 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 3.388157\n",
            "accuracy: 0.124393\n",
            "----1-----\n",
            "mean loss: 3.424493\n",
            "accuracy: 0.121582\n",
            "----2-----\n",
            "mean loss: 3.389366\n",
            "accuracy: 0.128418\n",
            "----3-----\n",
            "mean loss: 3.505599\n",
            "accuracy: 0.115234\n",
            "----4-----\n",
            "mean loss: 3.368870\n",
            "accuracy: 0.119629\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 4529.628096\n",
            "eval accuracy: 0.047407\n",
            "eval avg class acc: 0.029250\n",
            "--- Total running time for EPOCH 002 : 0:05:51.575325 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 3.357883\n",
            "accuracy: 0.110352\n",
            "----1-----\n",
            "mean loss: 3.394570\n",
            "accuracy: 0.107910\n",
            "----2-----\n",
            "mean loss: 3.435112\n",
            "accuracy: 0.106445\n",
            "----3-----\n",
            "mean loss: 3.467450\n",
            "accuracy: 0.081311\n",
            "----4-----\n",
            "mean loss: 3.415065\n",
            "accuracy: 0.113281\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 56831.960478\n",
            "eval accuracy: 0.044165\n",
            "eval avg class acc: 0.027250\n",
            "--- Total running time for EPOCH 003 : 0:05:51.240610 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 3.449790\n",
            "accuracy: 0.097168\n",
            "----1-----\n",
            "mean loss: 3.428657\n",
            "accuracy: 0.101562\n",
            "----2-----\n",
            "mean loss: 3.367134\n",
            "accuracy: 0.129395\n",
            "----3-----\n",
            "mean loss: 3.467091\n",
            "accuracy: 0.081311\n",
            "----4-----\n",
            "mean loss: 3.435160\n",
            "accuracy: 0.089844\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 12275.422130\n",
            "eval accuracy: 0.040519\n",
            "eval avg class acc: 0.025000\n",
            "--- Total running time for EPOCH 004 : 0:05:50.995709 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 3.461804\n",
            "accuracy: 0.101942\n",
            "----1-----\n",
            "mean loss: 3.444559\n",
            "accuracy: 0.110840\n",
            "----2-----\n",
            "mean loss: 3.422201\n",
            "accuracy: 0.105957\n",
            "----3-----\n",
            "mean loss: 3.437286\n",
            "accuracy: 0.112305\n",
            "----4-----\n",
            "mean loss: 3.435688\n",
            "accuracy: 0.095215\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 3329551.200237\n",
            "eval accuracy: 0.040113\n",
            "eval avg class acc: 0.024750\n",
            "--- Total running time for EPOCH 005 : 0:05:51.007601 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 3.432995\n",
            "accuracy: 0.092773\n",
            "----1-----\n",
            "mean loss: 3.456907\n",
            "accuracy: 0.086772\n",
            "----2-----\n",
            "mean loss: 3.453718\n",
            "accuracy: 0.104004\n",
            "----3-----\n",
            "mean loss: 3.419209\n",
            "accuracy: 0.101562\n",
            "----4-----\n",
            "mean loss: 3.443606\n",
            "accuracy: 0.100586\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 27000.031844\n",
            "eval accuracy: 0.040519\n",
            "eval avg class acc: 0.025000\n",
            "--- Total running time for EPOCH 006 : 0:05:50.818496 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 3.440102\n",
            "accuracy: 0.102549\n",
            "----1-----\n",
            "mean loss: 3.431283\n",
            "accuracy: 0.093262\n",
            "----2-----\n",
            "mean loss: 3.401969\n",
            "accuracy: 0.107910\n",
            "----3-----\n",
            "mean loss: 3.466451\n",
            "accuracy: 0.100098\n",
            "----4-----\n",
            "mean loss: 3.413717\n",
            "accuracy: 0.104492\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 65174.199681\n",
            "eval accuracy: 0.040519\n",
            "eval avg class acc: 0.025000\n",
            "--- Total running time for EPOCH 007 : 0:05:50.634130 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 3.431730\n",
            "accuracy: 0.095215\n",
            "----1-----\n",
            "mean loss: 3.405975\n",
            "accuracy: 0.101074\n",
            "----2-----\n",
            "mean loss: 3.387669\n",
            "accuracy: 0.094238\n",
            "----3-----\n",
            "mean loss: 3.401957\n",
            "accuracy: 0.091019\n",
            "----4-----\n",
            "mean loss: 3.394182\n",
            "accuracy: 0.099121\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 525670.821226\n",
            "eval accuracy: 0.040519\n",
            "eval avg class acc: 0.025000\n",
            "--- Total running time for EPOCH 008 : 0:05:50.748803 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 3.382384\n",
            "accuracy: 0.116699\n",
            "----1-----\n",
            "mean loss: 3.390427\n",
            "accuracy: 0.104492\n",
            "----2-----\n",
            "mean loss: 3.382935\n",
            "accuracy: 0.100098\n",
            "----3-----\n",
            "mean loss: 3.381294\n",
            "accuracy: 0.104976\n",
            "----4-----\n",
            "mean loss: 3.357463\n",
            "accuracy: 0.110352\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 338.055892\n",
            "eval accuracy: 0.038898\n",
            "eval avg class acc: 0.024000\n",
            "--- Total running time for EPOCH 009 : 0:05:50.653682 ---\n",
            "--- Total running time for MAIN : 0:58:40.130234 ---\n",
            "HyperOpt batch size selected:4\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 19:03:23.974867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 19:03:23.974965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 19:03:23.974999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 19:03:23.975026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 19:03:23.975370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 4.158888\n",
            "accuracy: 0.099121\n",
            "----1-----\n",
            "mean loss: 3.557326\n",
            "accuracy: 0.104976\n",
            "----2-----\n",
            "mean loss: 3.386292\n",
            "accuracy: 0.134766\n",
            "----3-----\n",
            "mean loss: 3.275129\n",
            "accuracy: 0.148926\n",
            "----4-----\n",
            "mean loss: 3.275624\n",
            "accuracy: 0.153809\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 3.825514\n",
            "eval accuracy: 0.132496\n",
            "eval avg class acc: 0.081750\n",
            "--- Total running time for EPOCH 000 : 0:04:33.178353 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 3.111032\n",
            "accuracy: 0.176270\n",
            "----1-----\n",
            "mean loss: 3.067254\n",
            "accuracy: 0.165049\n",
            "----2-----\n",
            "mean loss: 3.029586\n",
            "accuracy: 0.183105\n",
            "----3-----\n",
            "mean loss: 2.969641\n",
            "accuracy: 0.203125\n",
            "----4-----\n",
            "mean loss: 2.937056\n",
            "accuracy: 0.209473\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.665310\n",
            "eval accuracy: 0.218395\n",
            "eval avg class acc: 0.188238\n",
            "--- Total running time for EPOCH 001 : 0:04:30.710443 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 2.831526\n",
            "accuracy: 0.224121\n",
            "----1-----\n",
            "mean loss: 2.785289\n",
            "accuracy: 0.232422\n",
            "----2-----\n",
            "mean loss: 2.668076\n",
            "accuracy: 0.250977\n",
            "----3-----\n",
            "mean loss: 2.710748\n",
            "accuracy: 0.255859\n",
            "----4-----\n",
            "mean loss: 2.531598\n",
            "accuracy: 0.282160\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 3.083713\n",
            "eval accuracy: 0.276337\n",
            "eval avg class acc: 0.211820\n",
            "--- Total running time for EPOCH 002 : 0:04:30.386185 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 2.458437\n",
            "accuracy: 0.304688\n",
            "----1-----\n",
            "mean loss: 2.330980\n",
            "accuracy: 0.336426\n",
            "----2-----\n",
            "mean loss: 2.216946\n",
            "accuracy: 0.352549\n",
            "----3-----\n",
            "mean loss: 2.148144\n",
            "accuracy: 0.371582\n",
            "----4-----\n",
            "mean loss: 2.087909\n",
            "accuracy: 0.396484\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 9.403125\n",
            "eval accuracy: 0.291329\n",
            "eval avg class acc: 0.256203\n",
            "--- Total running time for EPOCH 003 : 0:04:30.455121 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 2.007503\n",
            "accuracy: 0.404785\n",
            "----1-----\n",
            "mean loss: 1.939350\n",
            "accuracy: 0.425781\n",
            "----2-----\n",
            "mean loss: 1.899442\n",
            "accuracy: 0.466309\n",
            "----3-----\n",
            "mean loss: 1.989909\n",
            "accuracy: 0.430664\n",
            "----4-----\n",
            "mean loss: 1.911659\n",
            "accuracy: 0.427184\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.730643\n",
            "eval accuracy: 0.537277\n",
            "eval avg class acc: 0.440826\n",
            "--- Total running time for EPOCH 004 : 0:04:30.485869 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 1.843126\n",
            "accuracy: 0.450684\n",
            "----1-----\n",
            "mean loss: 1.803918\n",
            "accuracy: 0.472087\n",
            "----2-----\n",
            "mean loss: 1.789605\n",
            "accuracy: 0.484375\n",
            "----3-----\n",
            "mean loss: 1.740445\n",
            "accuracy: 0.504395\n",
            "----4-----\n",
            "mean loss: 1.760074\n",
            "accuracy: 0.486328\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.713813\n",
            "eval accuracy: 0.535656\n",
            "eval avg class acc: 0.449802\n",
            "--- Total running time for EPOCH 005 : 0:04:30.286267 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 1.694822\n",
            "accuracy: 0.507324\n",
            "----1-----\n",
            "mean loss: 1.729719\n",
            "accuracy: 0.503418\n",
            "----2-----\n",
            "mean loss: 1.664126\n",
            "accuracy: 0.524902\n",
            "----3-----\n",
            "mean loss: 1.685743\n",
            "accuracy: 0.517597\n",
            "----4-----\n",
            "mean loss: 1.670786\n",
            "accuracy: 0.514648\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.857858\n",
            "eval accuracy: 0.561994\n",
            "eval avg class acc: 0.464203\n",
            "--- Total running time for EPOCH 006 : 0:04:30.429673 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 1.622603\n",
            "accuracy: 0.515777\n",
            "----1-----\n",
            "mean loss: 1.699327\n",
            "accuracy: 0.512207\n",
            "----2-----\n",
            "mean loss: 1.540680\n",
            "accuracy: 0.561035\n",
            "----3-----\n",
            "mean loss: 1.620680\n",
            "accuracy: 0.536133\n",
            "----4-----\n",
            "mean loss: 1.607930\n",
            "accuracy: 0.527832\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.401520\n",
            "eval accuracy: 0.627634\n",
            "eval avg class acc: 0.555901\n",
            "--- Total running time for EPOCH 007 : 0:04:30.235079 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 1.566284\n",
            "accuracy: 0.541504\n",
            "----1-----\n",
            "mean loss: 1.509709\n",
            "accuracy: 0.551270\n",
            "----2-----\n",
            "mean loss: 1.587851\n",
            "accuracy: 0.558859\n",
            "----3-----\n",
            "mean loss: 1.592816\n",
            "accuracy: 0.540527\n",
            "----4-----\n",
            "mean loss: 1.526648\n",
            "accuracy: 0.553711\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.316725\n",
            "eval accuracy: 0.623987\n",
            "eval avg class acc: 0.554209\n",
            "--- Total running time for EPOCH 008 : 0:04:30.470096 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 1.473549\n",
            "accuracy: 0.572754\n",
            "----1-----\n",
            "mean loss: 1.496285\n",
            "accuracy: 0.559570\n",
            "----2-----\n",
            "mean loss: 1.455278\n",
            "accuracy: 0.561286\n",
            "----3-----\n",
            "mean loss: 1.444912\n",
            "accuracy: 0.577148\n",
            "----4-----\n",
            "mean loss: 1.464460\n",
            "accuracy: 0.565430\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 4.084831\n",
            "eval accuracy: 0.541734\n",
            "eval avg class acc: 0.509186\n",
            "--- Total running time for EPOCH 009 : 0:04:30.403754 ---\n",
            "--- Total running time for MAIN : 0:45:15.109617 ---\n",
            "HyperOpt batch size selected:2\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 19:48:38.914231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 19:48:38.914350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 19:48:38.914382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 19:48:38.914404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 19:48:38.914662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 6.563374\n",
            "accuracy: 0.078125\n",
            "----1-----\n",
            "mean loss: 4.551657\n",
            "accuracy: 0.071777\n",
            "----2-----\n",
            "mean loss: 3.944852\n",
            "accuracy: 0.097168\n",
            "----3-----\n",
            "mean loss: 3.665053\n",
            "accuracy: 0.090820\n",
            "----4-----\n",
            "mean loss: 3.614430\n",
            "accuracy: 0.097694\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 96777.997212\n",
            "eval accuracy: 0.044976\n",
            "eval avg class acc: 0.027750\n",
            "--- Total running time for EPOCH 000 : 0:05:52.888579 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 3.498873\n",
            "accuracy: 0.093262\n",
            "----1-----\n",
            "mean loss: 3.559021\n",
            "accuracy: 0.085938\n",
            "----2-----\n",
            "mean loss: 3.402290\n",
            "accuracy: 0.105957\n",
            "----3-----\n",
            "mean loss: 3.562431\n",
            "accuracy: 0.081917\n",
            "----4-----\n",
            "mean loss: 3.491474\n",
            "accuracy: 0.095215\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 10197.215436\n",
            "eval accuracy: 0.046596\n",
            "eval avg class acc: 0.028750\n",
            "--- Total running time for EPOCH 001 : 0:05:51.084952 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 3.399840\n",
            "accuracy: 0.105469\n",
            "----1-----\n",
            "mean loss: 3.368058\n",
            "accuracy: 0.115898\n",
            "----2-----\n",
            "mean loss: 3.334002\n",
            "accuracy: 0.126953\n",
            "----3-----\n",
            "mean loss: 3.359882\n",
            "accuracy: 0.128906\n",
            "----4-----\n",
            "mean loss: 3.348944\n",
            "accuracy: 0.120605\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 15332074.204133\n",
            "eval accuracy: 0.040519\n",
            "eval avg class acc: 0.025000\n",
            "--- Total running time for EPOCH 002 : 0:05:50.603374 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 3.360294\n",
            "accuracy: 0.127441\n",
            "----1-----\n",
            "mean loss: 3.378812\n",
            "accuracy: 0.126953\n",
            "----2-----\n",
            "mean loss: 3.434369\n",
            "accuracy: 0.090820\n",
            "----3-----\n",
            "mean loss: 3.391199\n",
            "accuracy: 0.097656\n",
            "----4-----\n",
            "mean loss: 3.387132\n",
            "accuracy: 0.116505\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 3238.728764\n",
            "eval accuracy: 0.073744\n",
            "eval avg class acc: 0.045500\n",
            "--- Total running time for EPOCH 003 : 0:05:50.575288 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 3.361582\n",
            "accuracy: 0.111816\n",
            "----1-----\n",
            "mean loss: 3.357496\n",
            "accuracy: 0.111650\n",
            "----2-----\n",
            "mean loss: 3.343450\n",
            "accuracy: 0.126465\n",
            "----3-----\n",
            "mean loss: 3.411759\n",
            "accuracy: 0.107910\n",
            "----4-----\n",
            "mean loss: 3.438986\n",
            "accuracy: 0.091797\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 643.059128\n",
            "eval accuracy: 0.074959\n",
            "eval avg class acc: 0.046250\n",
            "--- Total running time for EPOCH 004 : 0:05:50.598112 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 3.358770\n",
            "accuracy: 0.117676\n",
            "----1-----\n",
            "mean loss: 3.349224\n",
            "accuracy: 0.120146\n",
            "----2-----\n",
            "mean loss: 3.347760\n",
            "accuracy: 0.125488\n",
            "----3-----\n",
            "mean loss: 3.327696\n",
            "accuracy: 0.121094\n",
            "----4-----\n",
            "mean loss: 3.333520\n",
            "accuracy: 0.111328\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 6444.683725\n",
            "eval accuracy: 0.059157\n",
            "eval avg class acc: 0.036500\n",
            "--- Total running time for EPOCH 005 : 0:05:50.377933 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 3.320865\n",
            "accuracy: 0.120146\n",
            "----1-----\n",
            "mean loss: 3.348901\n",
            "accuracy: 0.121582\n",
            "----2-----\n",
            "mean loss: 3.342197\n",
            "accuracy: 0.116699\n",
            "----3-----\n",
            "mean loss: 3.365364\n",
            "accuracy: 0.092773\n",
            "----4-----\n",
            "mean loss: 3.317651\n",
            "accuracy: 0.124512\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 71.606262\n",
            "eval accuracy: 0.045786\n",
            "eval avg class acc: 0.028250\n",
            "--- Total running time for EPOCH 006 : 0:05:50.668483 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 3.337603\n",
            "accuracy: 0.101562\n",
            "----1-----\n",
            "mean loss: 3.372781\n",
            "accuracy: 0.098633\n",
            "----2-----\n",
            "mean loss: 3.345262\n",
            "accuracy: 0.124023\n",
            "----3-----\n",
            "mean loss: 3.387448\n",
            "accuracy: 0.106796\n",
            "----4-----\n",
            "mean loss: 3.450501\n",
            "accuracy: 0.091797\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 233362.843750\n",
            "eval accuracy: 0.040113\n",
            "eval avg class acc: 0.024750\n",
            "--- Total running time for EPOCH 007 : 0:05:50.509656 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 3.418368\n",
            "accuracy: 0.094238\n",
            "----1-----\n",
            "mean loss: 3.410277\n",
            "accuracy: 0.093262\n",
            "----2-----\n",
            "mean loss: 3.433005\n",
            "accuracy: 0.089844\n",
            "----3-----\n",
            "mean loss: 3.426951\n",
            "accuracy: 0.096191\n",
            "----4-----\n",
            "mean loss: 3.436516\n",
            "accuracy: 0.084951\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 217656.650359\n",
            "eval accuracy: 0.040519\n",
            "eval avg class acc: 0.025000\n",
            "--- Total running time for EPOCH 008 : 0:05:50.515501 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 3.430154\n",
            "accuracy: 0.091309\n",
            "----1-----\n",
            "mean loss: 3.378161\n",
            "accuracy: 0.094238\n",
            "----2-----\n",
            "mean loss: 3.395459\n",
            "accuracy: 0.096680\n",
            "----3-----\n",
            "mean loss: 3.490475\n",
            "accuracy: 0.091309\n",
            "----4-----\n",
            "mean loss: 3.448449\n",
            "accuracy: 0.084345\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 32499.985232\n",
            "eval accuracy: 0.039303\n",
            "eval avg class acc: 0.024250\n",
            "--- Total running time for EPOCH 009 : 0:05:51.029590 ---\n",
            "--- Total running time for MAIN : 0:58:36.638911 ---\n",
            "HyperOpt batch size selected:32\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 20:47:15.664794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 20:47:15.664897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 20:47:15.664928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 20:47:15.664950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 20:47:15.665204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.742031\n",
            "accuracy: 0.219238\n",
            "----1-----\n",
            "mean loss: 2.839655\n",
            "accuracy: 0.305176\n",
            "----2-----\n",
            "mean loss: 2.480971\n",
            "accuracy: 0.351562\n",
            "----3-----\n",
            "mean loss: 2.113892\n",
            "accuracy: 0.427696\n",
            "----4-----\n",
            "mean loss: 1.871507\n",
            "accuracy: 0.469727\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.889697\n",
            "eval accuracy: 0.421672\n",
            "eval avg class acc: 0.343720\n",
            "--- Total running time for EPOCH 000 : 0:03:39.281056 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 1.937609\n",
            "accuracy: 0.470215\n",
            "----1-----\n",
            "mean loss: 1.961615\n",
            "accuracy: 0.464355\n",
            "----2-----\n",
            "mean loss: 1.587696\n",
            "accuracy: 0.543505\n",
            "----3-----\n",
            "mean loss: 1.536003\n",
            "accuracy: 0.564453\n",
            "----4-----\n",
            "mean loss: 1.473085\n",
            "accuracy: 0.570801\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.414585\n",
            "eval accuracy: 0.581575\n",
            "eval avg class acc: 0.497985\n",
            "--- Total running time for EPOCH 001 : 0:03:36.923895 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.391178\n",
            "accuracy: 0.597168\n",
            "----1-----\n",
            "mean loss: 1.247587\n",
            "accuracy: 0.631836\n",
            "----2-----\n",
            "mean loss: 1.273617\n",
            "accuracy: 0.616699\n",
            "----3-----\n",
            "mean loss: 1.205531\n",
            "accuracy: 0.628676\n",
            "----4-----\n",
            "mean loss: 1.328275\n",
            "accuracy: 0.616699\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.486383\n",
            "eval accuracy: 0.570211\n",
            "eval avg class acc: 0.521408\n",
            "--- Total running time for EPOCH 002 : 0:03:36.982966 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.250261\n",
            "accuracy: 0.625000\n",
            "----1-----\n",
            "mean loss: 1.181312\n",
            "accuracy: 0.654785\n",
            "----2-----\n",
            "mean loss: 1.156116\n",
            "accuracy: 0.647461\n",
            "----3-----\n",
            "mean loss: 1.079083\n",
            "accuracy: 0.676471\n",
            "----4-----\n",
            "mean loss: 1.092041\n",
            "accuracy: 0.673828\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.981291\n",
            "eval accuracy: 0.697646\n",
            "eval avg class acc: 0.625724\n",
            "--- Total running time for EPOCH 003 : 0:03:36.860034 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 1.011485\n",
            "accuracy: 0.700684\n",
            "----1-----\n",
            "mean loss: 0.934455\n",
            "accuracy: 0.716299\n",
            "----2-----\n",
            "mean loss: 1.131162\n",
            "accuracy: 0.672363\n",
            "----3-----\n",
            "mean loss: 1.125486\n",
            "accuracy: 0.669922\n",
            "----4-----\n",
            "mean loss: 0.988725\n",
            "accuracy: 0.707520\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.936587\n",
            "eval accuracy: 0.704951\n",
            "eval avg class acc: 0.641977\n",
            "--- Total running time for EPOCH 004 : 0:03:36.891257 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 0.958534\n",
            "accuracy: 0.715820\n",
            "----1-----\n",
            "mean loss: 0.943521\n",
            "accuracy: 0.712891\n",
            "----2-----\n",
            "mean loss: 0.974661\n",
            "accuracy: 0.695801\n",
            "----3-----\n",
            "mean loss: 0.922564\n",
            "accuracy: 0.727051\n",
            "----4-----\n",
            "mean loss: 0.954479\n",
            "accuracy: 0.719975\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.840406\n",
            "eval accuracy: 0.747159\n",
            "eval avg class acc: 0.689974\n",
            "--- Total running time for EPOCH 005 : 0:03:36.903630 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 0.902918\n",
            "accuracy: 0.714844\n",
            "----1-----\n",
            "mean loss: 0.927197\n",
            "accuracy: 0.731934\n",
            "----2-----\n",
            "mean loss: 0.841057\n",
            "accuracy: 0.741699\n",
            "----3-----\n",
            "mean loss: 0.794696\n",
            "accuracy: 0.760417\n",
            "----4-----\n",
            "mean loss: 0.896225\n",
            "accuracy: 0.726562\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.981969\n",
            "eval accuracy: 0.704545\n",
            "eval avg class acc: 0.649879\n",
            "--- Total running time for EPOCH 006 : 0:03:36.844431 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 0.960936\n",
            "accuracy: 0.702206\n",
            "----1-----\n",
            "mean loss: 0.897139\n",
            "accuracy: 0.729492\n",
            "----2-----\n",
            "mean loss: 0.837743\n",
            "accuracy: 0.743652\n",
            "----3-----\n",
            "mean loss: 0.809984\n",
            "accuracy: 0.750977\n",
            "----4-----\n",
            "mean loss: 0.829826\n",
            "accuracy: 0.735352\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.745721\n",
            "eval accuracy: 0.776786\n",
            "eval avg class acc: 0.711081\n",
            "--- Total running time for EPOCH 007 : 0:03:36.892627 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 0.792865\n",
            "accuracy: 0.770020\n",
            "----1-----\n",
            "mean loss: 0.795766\n",
            "accuracy: 0.747070\n",
            "----2-----\n",
            "mean loss: 0.814484\n",
            "accuracy: 0.747559\n",
            "----3-----\n",
            "mean loss: 0.799653\n",
            "accuracy: 0.751953\n",
            "----4-----\n",
            "mean loss: 0.730878\n",
            "accuracy: 0.770833\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.694020\n",
            "eval accuracy: 0.795860\n",
            "eval avg class acc: 0.760897\n",
            "--- Total running time for EPOCH 008 : 0:03:36.928133 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.725640\n",
            "accuracy: 0.766602\n",
            "----1-----\n",
            "mean loss: 0.671757\n",
            "accuracy: 0.786152\n",
            "----2-----\n",
            "mean loss: 0.769087\n",
            "accuracy: 0.770996\n",
            "----3-----\n",
            "mean loss: 0.793845\n",
            "accuracy: 0.752930\n",
            "----4-----\n",
            "mean loss: 0.720989\n",
            "accuracy: 0.775879\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.699257\n",
            "eval accuracy: 0.777597\n",
            "eval avg class acc: 0.727699\n",
            "--- Total running time for EPOCH 009 : 0:03:36.978936 ---\n",
            "--- Total running time for MAIN : 0:36:19.470145 ---\n",
            "HyperOpt batch size selected:8\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 21:23:35.043372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 21:23:35.043474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 21:23:35.043505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 21:23:35.043528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 21:23:35.043804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.805981\n",
            "accuracy: 0.142090\n",
            "----1-----\n",
            "mean loss: 3.265156\n",
            "accuracy: 0.178398\n",
            "----2-----\n",
            "mean loss: 3.049068\n",
            "accuracy: 0.205566\n",
            "----3-----\n",
            "mean loss: 2.933207\n",
            "accuracy: 0.222168\n",
            "----4-----\n",
            "mean loss: 2.645158\n",
            "accuracy: 0.296875\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.493834\n",
            "eval accuracy: 0.283685\n",
            "eval avg class acc: 0.193150\n",
            "--- Total running time for EPOCH 000 : 0:03:53.771470 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 2.486775\n",
            "accuracy: 0.313477\n",
            "----1-----\n",
            "mean loss: 2.418414\n",
            "accuracy: 0.315918\n",
            "----2-----\n",
            "mean loss: 2.233922\n",
            "accuracy: 0.360840\n",
            "----3-----\n",
            "mean loss: 2.081535\n",
            "accuracy: 0.396484\n",
            "----4-----\n",
            "mean loss: 2.014895\n",
            "accuracy: 0.408374\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.683790\n",
            "eval accuracy: 0.480519\n",
            "eval avg class acc: 0.396702\n",
            "--- Total running time for EPOCH 001 : 0:03:51.451549 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.970391\n",
            "accuracy: 0.432129\n",
            "----1-----\n",
            "mean loss: 1.727813\n",
            "accuracy: 0.481189\n",
            "----2-----\n",
            "mean loss: 1.745128\n",
            "accuracy: 0.489746\n",
            "----3-----\n",
            "mean loss: 1.640050\n",
            "accuracy: 0.502930\n",
            "----4-----\n",
            "mean loss: 1.538713\n",
            "accuracy: 0.542480\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.369844\n",
            "eval accuracy: 0.579545\n",
            "eval avg class acc: 0.507528\n",
            "--- Total running time for EPOCH 002 : 0:03:51.348825 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.415856\n",
            "accuracy: 0.577063\n",
            "----1-----\n",
            "mean loss: 1.432421\n",
            "accuracy: 0.587402\n",
            "----2-----\n",
            "mean loss: 1.420494\n",
            "accuracy: 0.572266\n",
            "----3-----\n",
            "mean loss: 1.417452\n",
            "accuracy: 0.581543\n",
            "----4-----\n",
            "mean loss: 1.424565\n",
            "accuracy: 0.575684\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.113464\n",
            "eval accuracy: 0.655844\n",
            "eval avg class acc: 0.586827\n",
            "--- Total running time for EPOCH 003 : 0:03:51.289912 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 1.297621\n",
            "accuracy: 0.617112\n",
            "----1-----\n",
            "mean loss: 1.307264\n",
            "accuracy: 0.611816\n",
            "----2-----\n",
            "mean loss: 1.233625\n",
            "accuracy: 0.634766\n",
            "----3-----\n",
            "mean loss: 1.310947\n",
            "accuracy: 0.616211\n",
            "----4-----\n",
            "mean loss: 1.313550\n",
            "accuracy: 0.613770\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.960682\n",
            "eval accuracy: 0.702922\n",
            "eval avg class acc: 0.636365\n",
            "--- Total running time for EPOCH 004 : 0:03:51.222458 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 1.198567\n",
            "accuracy: 0.631836\n",
            "----1-----\n",
            "mean loss: 1.174011\n",
            "accuracy: 0.645508\n",
            "----2-----\n",
            "mean loss: 1.158187\n",
            "accuracy: 0.662598\n",
            "----3-----\n",
            "mean loss: 1.159169\n",
            "accuracy: 0.646845\n",
            "----4-----\n",
            "mean loss: 1.091538\n",
            "accuracy: 0.676270\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.480484\n",
            "eval accuracy: 0.628653\n",
            "eval avg class acc: 0.608852\n",
            "--- Total running time for EPOCH 005 : 0:03:51.298573 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 1.149243\n",
            "accuracy: 0.660156\n",
            "----1-----\n",
            "mean loss: 1.126612\n",
            "accuracy: 0.654785\n",
            "----2-----\n",
            "mean loss: 1.097391\n",
            "accuracy: 0.677246\n",
            "----3-----\n",
            "mean loss: 1.057256\n",
            "accuracy: 0.688107\n",
            "----4-----\n",
            "mean loss: 1.109025\n",
            "accuracy: 0.663086\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.104587\n",
            "eval accuracy: 0.654627\n",
            "eval avg class acc: 0.597120\n",
            "--- Total running time for EPOCH 006 : 0:03:51.339631 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 1.014515\n",
            "accuracy: 0.682039\n",
            "----1-----\n",
            "mean loss: 1.045153\n",
            "accuracy: 0.691406\n",
            "----2-----\n",
            "mean loss: 1.053002\n",
            "accuracy: 0.680176\n",
            "----3-----\n",
            "mean loss: 1.011815\n",
            "accuracy: 0.698730\n",
            "----4-----\n",
            "mean loss: 1.043381\n",
            "accuracy: 0.677246\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.908930\n",
            "eval accuracy: 0.637581\n",
            "eval avg class acc: 0.605220\n",
            "--- Total running time for EPOCH 007 : 0:03:51.324902 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 0.914421\n",
            "accuracy: 0.714199\n",
            "----1-----\n",
            "mean loss: 1.172728\n",
            "accuracy: 0.664551\n",
            "----2-----\n",
            "mean loss: 1.177534\n",
            "accuracy: 0.659180\n",
            "----3-----\n",
            "mean loss: 1.028650\n",
            "accuracy: 0.688965\n",
            "----4-----\n",
            "mean loss: 0.971072\n",
            "accuracy: 0.717773\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.822135\n",
            "eval accuracy: 0.656656\n",
            "eval avg class acc: 0.612487\n",
            "--- Total running time for EPOCH 008 : 0:03:51.211458 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.890126\n",
            "accuracy: 0.726942\n",
            "----1-----\n",
            "mean loss: 0.987730\n",
            "accuracy: 0.708008\n",
            "----2-----\n",
            "mean loss: 0.938075\n",
            "accuracy: 0.708984\n",
            "----3-----\n",
            "mean loss: 0.988845\n",
            "accuracy: 0.710938\n",
            "----4-----\n",
            "mean loss: 0.942731\n",
            "accuracy: 0.721680\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.555715\n",
            "eval accuracy: 0.697240\n",
            "eval avg class acc: 0.633360\n",
            "--- Total running time for EPOCH 009 : 0:03:51.325520 ---\n",
            "--- Total running time for MAIN : 0:38:43.551617 ---\n",
            "HyperOpt batch size selected:4\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 22:02:18.590744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 22:02:18.590845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 22:02:18.590876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 22:02:18.590902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 22:02:18.591150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 4.084017\n",
            "accuracy: 0.119141\n",
            "----1-----\n",
            "mean loss: 3.460318\n",
            "accuracy: 0.125488\n",
            "----2-----\n",
            "mean loss: 3.360112\n",
            "accuracy: 0.125488\n",
            "----3-----\n",
            "mean loss: 3.400568\n",
            "accuracy: 0.132812\n",
            "----4-----\n",
            "mean loss: 3.357373\n",
            "accuracy: 0.125607\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 5.446400\n",
            "eval accuracy: 0.151540\n",
            "eval avg class acc: 0.093500\n",
            "--- Total running time for EPOCH 000 : 0:04:33.364079 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 3.356095\n",
            "accuracy: 0.139160\n",
            "----1-----\n",
            "mean loss: 3.251791\n",
            "accuracy: 0.146484\n",
            "----2-----\n",
            "mean loss: 3.017892\n",
            "accuracy: 0.184082\n",
            "----3-----\n",
            "mean loss: 3.004321\n",
            "accuracy: 0.194782\n",
            "----4-----\n",
            "mean loss: 2.847860\n",
            "accuracy: 0.212402\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.358579\n",
            "eval accuracy: 0.324554\n",
            "eval avg class acc: 0.227326\n",
            "--- Total running time for EPOCH 001 : 0:04:30.875705 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 2.643546\n",
            "accuracy: 0.257812\n",
            "----1-----\n",
            "mean loss: 2.561662\n",
            "accuracy: 0.288086\n",
            "----2-----\n",
            "mean loss: 2.432944\n",
            "accuracy: 0.303711\n",
            "----3-----\n",
            "mean loss: 2.316680\n",
            "accuracy: 0.355957\n",
            "----4-----\n",
            "mean loss: 2.290223\n",
            "accuracy: 0.338592\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 4.860765\n",
            "eval accuracy: 0.399109\n",
            "eval avg class acc: 0.308064\n",
            "--- Total running time for EPOCH 002 : 0:04:30.697618 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 2.251148\n",
            "accuracy: 0.368652\n",
            "----1-----\n",
            "mean loss: 2.227541\n",
            "accuracy: 0.374023\n",
            "----2-----\n",
            "mean loss: 2.071600\n",
            "accuracy: 0.395024\n",
            "----3-----\n",
            "mean loss: 2.065583\n",
            "accuracy: 0.407227\n",
            "----4-----\n",
            "mean loss: 1.961290\n",
            "accuracy: 0.428223\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 6.726227\n",
            "eval accuracy: 0.404781\n",
            "eval avg class acc: 0.338221\n",
            "--- Total running time for EPOCH 003 : 0:04:30.882412 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 1.911617\n",
            "accuracy: 0.441895\n",
            "----1-----\n",
            "mean loss: 1.998219\n",
            "accuracy: 0.427246\n",
            "----2-----\n",
            "mean loss: 1.847455\n",
            "accuracy: 0.459961\n",
            "----3-----\n",
            "mean loss: 1.816850\n",
            "accuracy: 0.469238\n",
            "----4-----\n",
            "mean loss: 1.811376\n",
            "accuracy: 0.473908\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.841743\n",
            "eval accuracy: 0.530794\n",
            "eval avg class acc: 0.458122\n",
            "--- Total running time for EPOCH 004 : 0:04:30.756730 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 1.731840\n",
            "accuracy: 0.501953\n",
            "----1-----\n",
            "mean loss: 1.816268\n",
            "accuracy: 0.467773\n",
            "----2-----\n",
            "mean loss: 1.807765\n",
            "accuracy: 0.463592\n",
            "----3-----\n",
            "mean loss: 1.798969\n",
            "accuracy: 0.477539\n",
            "----4-----\n",
            "mean loss: 1.816447\n",
            "accuracy: 0.471191\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 12.618730\n",
            "eval accuracy: 0.451378\n",
            "eval avg class acc: 0.392384\n",
            "--- Total running time for EPOCH 005 : 0:04:30.656433 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 1.677681\n",
            "accuracy: 0.520631\n",
            "----1-----\n",
            "mean loss: 1.762013\n",
            "accuracy: 0.481445\n",
            "----2-----\n",
            "mean loss: 1.641484\n",
            "accuracy: 0.522949\n",
            "----3-----\n",
            "mean loss: 1.666408\n",
            "accuracy: 0.530762\n",
            "----4-----\n",
            "mean loss: 1.620887\n",
            "accuracy: 0.513672\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 7.653889\n",
            "eval accuracy: 0.483387\n",
            "eval avg class acc: 0.439767\n",
            "--- Total running time for EPOCH 006 : 0:04:30.695882 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 1.663894\n",
            "accuracy: 0.502930\n",
            "----1-----\n",
            "mean loss: 1.585370\n",
            "accuracy: 0.541992\n",
            "----2-----\n",
            "mean loss: 1.646046\n",
            "accuracy: 0.519531\n",
            "----3-----\n",
            "mean loss: 1.681041\n",
            "accuracy: 0.518811\n",
            "----4-----\n",
            "mean loss: 1.625218\n",
            "accuracy: 0.521484\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 12.484299\n",
            "eval accuracy: 0.534036\n",
            "eval avg class acc: 0.464134\n",
            "--- Total running time for EPOCH 007 : 0:04:30.688496 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 1.554268\n",
            "accuracy: 0.557129\n",
            "----1-----\n",
            "mean loss: 1.553447\n",
            "accuracy: 0.556152\n",
            "----2-----\n",
            "mean loss: 1.572508\n",
            "accuracy: 0.527344\n",
            "----3-----\n",
            "mean loss: 1.465289\n",
            "accuracy: 0.566141\n",
            "----4-----\n",
            "mean loss: 1.506214\n",
            "accuracy: 0.573730\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.411883\n",
            "eval accuracy: 0.633712\n",
            "eval avg class acc: 0.578262\n",
            "--- Total running time for EPOCH 008 : 0:04:30.586140 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 1.528886\n",
            "accuracy: 0.556641\n",
            "----1-----\n",
            "mean loss: 1.459545\n",
            "accuracy: 0.589844\n",
            "----2-----\n",
            "mean loss: 1.413530\n",
            "accuracy: 0.587379\n",
            "----3-----\n",
            "mean loss: 1.474291\n",
            "accuracy: 0.586426\n",
            "----4-----\n",
            "mean loss: 1.458831\n",
            "accuracy: 0.574707\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 4.470421\n",
            "eval accuracy: 0.535656\n",
            "eval avg class acc: 0.472372\n",
            "--- Total running time for EPOCH 009 : 0:04:30.749376 ---\n",
            "--- Total running time for MAIN : 0:45:17.790198 ---\n",
            "HyperOpt batch size selected:8\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 22:47:36.548320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 22:47:36.548417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 22:47:36.548448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 22:47:36.548470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 22:47:36.548739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.908330\n",
            "accuracy: 0.134766\n",
            "----1-----\n",
            "mean loss: 3.288481\n",
            "accuracy: 0.174805\n",
            "----2-----\n",
            "mean loss: 2.987087\n",
            "accuracy: 0.214355\n",
            "----3-----\n",
            "mean loss: 2.780515\n",
            "accuracy: 0.254395\n",
            "----4-----\n",
            "mean loss: 2.611248\n",
            "accuracy: 0.279733\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.205921\n",
            "eval accuracy: 0.385146\n",
            "eval avg class acc: 0.304851\n",
            "--- Total running time for EPOCH 000 : 0:03:53.701264 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 2.419268\n",
            "accuracy: 0.312988\n",
            "----1-----\n",
            "mean loss: 2.344090\n",
            "accuracy: 0.335938\n",
            "----2-----\n",
            "mean loss: 2.215702\n",
            "accuracy: 0.363281\n",
            "----3-----\n",
            "mean loss: 2.174194\n",
            "accuracy: 0.368932\n",
            "----4-----\n",
            "mean loss: 2.075127\n",
            "accuracy: 0.382812\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.660634\n",
            "eval accuracy: 0.478896\n",
            "eval avg class acc: 0.406117\n",
            "--- Total running time for EPOCH 001 : 0:03:51.425955 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.913663\n",
            "accuracy: 0.448730\n",
            "----1-----\n",
            "mean loss: 1.865987\n",
            "accuracy: 0.442961\n",
            "----2-----\n",
            "mean loss: 1.786158\n",
            "accuracy: 0.472656\n",
            "----3-----\n",
            "mean loss: 1.637969\n",
            "accuracy: 0.502441\n",
            "----4-----\n",
            "mean loss: 1.577591\n",
            "accuracy: 0.527344\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.513141\n",
            "eval accuracy: 0.535308\n",
            "eval avg class acc: 0.468985\n",
            "--- Total running time for EPOCH 002 : 0:03:51.530107 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.539330\n",
            "accuracy: 0.529785\n",
            "----1-----\n",
            "mean loss: 1.572802\n",
            "accuracy: 0.529733\n",
            "----2-----\n",
            "mean loss: 1.523362\n",
            "accuracy: 0.543945\n",
            "----3-----\n",
            "mean loss: 1.403107\n",
            "accuracy: 0.588379\n",
            "----4-----\n",
            "mean loss: 1.414111\n",
            "accuracy: 0.586426\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.308671\n",
            "eval accuracy: 0.610795\n",
            "eval avg class acc: 0.520672\n",
            "--- Total running time for EPOCH 003 : 0:03:51.442794 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 1.393803\n",
            "accuracy: 0.588867\n",
            "----1-----\n",
            "mean loss: 1.281812\n",
            "accuracy: 0.613471\n",
            "----2-----\n",
            "mean loss: 1.344700\n",
            "accuracy: 0.595703\n",
            "----3-----\n",
            "mean loss: 1.275974\n",
            "accuracy: 0.627441\n",
            "----4-----\n",
            "mean loss: 1.277188\n",
            "accuracy: 0.623047\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.042070\n",
            "eval accuracy: 0.652597\n",
            "eval avg class acc: 0.580269\n",
            "--- Total running time for EPOCH 004 : 0:03:51.382259 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 1.286331\n",
            "accuracy: 0.616211\n",
            "----1-----\n",
            "mean loss: 1.220402\n",
            "accuracy: 0.643066\n",
            "----2-----\n",
            "mean loss: 1.213308\n",
            "accuracy: 0.652344\n",
            "----3-----\n",
            "mean loss: 1.325737\n",
            "accuracy: 0.601335\n",
            "----4-----\n",
            "mean loss: 1.240948\n",
            "accuracy: 0.631348\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.065912\n",
            "eval accuracy: 0.671672\n",
            "eval avg class acc: 0.600838\n",
            "--- Total running time for EPOCH 005 : 0:03:51.239907 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 1.074361\n",
            "accuracy: 0.682646\n",
            "----1-----\n",
            "mean loss: 1.185868\n",
            "accuracy: 0.658691\n",
            "----2-----\n",
            "mean loss: 1.175991\n",
            "accuracy: 0.647949\n",
            "----3-----\n",
            "mean loss: 1.262635\n",
            "accuracy: 0.635254\n",
            "----4-----\n",
            "mean loss: 1.225818\n",
            "accuracy: 0.628418\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.976312\n",
            "eval accuracy: 0.724838\n",
            "eval avg class acc: 0.680283\n",
            "--- Total running time for EPOCH 006 : 0:03:51.320991 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 1.139737\n",
            "accuracy: 0.653809\n",
            "----1-----\n",
            "mean loss: 1.049860\n",
            "accuracy: 0.695801\n",
            "----2-----\n",
            "mean loss: 1.114125\n",
            "accuracy: 0.672852\n",
            "----3-----\n",
            "mean loss: 0.968478\n",
            "accuracy: 0.703277\n",
            "----4-----\n",
            "mean loss: 1.062401\n",
            "accuracy: 0.683105\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.000232\n",
            "eval accuracy: 0.728896\n",
            "eval avg class acc: 0.658379\n",
            "--- Total running time for EPOCH 007 : 0:03:51.343800 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 1.020814\n",
            "accuracy: 0.701660\n",
            "----1-----\n",
            "mean loss: 0.951231\n",
            "accuracy: 0.706917\n",
            "----2-----\n",
            "mean loss: 1.002872\n",
            "accuracy: 0.691895\n",
            "----3-----\n",
            "mean loss: 0.985170\n",
            "accuracy: 0.693359\n",
            "----4-----\n",
            "mean loss: 0.981712\n",
            "accuracy: 0.701172\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.853854\n",
            "eval accuracy: 0.741071\n",
            "eval avg class acc: 0.698317\n",
            "--- Total running time for EPOCH 008 : 0:03:51.488070 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.951521\n",
            "accuracy: 0.708984\n",
            "----1-----\n",
            "mean loss: 0.992714\n",
            "accuracy: 0.702637\n",
            "----2-----\n",
            "mean loss: 0.976903\n",
            "accuracy: 0.712891\n",
            "----3-----\n",
            "mean loss: 1.108546\n",
            "accuracy: 0.674316\n",
            "----4-----\n",
            "mean loss: 0.977718\n",
            "accuracy: 0.700850\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.975568\n",
            "eval accuracy: 0.676136\n",
            "eval avg class acc: 0.614320\n",
            "--- Total running time for EPOCH 009 : 0:03:51.444238 ---\n",
            "--- Total running time for MAIN : 0:38:44.239998 ---\n",
            "HyperOpt batch size selected:8\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-06 23:26:20.805532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-06 23:26:20.805635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-06 23:26:20.805666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-06 23:26:20.805688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-06 23:26:20.805981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 4.071973\n",
            "accuracy: 0.120146\n",
            "----1-----\n",
            "mean loss: 3.250893\n",
            "accuracy: 0.193848\n",
            "----2-----\n",
            "mean loss: 3.027577\n",
            "accuracy: 0.208984\n",
            "----3-----\n",
            "mean loss: 2.818575\n",
            "accuracy: 0.237793\n",
            "----4-----\n",
            "mean loss: 2.744401\n",
            "accuracy: 0.244629\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.442698\n",
            "eval accuracy: 0.327516\n",
            "eval avg class acc: 0.243191\n",
            "--- Total running time for EPOCH 000 : 0:03:53.853821 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 2.427072\n",
            "accuracy: 0.321289\n",
            "----1-----\n",
            "mean loss: 2.245656\n",
            "accuracy: 0.349609\n",
            "----2-----\n",
            "mean loss: 2.267373\n",
            "accuracy: 0.354004\n",
            "----3-----\n",
            "mean loss: 2.097192\n",
            "accuracy: 0.389648\n",
            "----4-----\n",
            "mean loss: 1.980694\n",
            "accuracy: 0.424150\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.227852\n",
            "eval accuracy: 0.446429\n",
            "eval avg class acc: 0.346942\n",
            "--- Total running time for EPOCH 001 : 0:03:51.525218 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.946209\n",
            "accuracy: 0.435547\n",
            "----1-----\n",
            "mean loss: 1.796407\n",
            "accuracy: 0.466797\n",
            "----2-----\n",
            "mean loss: 1.657306\n",
            "accuracy: 0.514648\n",
            "----3-----\n",
            "mean loss: 1.663076\n",
            "accuracy: 0.494539\n",
            "----4-----\n",
            "mean loss: 1.629767\n",
            "accuracy: 0.516602\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.397417\n",
            "eval accuracy: 0.571834\n",
            "eval avg class acc: 0.520013\n",
            "--- Total running time for EPOCH 002 : 0:03:51.441746 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.604341\n",
            "accuracy: 0.529297\n",
            "----1-----\n",
            "mean loss: 1.475281\n",
            "accuracy: 0.547330\n",
            "----2-----\n",
            "mean loss: 1.453225\n",
            "accuracy: 0.556641\n",
            "----3-----\n",
            "mean loss: 1.414195\n",
            "accuracy: 0.582031\n",
            "----4-----\n",
            "mean loss: 1.427392\n",
            "accuracy: 0.583496\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.159363\n",
            "eval accuracy: 0.640422\n",
            "eval avg class acc: 0.563433\n",
            "--- Total running time for EPOCH 003 : 0:03:51.435728 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 1.371193\n",
            "accuracy: 0.598633\n",
            "----1-----\n",
            "mean loss: 1.376320\n",
            "accuracy: 0.583496\n",
            "----2-----\n",
            "mean loss: 1.288625\n",
            "accuracy: 0.621582\n",
            "----3-----\n",
            "mean loss: 1.298503\n",
            "accuracy: 0.609863\n",
            "----4-----\n",
            "mean loss: 1.254314\n",
            "accuracy: 0.617718\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.168429\n",
            "eval accuracy: 0.655032\n",
            "eval avg class acc: 0.578672\n",
            "--- Total running time for EPOCH 004 : 0:03:51.445723 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 1.249991\n",
            "accuracy: 0.615723\n",
            "----1-----\n",
            "mean loss: 1.269200\n",
            "accuracy: 0.621582\n",
            "----2-----\n",
            "mean loss: 1.186300\n",
            "accuracy: 0.631836\n",
            "----3-----\n",
            "mean loss: 1.151492\n",
            "accuracy: 0.636529\n",
            "----4-----\n",
            "mean loss: 1.138416\n",
            "accuracy: 0.658691\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.951941\n",
            "eval accuracy: 0.712662\n",
            "eval avg class acc: 0.631964\n",
            "--- Total running time for EPOCH 005 : 0:03:51.439333 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 1.255206\n",
            "accuracy: 0.633789\n",
            "----1-----\n",
            "mean loss: 1.174782\n",
            "accuracy: 0.651855\n",
            "----2-----\n",
            "mean loss: 1.174863\n",
            "accuracy: 0.648438\n",
            "----3-----\n",
            "mean loss: 1.064227\n",
            "accuracy: 0.687012\n",
            "----4-----\n",
            "mean loss: 1.075659\n",
            "accuracy: 0.668083\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.163545\n",
            "eval accuracy: 0.676948\n",
            "eval avg class acc: 0.610544\n",
            "--- Total running time for EPOCH 006 : 0:03:51.267026 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 1.130088\n",
            "accuracy: 0.655762\n",
            "----1-----\n",
            "mean loss: 1.068708\n",
            "accuracy: 0.687500\n",
            "----2-----\n",
            "mean loss: 1.028850\n",
            "accuracy: 0.686286\n",
            "----3-----\n",
            "mean loss: 1.082859\n",
            "accuracy: 0.682129\n",
            "----4-----\n",
            "mean loss: 1.055119\n",
            "accuracy: 0.678711\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.885610\n",
            "eval accuracy: 0.727679\n",
            "eval avg class acc: 0.665144\n",
            "--- Total running time for EPOCH 007 : 0:03:51.275341 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 1.016776\n",
            "accuracy: 0.692871\n",
            "----1-----\n",
            "mean loss: 1.014379\n",
            "accuracy: 0.699707\n",
            "----2-----\n",
            "mean loss: 0.975982\n",
            "accuracy: 0.698422\n",
            "----3-----\n",
            "mean loss: 1.026298\n",
            "accuracy: 0.695801\n",
            "----4-----\n",
            "mean loss: 0.926650\n",
            "accuracy: 0.721680\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.843795\n",
            "eval accuracy: 0.734578\n",
            "eval avg class acc: 0.679982\n",
            "--- Total running time for EPOCH 008 : 0:03:51.344325 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.975370\n",
            "accuracy: 0.703613\n",
            "----1-----\n",
            "mean loss: 0.969392\n",
            "accuracy: 0.711914\n",
            "----2-----\n",
            "mean loss: 0.981764\n",
            "accuracy: 0.699219\n",
            "----3-----\n",
            "mean loss: 0.941439\n",
            "accuracy: 0.717285\n",
            "----4-----\n",
            "mean loss: 0.892140\n",
            "accuracy: 0.729369\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.762808\n",
            "eval accuracy: 0.771916\n",
            "eval avg class acc: 0.717410\n",
            "--- Total running time for EPOCH 009 : 0:03:51.433144 ---\n",
            "--- Total running time for MAIN : 0:38:44.434486 ---\n",
            "HyperOpt batch size selected:32\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-07 00:05:05.280915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-07 00:05:05.281004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-07 00:05:05.281035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-07 00:05:05.281065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-07 00:05:05.281353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.810567\n",
            "accuracy: 0.209961\n",
            "----1-----\n",
            "mean loss: 2.758910\n",
            "accuracy: 0.325684\n",
            "----2-----\n",
            "mean loss: 2.321770\n",
            "accuracy: 0.398438\n",
            "----3-----\n",
            "mean loss: 2.010673\n",
            "accuracy: 0.467773\n",
            "----4-----\n",
            "mean loss: 1.841682\n",
            "accuracy: 0.488358\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 2.144466\n",
            "eval accuracy: 0.431818\n",
            "eval avg class acc: 0.357089\n",
            "--- Total running time for EPOCH 000 : 0:03:39.410320 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 1.857961\n",
            "accuracy: 0.492676\n",
            "----1-----\n",
            "mean loss: 1.673812\n",
            "accuracy: 0.537109\n",
            "----2-----\n",
            "mean loss: 1.515651\n",
            "accuracy: 0.574707\n",
            "----3-----\n",
            "mean loss: 1.433587\n",
            "accuracy: 0.585449\n",
            "----4-----\n",
            "mean loss: 1.283118\n",
            "accuracy: 0.608456\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.178728\n",
            "eval accuracy: 0.650974\n",
            "eval avg class acc: 0.571506\n",
            "--- Total running time for EPOCH 001 : 0:03:37.009407 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.314968\n",
            "accuracy: 0.613281\n",
            "----1-----\n",
            "mean loss: 1.414278\n",
            "accuracy: 0.591797\n",
            "----2-----\n",
            "mean loss: 1.391987\n",
            "accuracy: 0.591797\n",
            "----3-----\n",
            "mean loss: 1.213036\n",
            "accuracy: 0.636230\n",
            "----4-----\n",
            "mean loss: 1.143488\n",
            "accuracy: 0.673407\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.268443\n",
            "eval accuracy: 0.630682\n",
            "eval avg class acc: 0.547678\n",
            "--- Total running time for EPOCH 002 : 0:03:37.020418 ---\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.086472\n",
            "accuracy: 0.674632\n",
            "----1-----\n",
            "mean loss: 1.081857\n",
            "accuracy: 0.675293\n",
            "----2-----\n",
            "mean loss: 1.063477\n",
            "accuracy: 0.688477\n",
            "----3-----\n",
            "mean loss: 1.093061\n",
            "accuracy: 0.666992\n",
            "----4-----\n",
            "mean loss: 1.101327\n",
            "accuracy: 0.675293\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.032751\n",
            "eval accuracy: 0.693994\n",
            "eval avg class acc: 0.645370\n",
            "--- Total running time for EPOCH 003 : 0:03:37.037404 ---\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 0.995514\n",
            "accuracy: 0.697754\n",
            "----1-----\n",
            "mean loss: 1.017909\n",
            "accuracy: 0.695801\n",
            "----2-----\n",
            "mean loss: 0.980957\n",
            "accuracy: 0.709473\n",
            "----3-----\n",
            "mean loss: 0.942082\n",
            "accuracy: 0.719238\n",
            "----4-----\n",
            "mean loss: 0.908388\n",
            "accuracy: 0.708946\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.893087\n",
            "eval accuracy: 0.732143\n",
            "eval avg class acc: 0.655258\n",
            "--- Total running time for EPOCH 004 : 0:03:37.012622 ---\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 1.017830\n",
            "accuracy: 0.697266\n",
            "----1-----\n",
            "mean loss: 0.964725\n",
            "accuracy: 0.712891\n",
            "----2-----\n",
            "mean loss: 0.941585\n",
            "accuracy: 0.708946\n",
            "----3-----\n",
            "mean loss: 0.959626\n",
            "accuracy: 0.709961\n",
            "----4-----\n",
            "mean loss: 1.030746\n",
            "accuracy: 0.687500\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.920144\n",
            "eval accuracy: 0.714692\n",
            "eval avg class acc: 0.652621\n",
            "--- Total running time for EPOCH 005 : 0:03:37.020027 ---\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 0.895197\n",
            "accuracy: 0.728027\n",
            "----1-----\n",
            "mean loss: 0.874169\n",
            "accuracy: 0.731445\n",
            "----2-----\n",
            "mean loss: 0.793728\n",
            "accuracy: 0.764706\n",
            "----3-----\n",
            "mean loss: 0.861258\n",
            "accuracy: 0.736328\n",
            "----4-----\n",
            "mean loss: 0.875589\n",
            "accuracy: 0.733398\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.777822\n",
            "eval accuracy: 0.764205\n",
            "eval avg class acc: 0.689648\n",
            "--- Total running time for EPOCH 006 : 0:03:36.969642 ---\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 0.791008\n",
            "accuracy: 0.763184\n",
            "----1-----\n",
            "mean loss: 0.843923\n",
            "accuracy: 0.747070\n",
            "----2-----\n",
            "mean loss: 0.776146\n",
            "accuracy: 0.766544\n",
            "----3-----\n",
            "mean loss: 0.818972\n",
            "accuracy: 0.755371\n",
            "----4-----\n",
            "mean loss: 0.788912\n",
            "accuracy: 0.753418\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.724441\n",
            "eval accuracy: 0.790584\n",
            "eval avg class acc: 0.712554\n",
            "--- Total running time for EPOCH 007 : 0:03:36.940580 ---\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 0.715068\n",
            "accuracy: 0.773926\n",
            "----1-----\n",
            "mean loss: 0.834503\n",
            "accuracy: 0.741699\n",
            "----2-----\n",
            "mean loss: 0.806678\n",
            "accuracy: 0.756348\n",
            "----3-----\n",
            "mean loss: 0.772015\n",
            "accuracy: 0.771484\n",
            "----4-----\n",
            "mean loss: 0.754732\n",
            "accuracy: 0.770221\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.751151\n",
            "eval accuracy: 0.765828\n",
            "eval avg class acc: 0.715934\n",
            "--- Total running time for EPOCH 008 : 0:03:37.056838 ---\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.665899\n",
            "accuracy: 0.780637\n",
            "----1-----\n",
            "mean loss: 0.767349\n",
            "accuracy: 0.759766\n",
            "----2-----\n",
            "mean loss: 0.752340\n",
            "accuracy: 0.767578\n",
            "----3-----\n",
            "mean loss: 0.740873\n",
            "accuracy: 0.778320\n",
            "----4-----\n",
            "mean loss: 0.706100\n",
            "accuracy: 0.776367\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.677357\n",
            "eval accuracy: 0.808036\n",
            "eval avg class acc: 0.744266\n",
            "--- Total running time for EPOCH 009 : 0:03:37.053585 ---\n",
            "--- Total running time for MAIN : 0:36:20.602552 ---\n",
            "HyperOpt batch size selected:4\n",
            "is_training_placeholder:Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "2018-11-07 00:41:25.781691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-07 00:41:25.781810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-07 00:41:25.781842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-07 00:41:25.781870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-07 00:41:25.782126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 4.208008\n",
            "accuracy: 0.098301\n",
            "----1-----\n",
            "mean loss: 3.615741\n",
            "accuracy: 0.105957\n",
            "----2-----\n",
            "mean loss: 3.485306\n",
            "accuracy: 0.127930\n",
            "----3-----\n",
            "mean loss: 3.288917\n",
            "accuracy: 0.128906\n",
            "----4-----\n",
            "mean loss: 3.226600\n",
            "accuracy: 0.131836\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 3.234881\n",
            "eval accuracy: 0.134117\n",
            "eval avg class acc: 0.083198\n",
            "--- Total running time for EPOCH 000 : 0:04:33.409393 ---\n",
            "Model saved in file: log/hyperopttiny/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 3.079912\n",
            "accuracy: 0.155273\n",
            "----1-----\n",
            "mean loss: 3.082801\n",
            "accuracy: 0.169903\n",
            "----2-----\n",
            "mean loss: 2.946632\n",
            "accuracy: 0.182617\n",
            "----3-----\n",
            "mean loss: 2.886498\n",
            "accuracy: 0.211426\n",
            "----4-----\n",
            "mean loss: 2.833521\n",
            "accuracy: 0.210938\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 3.058515\n",
            "eval accuracy: 0.196921\n",
            "eval avg class acc: 0.145663\n",
            "--- Total running time for EPOCH 001 : 0:04:31.056112 ---\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 2.727007\n",
            "accuracy: 0.244629\n",
            "----1-----\n",
            "mean loss: 2.667639\n",
            "accuracy: 0.250488\n",
            "----2-----\n",
            "mean loss: 2.489354\n",
            "accuracy: 0.291262\n",
            "----3-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5-2X59hAEUKD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "fAakEKduAND5",
        "colab_type": "code",
        "outputId": "1194e352-a443-4ac6-f1a7-0616a71d1681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet00/')\n",
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/')\n",
        "\n",
        "!python evaluate.py \n",
        "#--model_path=\"log/normal5/model.ckpt\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
            "2018-11-07 14:28:58.561810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-07 14:28:58.562293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-11-07 14:28:58.562338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-07 14:28:58.996271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-07 14:28:58.996338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-07 14:28:58.996363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-07 14:28:58.996697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "2018-11-07 14:28:58.997345: I tensorflow/core/common_runtime/direct_session.cc:307] Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"evaluate.py\", line 170, in <module>\n",
            "    evaluate(num_votes=1)\n",
            "  File \"evaluate.py\", line 79, in evaluate\n",
            "    saver.restore(sess, MODEL_PATH)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1538, in restore\n",
            "    + compat.as_text(save_path))\n",
            "ValueError: The passed save_path is not a valid checkpoint: log/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uDaM9jejpevv"
      },
      "cell_type": "markdown",
      "source": [
        "## Running tensorboard with the pointnet result\n",
        "https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/"
      ]
    },
    {
      "metadata": {
        "id": "8zMJyoXTI8Yp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "str = \"\"\n",
        "if str:\n",
        "  print (\"not empty\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "2081441d-a2d1-4953-bf60-363fac76be2f",
        "id": "Q1HvTklVpevy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-05 15:50:27--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.203.66.95, 52.202.60.111, 52.203.102.189, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.203.66.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  3.33MB/s    in 1.5s    \n",
            "\n",
            "2018-11-05 15:50:29 (3.33 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Lk5LgRFxpev9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet')\n",
        "\n",
        "LOG_DIR = './log/11'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1mDHS17MpewG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "00e1dfd2-e496-4298-d974-5eb356e84fed",
        "id": "YHCb450npewN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n",
            "    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bFEMdCnvEXir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running pointnet 2"
      ]
    },
    {
      "metadata": {
        "id": "SoYtZ-4BbeCN",
        "colab_type": "code",
        "outputId": "0956df5a-6d3d-4944-a88d-2d30affb0754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/tf_ops/sampling')\n",
        "!bash tf_sampling_compile.sh"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Ktf_sampling.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:20:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(0), 2, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:22:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(1), 2, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:34:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(0), 3, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:47:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(0), 3, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:49:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(1), 2, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pf9cvqQx2bik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "4c5dfc88-2893-41a5-deee-697d63212d2a"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/tf_ops/grouping')\n",
        "!bash tf_grouping_compile.sh"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Ktf_grouping.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_grouping.cpp:22:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(1), 3, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_grouping.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_grouping.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_grouping.cpp:47:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(0), 3, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_grouping.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_grouping.cpp:49:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(1), 3, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_grouping.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q3lp-iSx2ofl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "645463a4-098b-4cdc-f490-d59a4286a342"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/tf_ops/3d_interpolation')\n",
        "!bash tf_interpolate_compile.sh"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Ktf_interpolate.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_interpolate.cpp:29:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(0), 3, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_interpolate.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_interpolate.cpp:31:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(1), 3, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_interpolate.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "soaNJhOtEZud",
        "colab_type": "code",
        "outputId": "8e5e7333-a127-422a-e213-ce3abd6c0130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178569
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2')\n",
        "\n",
        "!python train.py #--gpu 0 # train_multi_gpu.py #--num_gpu=8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pid: 320\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/utils/pointnet_util.py:127: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "--- Get training operator\n",
            "2018-10-30 16:59:42.507595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-30 16:59:42.508064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-10-30 16:59:42.508105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-10-30 16:59:42.939796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-30 16:59:42.939888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-10-30 16:59:42.939914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-10-30 16:59:42.940283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "2018-10-30 16:59:44.181492\n",
            " ---- batch: 050 ----\n",
            "mean loss: 3.526222\n",
            "accuracy: 0.156250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 2.881351\n",
            "accuracy: 0.263750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 2.635329\n",
            "accuracy: 0.323750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 2.402624\n",
            "accuracy: 0.385000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 2.061759\n",
            "accuracy: 0.456250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 2.022208\n",
            "accuracy: 0.482500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 1.817767\n",
            "accuracy: 0.500000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 1.674554\n",
            "accuracy: 0.526250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 1.661777\n",
            "accuracy: 0.530000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 1.644472\n",
            "accuracy: 0.553750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 1.616432\n",
            "accuracy: 0.563750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 1.623406\n",
            "accuracy: 0.523750\n",
            "2018-10-30 17:02:47.530953\n",
            "---- EPOCH 000 EVALUATION ----\n",
            "eval mean loss: 1.162858\n",
            "eval accuracy: 0.649514\n",
            "eval avg class acc: 0.566471\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "2018-10-30 17:03:03.667238\n",
            " ---- batch: 050 ----\n",
            "mean loss: 1.529040\n",
            "accuracy: 0.552500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 1.441122\n",
            "accuracy: 0.592500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 1.486175\n",
            "accuracy: 0.578750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 1.381246\n",
            "accuracy: 0.577500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 1.322556\n",
            "accuracy: 0.615000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 1.325694\n",
            "accuracy: 0.615000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 1.271106\n",
            "accuracy: 0.638750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 1.284825\n",
            "accuracy: 0.632500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 1.365452\n",
            "accuracy: 0.603750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 1.233826\n",
            "accuracy: 0.645000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 1.251806\n",
            "accuracy: 0.643750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 1.125962\n",
            "accuracy: 0.673750\n",
            "2018-10-30 17:05:47.573005\n",
            "---- EPOCH 001 EVALUATION ----\n",
            "eval mean loss: 0.959724\n",
            "eval accuracy: 0.695300\n",
            "eval avg class acc: 0.630942\n",
            "**** EPOCH 002 ****\n",
            "2018-10-30 17:05:59.881353\n",
            " ---- batch: 050 ----\n",
            "mean loss: 1.155251\n",
            "accuracy: 0.668750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 1.117961\n",
            "accuracy: 0.676250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 1.158184\n",
            "accuracy: 0.661250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 1.159428\n",
            "accuracy: 0.652500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 1.040428\n",
            "accuracy: 0.703750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 1.159099\n",
            "accuracy: 0.686250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 1.119702\n",
            "accuracy: 0.667500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 1.019763\n",
            "accuracy: 0.688750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 1.040653\n",
            "accuracy: 0.682500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 1.058460\n",
            "accuracy: 0.711250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 1.061521\n",
            "accuracy: 0.671250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 1.241896\n",
            "accuracy: 0.638750\n",
            "2018-10-30 17:08:43.654814\n",
            "---- EPOCH 002 EVALUATION ----\n",
            "eval mean loss: 0.830632\n",
            "eval accuracy: 0.742707\n",
            "eval avg class acc: 0.683866\n",
            "**** EPOCH 003 ****\n",
            "2018-10-30 17:08:55.931568\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.988675\n",
            "accuracy: 0.715000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 1.057863\n",
            "accuracy: 0.698750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.979156\n",
            "accuracy: 0.698750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 1.018346\n",
            "accuracy: 0.692500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 1.045654\n",
            "accuracy: 0.713750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.974202\n",
            "accuracy: 0.706250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 1.032078\n",
            "accuracy: 0.701250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.875424\n",
            "accuracy: 0.731250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.975875\n",
            "accuracy: 0.701250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.856395\n",
            "accuracy: 0.743750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.873597\n",
            "accuracy: 0.741250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 1.030931\n",
            "accuracy: 0.683750\n",
            "2018-10-30 17:11:39.869129\n",
            "---- EPOCH 003 EVALUATION ----\n",
            "eval mean loss: 0.723140\n",
            "eval accuracy: 0.775932\n",
            "eval avg class acc: 0.724134\n",
            "**** EPOCH 004 ****\n",
            "2018-10-30 17:11:52.161703\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.916760\n",
            "accuracy: 0.730000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.950191\n",
            "accuracy: 0.711250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.871361\n",
            "accuracy: 0.735000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.901506\n",
            "accuracy: 0.727500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.824355\n",
            "accuracy: 0.745000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.885923\n",
            "accuracy: 0.728750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.956400\n",
            "accuracy: 0.731250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.945508\n",
            "accuracy: 0.715000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.910349\n",
            "accuracy: 0.718750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.901794\n",
            "accuracy: 0.731250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.889757\n",
            "accuracy: 0.718750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.901789\n",
            "accuracy: 0.718750\n",
            "2018-10-30 17:14:36.116356\n",
            "---- EPOCH 004 EVALUATION ----\n",
            "eval mean loss: 0.657637\n",
            "eval accuracy: 0.792545\n",
            "eval avg class acc: 0.735930\n",
            "**** EPOCH 005 ****\n",
            "2018-10-30 17:14:48.445741\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.870826\n",
            "accuracy: 0.726250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.903286\n",
            "accuracy: 0.733750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.821265\n",
            "accuracy: 0.743750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.800372\n",
            "accuracy: 0.736250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.782484\n",
            "accuracy: 0.743750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.884164\n",
            "accuracy: 0.733750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.876490\n",
            "accuracy: 0.732500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.824990\n",
            "accuracy: 0.738750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.940432\n",
            "accuracy: 0.741250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.905881\n",
            "accuracy: 0.712500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.801001\n",
            "accuracy: 0.777500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.818463\n",
            "accuracy: 0.737500\n",
            "2018-10-30 17:17:32.211284\n",
            "---- EPOCH 005 EVALUATION ----\n",
            "eval mean loss: 0.605685\n",
            "eval accuracy: 0.811183\n",
            "eval avg class acc: 0.745965\n",
            "**** EPOCH 006 ****\n",
            "2018-10-30 17:17:44.555032\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.765442\n",
            "accuracy: 0.773750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.705790\n",
            "accuracy: 0.763750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.778964\n",
            "accuracy: 0.758750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.838081\n",
            "accuracy: 0.736250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.839897\n",
            "accuracy: 0.745000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.728802\n",
            "accuracy: 0.753750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.823694\n",
            "accuracy: 0.746250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.805285\n",
            "accuracy: 0.758750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.822490\n",
            "accuracy: 0.743750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.831680\n",
            "accuracy: 0.733750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.857636\n",
            "accuracy: 0.735000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.799004\n",
            "accuracy: 0.750000\n",
            "2018-10-30 17:20:28.447713\n",
            "---- EPOCH 006 EVALUATION ----\n",
            "eval mean loss: 0.549487\n",
            "eval accuracy: 0.828606\n",
            "eval avg class acc: 0.774930\n",
            "**** EPOCH 007 ****\n",
            "2018-10-30 17:20:40.754648\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.824554\n",
            "accuracy: 0.750000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.678391\n",
            "accuracy: 0.775000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.723267\n",
            "accuracy: 0.781250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.711950\n",
            "accuracy: 0.793750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.746383\n",
            "accuracy: 0.776250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.807238\n",
            "accuracy: 0.742500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.727911\n",
            "accuracy: 0.768750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.819473\n",
            "accuracy: 0.765000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.694419\n",
            "accuracy: 0.788750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.685732\n",
            "accuracy: 0.783750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.757301\n",
            "accuracy: 0.770000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.752059\n",
            "accuracy: 0.781250\n",
            "2018-10-30 17:23:24.654208\n",
            "---- EPOCH 007 EVALUATION ----\n",
            "eval mean loss: 0.599749\n",
            "eval accuracy: 0.814830\n",
            "eval avg class acc: 0.773843\n",
            "**** EPOCH 008 ****\n",
            "2018-10-30 17:23:36.957781\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.677188\n",
            "accuracy: 0.798750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.724923\n",
            "accuracy: 0.768750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.749222\n",
            "accuracy: 0.767500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.823706\n",
            "accuracy: 0.762500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.708381\n",
            "accuracy: 0.765000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.751283\n",
            "accuracy: 0.772500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.682444\n",
            "accuracy: 0.772500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.665088\n",
            "accuracy: 0.792500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.688687\n",
            "accuracy: 0.775000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.669455\n",
            "accuracy: 0.787500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.710579\n",
            "accuracy: 0.792500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.717410\n",
            "accuracy: 0.767500\n",
            "2018-10-30 17:26:20.858215\n",
            "---- EPOCH 008 EVALUATION ----\n",
            "eval mean loss: 0.491309\n",
            "eval accuracy: 0.845219\n",
            "eval avg class acc: 0.788535\n",
            "**** EPOCH 009 ****\n",
            "2018-10-30 17:26:33.187243\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.666337\n",
            "accuracy: 0.810000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.697858\n",
            "accuracy: 0.796250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.674360\n",
            "accuracy: 0.801250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.687743\n",
            "accuracy: 0.776250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.803262\n",
            "accuracy: 0.756250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.673455\n",
            "accuracy: 0.786250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.738658\n",
            "accuracy: 0.777500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.711031\n",
            "accuracy: 0.776250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.662339\n",
            "accuracy: 0.796250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.769697\n",
            "accuracy: 0.763750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.633178\n",
            "accuracy: 0.792500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.705252\n",
            "accuracy: 0.793750\n",
            "2018-10-30 17:29:17.176998\n",
            "---- EPOCH 009 EVALUATION ----\n",
            "eval mean loss: 0.532429\n",
            "eval accuracy: 0.831848\n",
            "eval avg class acc: 0.775099\n",
            "**** EPOCH 010 ****\n",
            "2018-10-30 17:29:29.497064\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.650951\n",
            "accuracy: 0.796250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.673762\n",
            "accuracy: 0.783750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.671605\n",
            "accuracy: 0.783750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.663892\n",
            "accuracy: 0.801250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.721489\n",
            "accuracy: 0.773750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.708092\n",
            "accuracy: 0.776250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.672620\n",
            "accuracy: 0.786250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.669436\n",
            "accuracy: 0.791250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.655652\n",
            "accuracy: 0.776250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.642758\n",
            "accuracy: 0.812500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.622985\n",
            "accuracy: 0.802500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.651641\n",
            "accuracy: 0.797500\n",
            "2018-10-30 17:32:13.284461\n",
            "---- EPOCH 010 EVALUATION ----\n",
            "eval mean loss: 0.446233\n",
            "eval accuracy: 0.857780\n",
            "eval avg class acc: 0.794070\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 011 ****\n",
            "2018-10-30 17:32:25.968073\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.579460\n",
            "accuracy: 0.826250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.649297\n",
            "accuracy: 0.792500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.674319\n",
            "accuracy: 0.797500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.678956\n",
            "accuracy: 0.777500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.660505\n",
            "accuracy: 0.806250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.592822\n",
            "accuracy: 0.821250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.752911\n",
            "accuracy: 0.777500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.635808\n",
            "accuracy: 0.802500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.570940\n",
            "accuracy: 0.810000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.692109\n",
            "accuracy: 0.783750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.661639\n",
            "accuracy: 0.778750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.679496\n",
            "accuracy: 0.793750\n",
            "2018-10-30 17:35:09.987311\n",
            "---- EPOCH 011 EVALUATION ----\n",
            "eval mean loss: 0.456226\n",
            "eval accuracy: 0.858185\n",
            "eval avg class acc: 0.802779\n",
            "**** EPOCH 012 ****\n",
            "2018-10-30 17:35:22.270002\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.617487\n",
            "accuracy: 0.807500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.591148\n",
            "accuracy: 0.813750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.621740\n",
            "accuracy: 0.802500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.647029\n",
            "accuracy: 0.783750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.638623\n",
            "accuracy: 0.791250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.613831\n",
            "accuracy: 0.803750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.687738\n",
            "accuracy: 0.766250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.614462\n",
            "accuracy: 0.807500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.623437\n",
            "accuracy: 0.817500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.661502\n",
            "accuracy: 0.807500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.663122\n",
            "accuracy: 0.801250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.565350\n",
            "accuracy: 0.806250\n",
            "2018-10-30 17:38:06.142107\n",
            "---- EPOCH 012 EVALUATION ----\n",
            "eval mean loss: 0.513964\n",
            "eval accuracy: 0.834279\n",
            "eval avg class acc: 0.787831\n",
            "**** EPOCH 013 ****\n",
            "2018-10-30 17:38:18.461061\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.562271\n",
            "accuracy: 0.821250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.639604\n",
            "accuracy: 0.817500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.584481\n",
            "accuracy: 0.817500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.600969\n",
            "accuracy: 0.795000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.646413\n",
            "accuracy: 0.800000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.656504\n",
            "accuracy: 0.790000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.609144\n",
            "accuracy: 0.808750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.630316\n",
            "accuracy: 0.802500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.596824\n",
            "accuracy: 0.830000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.570733\n",
            "accuracy: 0.815000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.537933\n",
            "accuracy: 0.835000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.654413\n",
            "accuracy: 0.811250\n",
            "2018-10-30 17:41:02.335718\n",
            "---- EPOCH 013 EVALUATION ----\n",
            "eval mean loss: 0.449045\n",
            "eval accuracy: 0.865073\n",
            "eval avg class acc: 0.819628\n",
            "**** EPOCH 014 ****\n",
            "2018-10-30 17:41:14.645914\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.592978\n",
            "accuracy: 0.813750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.598209\n",
            "accuracy: 0.815000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.516029\n",
            "accuracy: 0.836250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.528350\n",
            "accuracy: 0.823750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.556987\n",
            "accuracy: 0.828750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.566383\n",
            "accuracy: 0.822500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.570559\n",
            "accuracy: 0.830000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.584777\n",
            "accuracy: 0.815000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.586259\n",
            "accuracy: 0.822500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.588720\n",
            "accuracy: 0.812500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.671410\n",
            "accuracy: 0.790000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.559671\n",
            "accuracy: 0.821250\n",
            "2018-10-30 17:43:58.513200\n",
            "---- EPOCH 014 EVALUATION ----\n",
            "eval mean loss: 0.483535\n",
            "eval accuracy: 0.847650\n",
            "eval avg class acc: 0.801727\n",
            "**** EPOCH 015 ****\n",
            "2018-10-30 17:44:10.867088\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.601080\n",
            "accuracy: 0.815000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.569251\n",
            "accuracy: 0.827500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.618652\n",
            "accuracy: 0.816250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.659199\n",
            "accuracy: 0.791250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.518803\n",
            "accuracy: 0.847500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.625326\n",
            "accuracy: 0.806250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.540380\n",
            "accuracy: 0.823750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.552942\n",
            "accuracy: 0.808750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.489860\n",
            "accuracy: 0.840000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.552387\n",
            "accuracy: 0.837500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.581575\n",
            "accuracy: 0.823750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.633880\n",
            "accuracy: 0.806250\n",
            "2018-10-30 17:46:54.829105\n",
            "---- EPOCH 015 EVALUATION ----\n",
            "eval mean loss: 0.465091\n",
            "eval accuracy: 0.855348\n",
            "eval avg class acc: 0.811250\n",
            "**** EPOCH 016 ****\n",
            "2018-10-30 17:47:07.177533\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.521605\n",
            "accuracy: 0.838750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.510557\n",
            "accuracy: 0.836250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.501828\n",
            "accuracy: 0.826250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.572355\n",
            "accuracy: 0.822500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.566757\n",
            "accuracy: 0.811250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.506157\n",
            "accuracy: 0.831250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.592316\n",
            "accuracy: 0.821250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.538497\n",
            "accuracy: 0.827500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.578151\n",
            "accuracy: 0.808750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.665321\n",
            "accuracy: 0.801250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.559415\n",
            "accuracy: 0.818750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.541833\n",
            "accuracy: 0.808750\n",
            "2018-10-30 17:49:51.522123\n",
            "---- EPOCH 016 EVALUATION ----\n",
            "eval mean loss: 0.489317\n",
            "eval accuracy: 0.848055\n",
            "eval avg class acc: 0.804250\n",
            "**** EPOCH 017 ****\n",
            "2018-10-30 17:50:03.812409\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.571233\n",
            "accuracy: 0.840000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.582451\n",
            "accuracy: 0.812500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.530856\n",
            "accuracy: 0.836250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.508445\n",
            "accuracy: 0.832500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.500338\n",
            "accuracy: 0.821250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.506202\n",
            "accuracy: 0.843750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.573393\n",
            "accuracy: 0.817500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.565002\n",
            "accuracy: 0.831250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.555105\n",
            "accuracy: 0.828750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.531312\n",
            "accuracy: 0.840000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.534384\n",
            "accuracy: 0.836250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.507753\n",
            "accuracy: 0.835000\n",
            "2018-10-30 17:52:47.770793\n",
            "---- EPOCH 017 EVALUATION ----\n",
            "eval mean loss: 0.424938\n",
            "eval accuracy: 0.861831\n",
            "eval avg class acc: 0.819901\n",
            "**** EPOCH 018 ****\n",
            "2018-10-30 17:53:00.132528\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.585463\n",
            "accuracy: 0.822500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.483344\n",
            "accuracy: 0.842500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.561613\n",
            "accuracy: 0.806250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.572694\n",
            "accuracy: 0.816250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.476934\n",
            "accuracy: 0.845000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.520203\n",
            "accuracy: 0.843750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.480407\n",
            "accuracy: 0.850000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.481748\n",
            "accuracy: 0.855000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.559899\n",
            "accuracy: 0.820000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.554665\n",
            "accuracy: 0.815000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.584717\n",
            "accuracy: 0.821250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.564649\n",
            "accuracy: 0.827500\n",
            "2018-10-30 17:55:44.205323\n",
            "---- EPOCH 018 EVALUATION ----\n",
            "eval mean loss: 0.412470\n",
            "eval accuracy: 0.861426\n",
            "eval avg class acc: 0.824738\n",
            "**** EPOCH 019 ****\n",
            "2018-10-30 17:55:56.558379\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.508654\n",
            "accuracy: 0.832500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.520000\n",
            "accuracy: 0.837500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.524184\n",
            "accuracy: 0.828750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.521586\n",
            "accuracy: 0.821250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.477908\n",
            "accuracy: 0.841250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.481443\n",
            "accuracy: 0.838750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.474636\n",
            "accuracy: 0.861250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.547904\n",
            "accuracy: 0.826250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.482295\n",
            "accuracy: 0.851250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.574130\n",
            "accuracy: 0.811250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.515417\n",
            "accuracy: 0.855000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.548722\n",
            "accuracy: 0.815000\n",
            "2018-10-30 17:58:40.540211\n",
            "---- EPOCH 019 EVALUATION ----\n",
            "eval mean loss: 0.460089\n",
            "eval accuracy: 0.846029\n",
            "eval avg class acc: 0.804401\n",
            "**** EPOCH 020 ****\n",
            "2018-10-30 17:58:52.878141\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.482666\n",
            "accuracy: 0.846250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.499657\n",
            "accuracy: 0.837500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.477013\n",
            "accuracy: 0.855000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.538320\n",
            "accuracy: 0.841250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.507080\n",
            "accuracy: 0.843750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.503551\n",
            "accuracy: 0.837500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.546624\n",
            "accuracy: 0.822500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.462482\n",
            "accuracy: 0.845000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.446635\n",
            "accuracy: 0.852500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.440801\n",
            "accuracy: 0.846250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.427526\n",
            "accuracy: 0.861250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.464511\n",
            "accuracy: 0.846250\n",
            "2018-10-30 18:01:36.897814\n",
            "---- EPOCH 020 EVALUATION ----\n",
            "eval mean loss: 0.381383\n",
            "eval accuracy: 0.878849\n",
            "eval avg class acc: 0.831326\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 021 ****\n",
            "2018-10-30 18:01:49.817554\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.448599\n",
            "accuracy: 0.853750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.448226\n",
            "accuracy: 0.850000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.424071\n",
            "accuracy: 0.861250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.402364\n",
            "accuracy: 0.862500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.476717\n",
            "accuracy: 0.850000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.510468\n",
            "accuracy: 0.846250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.444995\n",
            "accuracy: 0.847500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.429851\n",
            "accuracy: 0.866250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.533958\n",
            "accuracy: 0.826250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.391643\n",
            "accuracy: 0.875000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.489369\n",
            "accuracy: 0.843750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.403651\n",
            "accuracy: 0.865000\n",
            "2018-10-30 18:04:33.885220\n",
            "---- EPOCH 021 EVALUATION ----\n",
            "eval mean loss: 0.377589\n",
            "eval accuracy: 0.875608\n",
            "eval avg class acc: 0.840785\n",
            "**** EPOCH 022 ****\n",
            "2018-10-30 18:04:46.221262\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.427604\n",
            "accuracy: 0.850000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.466018\n",
            "accuracy: 0.860000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.432302\n",
            "accuracy: 0.876250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.387727\n",
            "accuracy: 0.862500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.503371\n",
            "accuracy: 0.838750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.386615\n",
            "accuracy: 0.880000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.425282\n",
            "accuracy: 0.867500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.468243\n",
            "accuracy: 0.850000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.476126\n",
            "accuracy: 0.840000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.478172\n",
            "accuracy: 0.843750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.419787\n",
            "accuracy: 0.885000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.418818\n",
            "accuracy: 0.851250\n",
            "2018-10-30 18:07:30.294011\n",
            "---- EPOCH 022 EVALUATION ----\n",
            "eval mean loss: 0.400673\n",
            "eval accuracy: 0.867909\n",
            "eval avg class acc: 0.833413\n",
            "**** EPOCH 023 ****\n",
            "2018-10-30 18:07:42.597727\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.440420\n",
            "accuracy: 0.865000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.418392\n",
            "accuracy: 0.876250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.364291\n",
            "accuracy: 0.885000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.395968\n",
            "accuracy: 0.872500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.428359\n",
            "accuracy: 0.860000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.453955\n",
            "accuracy: 0.841250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.389272\n",
            "accuracy: 0.886250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.521075\n",
            "accuracy: 0.831250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.450881\n",
            "accuracy: 0.846250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.420953\n",
            "accuracy: 0.860000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.423073\n",
            "accuracy: 0.861250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.412142\n",
            "accuracy: 0.865000\n",
            "2018-10-30 18:10:26.678790\n",
            "---- EPOCH 023 EVALUATION ----\n",
            "eval mean loss: 0.386063\n",
            "eval accuracy: 0.875608\n",
            "eval avg class acc: 0.822314\n",
            "**** EPOCH 024 ****\n",
            "2018-10-30 18:10:39.021628\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.390301\n",
            "accuracy: 0.880000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.473050\n",
            "accuracy: 0.866250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.421089\n",
            "accuracy: 0.861250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.442191\n",
            "accuracy: 0.852500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.413581\n",
            "accuracy: 0.866250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.400258\n",
            "accuracy: 0.858750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.489816\n",
            "accuracy: 0.852500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.436833\n",
            "accuracy: 0.863750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.464214\n",
            "accuracy: 0.857500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.448071\n",
            "accuracy: 0.858750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.421830\n",
            "accuracy: 0.860000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.464926\n",
            "accuracy: 0.856250\n",
            "2018-10-30 18:13:22.768800\n",
            "---- EPOCH 024 EVALUATION ----\n",
            "eval mean loss: 0.378339\n",
            "eval accuracy: 0.882901\n",
            "eval avg class acc: 0.834727\n",
            "**** EPOCH 025 ****\n",
            "2018-10-30 18:13:35.113280\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.454310\n",
            "accuracy: 0.860000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.459416\n",
            "accuracy: 0.851250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.401814\n",
            "accuracy: 0.872500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.415987\n",
            "accuracy: 0.866250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.407226\n",
            "accuracy: 0.862500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.382066\n",
            "accuracy: 0.872500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.438500\n",
            "accuracy: 0.851250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.427023\n",
            "accuracy: 0.862500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.431081\n",
            "accuracy: 0.861250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.415093\n",
            "accuracy: 0.862500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.404220\n",
            "accuracy: 0.873750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.407645\n",
            "accuracy: 0.873750\n",
            "2018-10-30 18:16:19.250848\n",
            "---- EPOCH 025 EVALUATION ----\n",
            "eval mean loss: 0.391912\n",
            "eval accuracy: 0.873987\n",
            "eval avg class acc: 0.836215\n",
            "**** EPOCH 026 ****\n",
            "2018-10-30 18:16:31.560318\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.439311\n",
            "accuracy: 0.853750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.351633\n",
            "accuracy: 0.887500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.441015\n",
            "accuracy: 0.868750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.451721\n",
            "accuracy: 0.860000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.459356\n",
            "accuracy: 0.833750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.424713\n",
            "accuracy: 0.862500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.424418\n",
            "accuracy: 0.868750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.429528\n",
            "accuracy: 0.847500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.374161\n",
            "accuracy: 0.883750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.398913\n",
            "accuracy: 0.876250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.399082\n",
            "accuracy: 0.862500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.423020\n",
            "accuracy: 0.866250\n",
            "2018-10-30 18:19:15.440093\n",
            "---- EPOCH 026 EVALUATION ----\n",
            "eval mean loss: 0.388681\n",
            "eval accuracy: 0.881280\n",
            "eval avg class acc: 0.851320\n",
            "**** EPOCH 027 ****\n",
            "2018-10-30 18:19:27.710836\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.397683\n",
            "accuracy: 0.867500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.442192\n",
            "accuracy: 0.865000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.365864\n",
            "accuracy: 0.883750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.394007\n",
            "accuracy: 0.881250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.456778\n",
            "accuracy: 0.845000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.366325\n",
            "accuracy: 0.881250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.367269\n",
            "accuracy: 0.887500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.466224\n",
            "accuracy: 0.866250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.396164\n",
            "accuracy: 0.872500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.407423\n",
            "accuracy: 0.882500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.431487\n",
            "accuracy: 0.862500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.418574\n",
            "accuracy: 0.871250\n",
            "2018-10-30 18:22:11.467328\n",
            "---- EPOCH 027 EVALUATION ----\n",
            "eval mean loss: 0.365110\n",
            "eval accuracy: 0.882496\n",
            "eval avg class acc: 0.841105\n",
            "**** EPOCH 028 ****\n",
            "2018-10-30 18:22:23.758424\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.396466\n",
            "accuracy: 0.877500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.396285\n",
            "accuracy: 0.873750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.374805\n",
            "accuracy: 0.882500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.406198\n",
            "accuracy: 0.868750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.390345\n",
            "accuracy: 0.876250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.434211\n",
            "accuracy: 0.837500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.369805\n",
            "accuracy: 0.871250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.457928\n",
            "accuracy: 0.842500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.381118\n",
            "accuracy: 0.881250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.376792\n",
            "accuracy: 0.878750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.402497\n",
            "accuracy: 0.865000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.339916\n",
            "accuracy: 0.897500\n",
            "2018-10-30 18:25:07.598423\n",
            "---- EPOCH 028 EVALUATION ----\n",
            "eval mean loss: 0.384355\n",
            "eval accuracy: 0.870340\n",
            "eval avg class acc: 0.831907\n",
            "**** EPOCH 029 ****\n",
            "2018-10-30 18:25:19.907456\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.397045\n",
            "accuracy: 0.860000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.403077\n",
            "accuracy: 0.876250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.344103\n",
            "accuracy: 0.881250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.371246\n",
            "accuracy: 0.875000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.379682\n",
            "accuracy: 0.881250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.339633\n",
            "accuracy: 0.883750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.405578\n",
            "accuracy: 0.868750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.368800\n",
            "accuracy: 0.867500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.405689\n",
            "accuracy: 0.861250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.444583\n",
            "accuracy: 0.863750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.370445\n",
            "accuracy: 0.867500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.357849\n",
            "accuracy: 0.880000\n",
            "2018-10-30 18:28:03.832581\n",
            "---- EPOCH 029 EVALUATION ----\n",
            "eval mean loss: 0.396377\n",
            "eval accuracy: 0.878039\n",
            "eval avg class acc: 0.845407\n",
            "**** EPOCH 030 ****\n",
            "2018-10-30 18:28:16.143318\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.376456\n",
            "accuracy: 0.861250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.440612\n",
            "accuracy: 0.861250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.341081\n",
            "accuracy: 0.893750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.384687\n",
            "accuracy: 0.877500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.425692\n",
            "accuracy: 0.858750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.439237\n",
            "accuracy: 0.856250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.392499\n",
            "accuracy: 0.862500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.376399\n",
            "accuracy: 0.876250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.451429\n",
            "accuracy: 0.855000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.364638\n",
            "accuracy: 0.875000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.415401\n",
            "accuracy: 0.868750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.405775\n",
            "accuracy: 0.866250\n",
            "2018-10-30 18:31:00.075380\n",
            "---- EPOCH 030 EVALUATION ----\n",
            "eval mean loss: 0.402071\n",
            "eval accuracy: 0.865073\n",
            "eval avg class acc: 0.834523\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 031 ****\n",
            "2018-10-30 18:31:12.841116\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.398443\n",
            "accuracy: 0.863750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.358763\n",
            "accuracy: 0.881250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.338146\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.363856\n",
            "accuracy: 0.880000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.439458\n",
            "accuracy: 0.868750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.389575\n",
            "accuracy: 0.861250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.393485\n",
            "accuracy: 0.877500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.353422\n",
            "accuracy: 0.880000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.359920\n",
            "accuracy: 0.880000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.350037\n",
            "accuracy: 0.888750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.377568\n",
            "accuracy: 0.881250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.406055\n",
            "accuracy: 0.853750\n",
            "2018-10-30 18:33:56.836179\n",
            "---- EPOCH 031 EVALUATION ----\n",
            "eval mean loss: 0.424086\n",
            "eval accuracy: 0.860211\n",
            "eval avg class acc: 0.819698\n",
            "**** EPOCH 032 ****\n",
            "2018-10-30 18:34:09.169798\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.358915\n",
            "accuracy: 0.876250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.400271\n",
            "accuracy: 0.881250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.365453\n",
            "accuracy: 0.871250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.346112\n",
            "accuracy: 0.880000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.382642\n",
            "accuracy: 0.875000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.396394\n",
            "accuracy: 0.867500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.346286\n",
            "accuracy: 0.882500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.390333\n",
            "accuracy: 0.885000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.424460\n",
            "accuracy: 0.871250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.366049\n",
            "accuracy: 0.880000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.431285\n",
            "accuracy: 0.851250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.338506\n",
            "accuracy: 0.897500\n",
            "2018-10-30 18:36:53.003608\n",
            "---- EPOCH 032 EVALUATION ----\n",
            "eval mean loss: 0.368135\n",
            "eval accuracy: 0.876418\n",
            "eval avg class acc: 0.840488\n",
            "**** EPOCH 033 ****\n",
            "2018-10-30 18:37:05.279345\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.374040\n",
            "accuracy: 0.866250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.427125\n",
            "accuracy: 0.852500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.401045\n",
            "accuracy: 0.871250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.312690\n",
            "accuracy: 0.888750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.411527\n",
            "accuracy: 0.867500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.378024\n",
            "accuracy: 0.871250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.352823\n",
            "accuracy: 0.890000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.320036\n",
            "accuracy: 0.890000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.350325\n",
            "accuracy: 0.897500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.396303\n",
            "accuracy: 0.855000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.372431\n",
            "accuracy: 0.866250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.367313\n",
            "accuracy: 0.878750\n",
            "2018-10-30 18:39:49.083241\n",
            "---- EPOCH 033 EVALUATION ----\n",
            "eval mean loss: 0.360680\n",
            "eval accuracy: 0.884927\n",
            "eval avg class acc: 0.839855\n",
            "**** EPOCH 034 ****\n",
            "2018-10-30 18:40:01.374975\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.417209\n",
            "accuracy: 0.871250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.394838\n",
            "accuracy: 0.876250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.323017\n",
            "accuracy: 0.893750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.391828\n",
            "accuracy: 0.870000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.393038\n",
            "accuracy: 0.877500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.413819\n",
            "accuracy: 0.876250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.375277\n",
            "accuracy: 0.875000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.354710\n",
            "accuracy: 0.885000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.401371\n",
            "accuracy: 0.872500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.365556\n",
            "accuracy: 0.873750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.328004\n",
            "accuracy: 0.896250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.333996\n",
            "accuracy: 0.896250\n",
            "2018-10-30 18:42:45.600075\n",
            "---- EPOCH 034 EVALUATION ----\n",
            "eval mean loss: 0.357303\n",
            "eval accuracy: 0.884927\n",
            "eval avg class acc: 0.857866\n",
            "**** EPOCH 035 ****\n",
            "2018-10-30 18:42:57.942618\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.319330\n",
            "accuracy: 0.896250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.340894\n",
            "accuracy: 0.887500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.370255\n",
            "accuracy: 0.892500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.364670\n",
            "accuracy: 0.870000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.342942\n",
            "accuracy: 0.892500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.306385\n",
            "accuracy: 0.913750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.378926\n",
            "accuracy: 0.867500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.359898\n",
            "accuracy: 0.866250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.341457\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.367999\n",
            "accuracy: 0.883750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.378978\n",
            "accuracy: 0.882500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.378958\n",
            "accuracy: 0.876250\n",
            "2018-10-30 18:45:41.894106\n",
            "---- EPOCH 035 EVALUATION ----\n",
            "eval mean loss: 0.355270\n",
            "eval accuracy: 0.887358\n",
            "eval avg class acc: 0.857529\n",
            "**** EPOCH 036 ****\n",
            "2018-10-30 18:45:54.188300\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.326232\n",
            "accuracy: 0.883750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.393474\n",
            "accuracy: 0.870000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.328122\n",
            "accuracy: 0.891250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.321035\n",
            "accuracy: 0.890000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.363605\n",
            "accuracy: 0.885000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.333645\n",
            "accuracy: 0.885000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.363139\n",
            "accuracy: 0.873750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.338250\n",
            "accuracy: 0.890000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.363740\n",
            "accuracy: 0.871250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.338461\n",
            "accuracy: 0.885000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.331947\n",
            "accuracy: 0.868750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.312725\n",
            "accuracy: 0.886250\n",
            "2018-10-30 18:48:38.320752\n",
            "---- EPOCH 036 EVALUATION ----\n",
            "eval mean loss: 0.385700\n",
            "eval accuracy: 0.884522\n",
            "eval avg class acc: 0.840552\n",
            "**** EPOCH 037 ****\n",
            "2018-10-30 18:48:50.646384\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.303815\n",
            "accuracy: 0.907500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.331051\n",
            "accuracy: 0.895000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.353669\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.351948\n",
            "accuracy: 0.862500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.328803\n",
            "accuracy: 0.882500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.327733\n",
            "accuracy: 0.878750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.373544\n",
            "accuracy: 0.878750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.339167\n",
            "accuracy: 0.883750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.328798\n",
            "accuracy: 0.881250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.411299\n",
            "accuracy: 0.872500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.341977\n",
            "accuracy: 0.891250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.365724\n",
            "accuracy: 0.883750\n",
            "2018-10-30 18:51:34.672247\n",
            "---- EPOCH 037 EVALUATION ----\n",
            "eval mean loss: 0.376504\n",
            "eval accuracy: 0.880875\n",
            "eval avg class acc: 0.855570\n",
            "**** EPOCH 038 ****\n",
            "2018-10-30 18:51:47.030100\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.353396\n",
            "accuracy: 0.882500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.301789\n",
            "accuracy: 0.895000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.425956\n",
            "accuracy: 0.863750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.293978\n",
            "accuracy: 0.905000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.307032\n",
            "accuracy: 0.895000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.308268\n",
            "accuracy: 0.885000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.298772\n",
            "accuracy: 0.906250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.434782\n",
            "accuracy: 0.875000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.356284\n",
            "accuracy: 0.880000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.340929\n",
            "accuracy: 0.885000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.349579\n",
            "accuracy: 0.876250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.386129\n",
            "accuracy: 0.876250\n",
            "2018-10-30 18:54:31.071575\n",
            "---- EPOCH 038 EVALUATION ----\n",
            "eval mean loss: 0.364482\n",
            "eval accuracy: 0.888979\n",
            "eval avg class acc: 0.859517\n",
            "**** EPOCH 039 ****\n",
            "2018-10-30 18:54:43.408538\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.364590\n",
            "accuracy: 0.880000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.348294\n",
            "accuracy: 0.878750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.346623\n",
            "accuracy: 0.887500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.370944\n",
            "accuracy: 0.873750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.320565\n",
            "accuracy: 0.905000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.403957\n",
            "accuracy: 0.865000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.334002\n",
            "accuracy: 0.891250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.313292\n",
            "accuracy: 0.900000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.329644\n",
            "accuracy: 0.881250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.336875\n",
            "accuracy: 0.876250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.329256\n",
            "accuracy: 0.883750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.344242\n",
            "accuracy: 0.895000\n",
            "2018-10-30 18:57:27.243907\n",
            "---- EPOCH 039 EVALUATION ----\n",
            "eval mean loss: 0.377677\n",
            "eval accuracy: 0.880875\n",
            "eval avg class acc: 0.843029\n",
            "**** EPOCH 040 ****\n",
            "2018-10-30 18:57:39.568113\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.324553\n",
            "accuracy: 0.887500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.347220\n",
            "accuracy: 0.886250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.318629\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.321767\n",
            "accuracy: 0.883750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.349386\n",
            "accuracy: 0.873750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.339648\n",
            "accuracy: 0.878750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.293737\n",
            "accuracy: 0.907500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.367474\n",
            "accuracy: 0.881250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.329268\n",
            "accuracy: 0.895000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.332348\n",
            "accuracy: 0.890000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.314019\n",
            "accuracy: 0.906250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.318759\n",
            "accuracy: 0.898750\n",
            "2018-10-30 19:00:23.643733\n",
            "---- EPOCH 040 EVALUATION ----\n",
            "eval mean loss: 0.370877\n",
            "eval accuracy: 0.878849\n",
            "eval avg class acc: 0.847157\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 041 ****\n",
            "2018-10-30 19:00:36.422752\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.295780\n",
            "accuracy: 0.892500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.351083\n",
            "accuracy: 0.880000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.307569\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.299388\n",
            "accuracy: 0.902500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.312978\n",
            "accuracy: 0.886250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.325360\n",
            "accuracy: 0.882500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.301540\n",
            "accuracy: 0.902500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.336067\n",
            "accuracy: 0.881250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.281953\n",
            "accuracy: 0.912500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.312091\n",
            "accuracy: 0.898750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.315217\n",
            "accuracy: 0.898750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.292538\n",
            "accuracy: 0.896250\n",
            "2018-10-30 19:03:20.378516\n",
            "---- EPOCH 041 EVALUATION ----\n",
            "eval mean loss: 0.353831\n",
            "eval accuracy: 0.888169\n",
            "eval avg class acc: 0.858558\n",
            "**** EPOCH 042 ****\n",
            "2018-10-30 19:03:32.695932\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.294231\n",
            "accuracy: 0.913750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.293000\n",
            "accuracy: 0.905000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.296775\n",
            "accuracy: 0.913750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.276348\n",
            "accuracy: 0.892500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.296382\n",
            "accuracy: 0.900000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.279298\n",
            "accuracy: 0.897500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.297938\n",
            "accuracy: 0.892500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.353748\n",
            "accuracy: 0.883750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.308726\n",
            "accuracy: 0.893750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.279960\n",
            "accuracy: 0.896250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.308743\n",
            "accuracy: 0.903750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.321696\n",
            "accuracy: 0.903750\n",
            "2018-10-30 19:06:16.976929\n",
            "---- EPOCH 042 EVALUATION ----\n",
            "eval mean loss: 0.353165\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.864105\n",
            "**** EPOCH 043 ****\n",
            "2018-10-30 19:06:29.326383\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.353430\n",
            "accuracy: 0.881250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.306101\n",
            "accuracy: 0.892500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.286812\n",
            "accuracy: 0.907500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.285946\n",
            "accuracy: 0.902500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.290854\n",
            "accuracy: 0.905000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.290037\n",
            "accuracy: 0.895000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.324013\n",
            "accuracy: 0.886250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.269175\n",
            "accuracy: 0.906250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.293532\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.264800\n",
            "accuracy: 0.910000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.326525\n",
            "accuracy: 0.891250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.334081\n",
            "accuracy: 0.883750\n",
            "2018-10-30 19:09:13.758944\n",
            "---- EPOCH 043 EVALUATION ----\n",
            "eval mean loss: 0.368004\n",
            "eval accuracy: 0.882901\n",
            "eval avg class acc: 0.851977\n",
            "**** EPOCH 044 ****\n",
            "2018-10-30 19:09:26.100286\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.244945\n",
            "accuracy: 0.913750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.262427\n",
            "accuracy: 0.911250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.294206\n",
            "accuracy: 0.897500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.314229\n",
            "accuracy: 0.897500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.258527\n",
            "accuracy: 0.903750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.283373\n",
            "accuracy: 0.892500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.284327\n",
            "accuracy: 0.896250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.343086\n",
            "accuracy: 0.882500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.279508\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.289642\n",
            "accuracy: 0.913750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.257292\n",
            "accuracy: 0.918750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.323608\n",
            "accuracy: 0.882500\n",
            "2018-10-30 19:12:10.412498\n",
            "---- EPOCH 044 EVALUATION ----\n",
            "eval mean loss: 0.377770\n",
            "eval accuracy: 0.877229\n",
            "eval avg class acc: 0.857564\n",
            "**** EPOCH 045 ****\n",
            "2018-10-30 19:12:22.760183\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.289713\n",
            "accuracy: 0.902500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.300538\n",
            "accuracy: 0.891250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.307245\n",
            "accuracy: 0.903750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.266670\n",
            "accuracy: 0.906250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.281554\n",
            "accuracy: 0.897500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.326730\n",
            "accuracy: 0.881250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.265358\n",
            "accuracy: 0.907500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.293113\n",
            "accuracy: 0.900000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.266276\n",
            "accuracy: 0.905000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.274010\n",
            "accuracy: 0.901250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.250557\n",
            "accuracy: 0.916250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.327972\n",
            "accuracy: 0.895000\n",
            "2018-10-30 19:15:06.916696\n",
            "---- EPOCH 045 EVALUATION ----\n",
            "eval mean loss: 0.379038\n",
            "eval accuracy: 0.872366\n",
            "eval avg class acc: 0.837372\n",
            "**** EPOCH 046 ****\n",
            "2018-10-30 19:15:19.237329\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.310006\n",
            "accuracy: 0.883750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.277409\n",
            "accuracy: 0.912500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.300190\n",
            "accuracy: 0.892500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.315371\n",
            "accuracy: 0.905000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.261242\n",
            "accuracy: 0.908750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.295151\n",
            "accuracy: 0.903750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.265855\n",
            "accuracy: 0.903750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.304763\n",
            "accuracy: 0.891250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.316695\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.275485\n",
            "accuracy: 0.906250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.284536\n",
            "accuracy: 0.906250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.295004\n",
            "accuracy: 0.898750\n",
            "2018-10-30 19:18:03.007782\n",
            "---- EPOCH 046 EVALUATION ----\n",
            "eval mean loss: 0.351138\n",
            "eval accuracy: 0.886953\n",
            "eval avg class acc: 0.851767\n",
            "**** EPOCH 047 ****\n",
            "2018-10-30 19:18:15.272791\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.285894\n",
            "accuracy: 0.905000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.326244\n",
            "accuracy: 0.888750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.341441\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.251377\n",
            "accuracy: 0.912500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.289950\n",
            "accuracy: 0.902500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.304160\n",
            "accuracy: 0.898750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.277235\n",
            "accuracy: 0.920000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.314265\n",
            "accuracy: 0.887500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.302666\n",
            "accuracy: 0.901250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.287072\n",
            "accuracy: 0.901250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.274098\n",
            "accuracy: 0.905000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.322057\n",
            "accuracy: 0.893750\n",
            "2018-10-30 19:20:59.281133\n",
            "---- EPOCH 047 EVALUATION ----\n",
            "eval mean loss: 0.380649\n",
            "eval accuracy: 0.882091\n",
            "eval avg class acc: 0.862936\n",
            "**** EPOCH 048 ****\n",
            "2018-10-30 19:21:11.589197\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.287949\n",
            "accuracy: 0.901250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.286724\n",
            "accuracy: 0.908750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.274007\n",
            "accuracy: 0.902500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.255806\n",
            "accuracy: 0.920000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.298271\n",
            "accuracy: 0.898750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.308680\n",
            "accuracy: 0.902500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.281228\n",
            "accuracy: 0.910000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.248972\n",
            "accuracy: 0.918750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.303551\n",
            "accuracy: 0.897500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.324067\n",
            "accuracy: 0.880000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.272059\n",
            "accuracy: 0.893750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.284284\n",
            "accuracy: 0.907500\n",
            "2018-10-30 19:23:55.969251\n",
            "---- EPOCH 048 EVALUATION ----\n",
            "eval mean loss: 0.358851\n",
            "eval accuracy: 0.891410\n",
            "eval avg class acc: 0.851390\n",
            "**** EPOCH 049 ****\n",
            "2018-10-30 19:24:08.334609\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.254014\n",
            "accuracy: 0.922500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.292746\n",
            "accuracy: 0.896250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.286246\n",
            "accuracy: 0.903750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.290237\n",
            "accuracy: 0.905000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.274354\n",
            "accuracy: 0.905000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.288918\n",
            "accuracy: 0.900000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.249968\n",
            "accuracy: 0.921250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.250876\n",
            "accuracy: 0.907500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.261901\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.351290\n",
            "accuracy: 0.892500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.306530\n",
            "accuracy: 0.905000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.259082\n",
            "accuracy: 0.911250\n",
            "2018-10-30 19:26:52.492059\n",
            "---- EPOCH 049 EVALUATION ----\n",
            "eval mean loss: 0.397119\n",
            "eval accuracy: 0.864668\n",
            "eval avg class acc: 0.844924\n",
            "**** EPOCH 050 ****\n",
            "2018-10-30 19:27:04.808512\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.256706\n",
            "accuracy: 0.910000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.327650\n",
            "accuracy: 0.888750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.294198\n",
            "accuracy: 0.900000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.242447\n",
            "accuracy: 0.915000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.257250\n",
            "accuracy: 0.911250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.265224\n",
            "accuracy: 0.917500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.273981\n",
            "accuracy: 0.910000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.293609\n",
            "accuracy: 0.898750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.330457\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.317389\n",
            "accuracy: 0.898750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.278170\n",
            "accuracy: 0.903750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.296817\n",
            "accuracy: 0.893750\n",
            "2018-10-30 19:29:48.975814\n",
            "---- EPOCH 050 EVALUATION ----\n",
            "eval mean loss: 0.384368\n",
            "eval accuracy: 0.880875\n",
            "eval avg class acc: 0.857413\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 051 ****\n",
            "2018-10-30 19:30:01.761745\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.296760\n",
            "accuracy: 0.901250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.281740\n",
            "accuracy: 0.905000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.238023\n",
            "accuracy: 0.911250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.271397\n",
            "accuracy: 0.908750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.328824\n",
            "accuracy: 0.901250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.233470\n",
            "accuracy: 0.923750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.293348\n",
            "accuracy: 0.892500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.230221\n",
            "accuracy: 0.917500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.276981\n",
            "accuracy: 0.917500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.270217\n",
            "accuracy: 0.911250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.288061\n",
            "accuracy: 0.906250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.264639\n",
            "accuracy: 0.901250\n",
            "2018-10-30 19:32:46.097578\n",
            "---- EPOCH 051 EVALUATION ----\n",
            "eval mean loss: 0.383558\n",
            "eval accuracy: 0.875203\n",
            "eval avg class acc: 0.849593\n",
            "**** EPOCH 052 ****\n",
            "2018-10-30 19:32:58.411180\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.262860\n",
            "accuracy: 0.906250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.261530\n",
            "accuracy: 0.906250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.283390\n",
            "accuracy: 0.907500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.307189\n",
            "accuracy: 0.903750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.255918\n",
            "accuracy: 0.918750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.285075\n",
            "accuracy: 0.908750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.247851\n",
            "accuracy: 0.917500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.307108\n",
            "accuracy: 0.893750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.234628\n",
            "accuracy: 0.922500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.272563\n",
            "accuracy: 0.908750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.343558\n",
            "accuracy: 0.902500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.262476\n",
            "accuracy: 0.907500\n",
            "2018-10-30 19:35:42.366726\n",
            "---- EPOCH 052 EVALUATION ----\n",
            "eval mean loss: 0.371499\n",
            "eval accuracy: 0.887358\n",
            "eval avg class acc: 0.861651\n",
            "**** EPOCH 053 ****\n",
            "2018-10-30 19:35:54.650339\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.252084\n",
            "accuracy: 0.911250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.250699\n",
            "accuracy: 0.912500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.284330\n",
            "accuracy: 0.898750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.233772\n",
            "accuracy: 0.925000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.262038\n",
            "accuracy: 0.905000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.278120\n",
            "accuracy: 0.900000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.255625\n",
            "accuracy: 0.903750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.335310\n",
            "accuracy: 0.891250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.288604\n",
            "accuracy: 0.901250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.261108\n",
            "accuracy: 0.923750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.234230\n",
            "accuracy: 0.921250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.278344\n",
            "accuracy: 0.913750\n",
            "2018-10-30 19:38:38.632323\n",
            "---- EPOCH 053 EVALUATION ----\n",
            "eval mean loss: 0.344577\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.860395\n",
            "**** EPOCH 054 ****\n",
            "2018-10-30 19:38:50.952705\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.296757\n",
            "accuracy: 0.907500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.234591\n",
            "accuracy: 0.917500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.243494\n",
            "accuracy: 0.913750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.283970\n",
            "accuracy: 0.903750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.235757\n",
            "accuracy: 0.908750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.253047\n",
            "accuracy: 0.921250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.259233\n",
            "accuracy: 0.897500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.274891\n",
            "accuracy: 0.905000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.266210\n",
            "accuracy: 0.915000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.243272\n",
            "accuracy: 0.921250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.269950\n",
            "accuracy: 0.905000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.291773\n",
            "accuracy: 0.907500\n",
            "2018-10-30 19:41:35.090249\n",
            "---- EPOCH 054 EVALUATION ----\n",
            "eval mean loss: 0.378300\n",
            "eval accuracy: 0.883712\n",
            "eval avg class acc: 0.856012\n",
            "**** EPOCH 055 ****\n",
            "2018-10-30 19:41:47.406879\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.221370\n",
            "accuracy: 0.916250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.272684\n",
            "accuracy: 0.901250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.236751\n",
            "accuracy: 0.912500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.279056\n",
            "accuracy: 0.903750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.275891\n",
            "accuracy: 0.897500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.297191\n",
            "accuracy: 0.888750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.278630\n",
            "accuracy: 0.900000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.256242\n",
            "accuracy: 0.910000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.295121\n",
            "accuracy: 0.896250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.252058\n",
            "accuracy: 0.916250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.274942\n",
            "accuracy: 0.907500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.255756\n",
            "accuracy: 0.911250\n",
            "2018-10-30 19:44:31.504436\n",
            "---- EPOCH 055 EVALUATION ----\n",
            "eval mean loss: 0.340559\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.859064\n",
            "**** EPOCH 056 ****\n",
            "2018-10-30 19:44:43.859690\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.236701\n",
            "accuracy: 0.910000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.242668\n",
            "accuracy: 0.922500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.269974\n",
            "accuracy: 0.907500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.232243\n",
            "accuracy: 0.925000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.257989\n",
            "accuracy: 0.925000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.266055\n",
            "accuracy: 0.915000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.202365\n",
            "accuracy: 0.931250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.271317\n",
            "accuracy: 0.900000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.268143\n",
            "accuracy: 0.907500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.255130\n",
            "accuracy: 0.920000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.273982\n",
            "accuracy: 0.908750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.237252\n",
            "accuracy: 0.923750\n",
            "2018-10-30 19:47:27.912859\n",
            "---- EPOCH 056 EVALUATION ----\n",
            "eval mean loss: 0.381286\n",
            "eval accuracy: 0.880065\n",
            "eval avg class acc: 0.848802\n",
            "**** EPOCH 057 ****\n",
            "2018-10-30 19:47:40.237763\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.200237\n",
            "accuracy: 0.936250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.270039\n",
            "accuracy: 0.910000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.287369\n",
            "accuracy: 0.908750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.221612\n",
            "accuracy: 0.930000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.264618\n",
            "accuracy: 0.902500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.283519\n",
            "accuracy: 0.896250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.231421\n",
            "accuracy: 0.908750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.309370\n",
            "accuracy: 0.892500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.247903\n",
            "accuracy: 0.913750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.310603\n",
            "accuracy: 0.898750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.291327\n",
            "accuracy: 0.892500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.254234\n",
            "accuracy: 0.903750\n",
            "2018-10-30 19:50:24.278386\n",
            "---- EPOCH 057 EVALUATION ----\n",
            "eval mean loss: 0.355761\n",
            "eval accuracy: 0.881686\n",
            "eval avg class acc: 0.852785\n",
            "**** EPOCH 058 ****\n",
            "2018-10-30 19:50:36.588437\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.223259\n",
            "accuracy: 0.918750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.267492\n",
            "accuracy: 0.910000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.208071\n",
            "accuracy: 0.922500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.243713\n",
            "accuracy: 0.916250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.253927\n",
            "accuracy: 0.915000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.284684\n",
            "accuracy: 0.901250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.240221\n",
            "accuracy: 0.923750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.281946\n",
            "accuracy: 0.897500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.305387\n",
            "accuracy: 0.910000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.238157\n",
            "accuracy: 0.922500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.251911\n",
            "accuracy: 0.923750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.290031\n",
            "accuracy: 0.902500\n",
            "2018-10-30 19:53:20.749883\n",
            "---- EPOCH 058 EVALUATION ----\n",
            "eval mean loss: 0.356898\n",
            "eval accuracy: 0.890194\n",
            "eval avg class acc: 0.862686\n",
            "**** EPOCH 059 ****\n",
            "2018-10-30 19:53:33.087485\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.250295\n",
            "accuracy: 0.921250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.235400\n",
            "accuracy: 0.922500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.280442\n",
            "accuracy: 0.903750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.234434\n",
            "accuracy: 0.921250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.261533\n",
            "accuracy: 0.910000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.244344\n",
            "accuracy: 0.917500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.206977\n",
            "accuracy: 0.928750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.270703\n",
            "accuracy: 0.916250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.267495\n",
            "accuracy: 0.903750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.251146\n",
            "accuracy: 0.920000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.279111\n",
            "accuracy: 0.908750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.251469\n",
            "accuracy: 0.925000\n",
            "2018-10-30 19:56:17.164117\n",
            "---- EPOCH 059 EVALUATION ----\n",
            "eval mean loss: 0.379001\n",
            "eval accuracy: 0.890600\n",
            "eval avg class acc: 0.864186\n",
            "**** EPOCH 060 ****\n",
            "2018-10-30 19:56:29.446466\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.226552\n",
            "accuracy: 0.920000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.215132\n",
            "accuracy: 0.926250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.277067\n",
            "accuracy: 0.917500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.247202\n",
            "accuracy: 0.920000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.294212\n",
            "accuracy: 0.910000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.235386\n",
            "accuracy: 0.903750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.223237\n",
            "accuracy: 0.916250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.236832\n",
            "accuracy: 0.912500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.211942\n",
            "accuracy: 0.930000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.310397\n",
            "accuracy: 0.898750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.269328\n",
            "accuracy: 0.908750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.223172\n",
            "accuracy: 0.918750\n",
            "2018-10-30 19:59:13.257953\n",
            "---- EPOCH 060 EVALUATION ----\n",
            "eval mean loss: 0.365834\n",
            "eval accuracy: 0.891005\n",
            "eval avg class acc: 0.858314\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 061 ****\n",
            "2018-10-30 19:59:26.025067\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.210128\n",
            "accuracy: 0.927500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.254194\n",
            "accuracy: 0.923750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.227609\n",
            "accuracy: 0.926250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.273120\n",
            "accuracy: 0.912500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.216447\n",
            "accuracy: 0.931250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.267663\n",
            "accuracy: 0.910000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.255588\n",
            "accuracy: 0.907500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.255343\n",
            "accuracy: 0.908750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.263327\n",
            "accuracy: 0.907500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.210735\n",
            "accuracy: 0.925000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.262054\n",
            "accuracy: 0.911250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.237243\n",
            "accuracy: 0.921250\n",
            "2018-10-30 20:02:10.002109\n",
            "---- EPOCH 061 EVALUATION ----\n",
            "eval mean loss: 0.362526\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.870430\n",
            "**** EPOCH 062 ****\n",
            "2018-10-30 20:02:22.301994\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.228208\n",
            "accuracy: 0.927500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.247983\n",
            "accuracy: 0.933750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.216251\n",
            "accuracy: 0.925000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.218922\n",
            "accuracy: 0.918750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.227078\n",
            "accuracy: 0.908750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.232151\n",
            "accuracy: 0.906250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.234693\n",
            "accuracy: 0.923750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.253678\n",
            "accuracy: 0.911250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.212406\n",
            "accuracy: 0.921250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.242530\n",
            "accuracy: 0.921250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.229496\n",
            "accuracy: 0.925000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.204528\n",
            "accuracy: 0.931250\n",
            "2018-10-30 20:05:06.266432\n",
            "---- EPOCH 062 EVALUATION ----\n",
            "eval mean loss: 0.358295\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.864227\n",
            "**** EPOCH 063 ****\n",
            "2018-10-30 20:05:18.591519\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.237010\n",
            "accuracy: 0.922500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.210969\n",
            "accuracy: 0.923750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.167172\n",
            "accuracy: 0.941250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.256867\n",
            "accuracy: 0.915000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.243293\n",
            "accuracy: 0.913750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.184865\n",
            "accuracy: 0.936250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.277670\n",
            "accuracy: 0.911250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.252950\n",
            "accuracy: 0.920000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.216559\n",
            "accuracy: 0.925000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.242210\n",
            "accuracy: 0.912500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.283462\n",
            "accuracy: 0.903750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.236936\n",
            "accuracy: 0.917500\n",
            "2018-10-30 20:08:02.580468\n",
            "---- EPOCH 063 EVALUATION ----\n",
            "eval mean loss: 0.363997\n",
            "eval accuracy: 0.885332\n",
            "eval avg class acc: 0.857267\n",
            "**** EPOCH 064 ****\n",
            "2018-10-30 20:08:14.905437\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.237372\n",
            "accuracy: 0.923750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.213788\n",
            "accuracy: 0.928750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.214419\n",
            "accuracy: 0.932500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.233862\n",
            "accuracy: 0.921250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.235989\n",
            "accuracy: 0.913750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.191599\n",
            "accuracy: 0.933750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.223938\n",
            "accuracy: 0.920000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.219214\n",
            "accuracy: 0.928750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.251020\n",
            "accuracy: 0.907500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.199145\n",
            "accuracy: 0.930000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.217954\n",
            "accuracy: 0.923750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.211210\n",
            "accuracy: 0.922500\n",
            "2018-10-30 20:10:58.900845\n",
            "---- EPOCH 064 EVALUATION ----\n",
            "eval mean loss: 0.362384\n",
            "eval accuracy: 0.888169\n",
            "eval avg class acc: 0.857477\n",
            "**** EPOCH 065 ****\n",
            "2018-10-30 20:11:11.226875\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.204377\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.214162\n",
            "accuracy: 0.928750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.208643\n",
            "accuracy: 0.935000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.189751\n",
            "accuracy: 0.930000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.186133\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.214247\n",
            "accuracy: 0.926250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.287428\n",
            "accuracy: 0.902500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.225222\n",
            "accuracy: 0.928750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.229515\n",
            "accuracy: 0.925000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.247254\n",
            "accuracy: 0.913750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.243765\n",
            "accuracy: 0.923750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.245341\n",
            "accuracy: 0.916250\n",
            "2018-10-30 20:13:55.242793\n",
            "---- EPOCH 065 EVALUATION ----\n",
            "eval mean loss: 0.369795\n",
            "eval accuracy: 0.888979\n",
            "eval avg class acc: 0.857058\n",
            "**** EPOCH 066 ****\n",
            "2018-10-30 20:14:07.564615\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.250311\n",
            "accuracy: 0.922500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.253219\n",
            "accuracy: 0.915000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.207771\n",
            "accuracy: 0.927500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.194276\n",
            "accuracy: 0.926250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.226131\n",
            "accuracy: 0.927500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.243140\n",
            "accuracy: 0.915000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.268805\n",
            "accuracy: 0.907500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.217344\n",
            "accuracy: 0.923750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.184863\n",
            "accuracy: 0.938750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.230362\n",
            "accuracy: 0.921250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.203942\n",
            "accuracy: 0.922500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.224059\n",
            "accuracy: 0.921250\n",
            "2018-10-30 20:16:51.958361\n",
            "---- EPOCH 066 EVALUATION ----\n",
            "eval mean loss: 0.385001\n",
            "eval accuracy: 0.887358\n",
            "eval avg class acc: 0.860971\n",
            "**** EPOCH 067 ****\n",
            "2018-10-30 20:17:04.258415\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.190975\n",
            "accuracy: 0.930000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.169422\n",
            "accuracy: 0.945000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.194610\n",
            "accuracy: 0.942500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.199776\n",
            "accuracy: 0.933750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.220704\n",
            "accuracy: 0.926250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.225687\n",
            "accuracy: 0.926250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.171423\n",
            "accuracy: 0.931250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.223002\n",
            "accuracy: 0.927500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.267581\n",
            "accuracy: 0.912500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.210380\n",
            "accuracy: 0.925000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.191776\n",
            "accuracy: 0.927500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.233400\n",
            "accuracy: 0.923750\n",
            "2018-10-30 20:19:48.337181\n",
            "---- EPOCH 067 EVALUATION ----\n",
            "eval mean loss: 0.372654\n",
            "eval accuracy: 0.891005\n",
            "eval avg class acc: 0.858151\n",
            "**** EPOCH 068 ****\n",
            "2018-10-30 20:20:00.639418\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.191638\n",
            "accuracy: 0.936250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.208721\n",
            "accuracy: 0.922500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.214837\n",
            "accuracy: 0.931250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.184790\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.220664\n",
            "accuracy: 0.926250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.208783\n",
            "accuracy: 0.925000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.219680\n",
            "accuracy: 0.915000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.236855\n",
            "accuracy: 0.925000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.225884\n",
            "accuracy: 0.920000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.202021\n",
            "accuracy: 0.917500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.247055\n",
            "accuracy: 0.912500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.197990\n",
            "accuracy: 0.935000\n",
            "2018-10-30 20:22:44.937841\n",
            "---- EPOCH 068 EVALUATION ----\n",
            "eval mean loss: 0.364684\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.866599\n",
            "**** EPOCH 069 ****\n",
            "2018-10-30 20:22:57.307571\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.233748\n",
            "accuracy: 0.916250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.239721\n",
            "accuracy: 0.920000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.225414\n",
            "accuracy: 0.915000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.179935\n",
            "accuracy: 0.931250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.218617\n",
            "accuracy: 0.931250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.256308\n",
            "accuracy: 0.922500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.181759\n",
            "accuracy: 0.930000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.244545\n",
            "accuracy: 0.918750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.230570\n",
            "accuracy: 0.921250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.232427\n",
            "accuracy: 0.911250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.218587\n",
            "accuracy: 0.927500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.211962\n",
            "accuracy: 0.936250\n",
            "2018-10-30 20:25:41.624232\n",
            "---- EPOCH 069 EVALUATION ----\n",
            "eval mean loss: 0.352067\n",
            "eval accuracy: 0.897893\n",
            "eval avg class acc: 0.867099\n",
            "**** EPOCH 070 ****\n",
            "2018-10-30 20:25:53.966922\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.195086\n",
            "accuracy: 0.928750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.212537\n",
            "accuracy: 0.927500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.220082\n",
            "accuracy: 0.917500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.197316\n",
            "accuracy: 0.938750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.210239\n",
            "accuracy: 0.923750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.182409\n",
            "accuracy: 0.937500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.225877\n",
            "accuracy: 0.928750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.224534\n",
            "accuracy: 0.920000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.189332\n",
            "accuracy: 0.927500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.236904\n",
            "accuracy: 0.911250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.243381\n",
            "accuracy: 0.920000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.217962\n",
            "accuracy: 0.931250\n",
            "2018-10-30 20:28:38.394558\n",
            "---- EPOCH 070 EVALUATION ----\n",
            "eval mean loss: 0.356074\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.863099\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 071 ****\n",
            "2018-10-30 20:28:51.186499\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.188066\n",
            "accuracy: 0.926250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.227076\n",
            "accuracy: 0.921250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.209221\n",
            "accuracy: 0.923750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.184644\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.219237\n",
            "accuracy: 0.932500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.225783\n",
            "accuracy: 0.917500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.217509\n",
            "accuracy: 0.932500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.186846\n",
            "accuracy: 0.935000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.241977\n",
            "accuracy: 0.918750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.225974\n",
            "accuracy: 0.920000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.194535\n",
            "accuracy: 0.932500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.244440\n",
            "accuracy: 0.918750\n",
            "2018-10-30 20:31:35.400569\n",
            "---- EPOCH 071 EVALUATION ----\n",
            "eval mean loss: 0.364574\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.868570\n",
            "**** EPOCH 072 ****\n",
            "2018-10-30 20:31:47.774098\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.228517\n",
            "accuracy: 0.926250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.175811\n",
            "accuracy: 0.936250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.221995\n",
            "accuracy: 0.921250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.257032\n",
            "accuracy: 0.912500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.221620\n",
            "accuracy: 0.925000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.191929\n",
            "accuracy: 0.938750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.160125\n",
            "accuracy: 0.946250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.175542\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.205549\n",
            "accuracy: 0.922500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.217150\n",
            "accuracy: 0.920000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.209542\n",
            "accuracy: 0.922500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.179729\n",
            "accuracy: 0.933750\n",
            "2018-10-30 20:34:32.010031\n",
            "---- EPOCH 072 EVALUATION ----\n",
            "eval mean loss: 0.386746\n",
            "eval accuracy: 0.887763\n",
            "eval avg class acc: 0.859343\n",
            "**** EPOCH 073 ****\n",
            "2018-10-30 20:34:44.363057\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.181009\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.191752\n",
            "accuracy: 0.936250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.183037\n",
            "accuracy: 0.931250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.201219\n",
            "accuracy: 0.918750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.213276\n",
            "accuracy: 0.930000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.228101\n",
            "accuracy: 0.925000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.207590\n",
            "accuracy: 0.927500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.236471\n",
            "accuracy: 0.921250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.183353\n",
            "accuracy: 0.933750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.196878\n",
            "accuracy: 0.928750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.177234\n",
            "accuracy: 0.945000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.236727\n",
            "accuracy: 0.918750\n",
            "2018-10-30 20:37:28.514318\n",
            "---- EPOCH 073 EVALUATION ----\n",
            "eval mean loss: 0.388451\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.861267\n",
            "**** EPOCH 074 ****\n",
            "2018-10-30 20:37:40.821956\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.215483\n",
            "accuracy: 0.925000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.192682\n",
            "accuracy: 0.930000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.217350\n",
            "accuracy: 0.927500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.198044\n",
            "accuracy: 0.928750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.183894\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.226572\n",
            "accuracy: 0.918750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.203862\n",
            "accuracy: 0.933750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.205881\n",
            "accuracy: 0.930000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.213508\n",
            "accuracy: 0.920000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.222564\n",
            "accuracy: 0.917500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.239511\n",
            "accuracy: 0.908750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.176350\n",
            "accuracy: 0.930000\n",
            "2018-10-30 20:40:24.990334\n",
            "---- EPOCH 074 EVALUATION ----\n",
            "eval mean loss: 0.377731\n",
            "eval accuracy: 0.898298\n",
            "eval avg class acc: 0.867186\n",
            "**** EPOCH 075 ****\n",
            "2018-10-30 20:40:37.321091\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.190361\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.165004\n",
            "accuracy: 0.940000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.290903\n",
            "accuracy: 0.906250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.165761\n",
            "accuracy: 0.936250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.155815\n",
            "accuracy: 0.943750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.178010\n",
            "accuracy: 0.943750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.191504\n",
            "accuracy: 0.938750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.215031\n",
            "accuracy: 0.918750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.212819\n",
            "accuracy: 0.921250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.175302\n",
            "accuracy: 0.932500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.203419\n",
            "accuracy: 0.937500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.227815\n",
            "accuracy: 0.913750\n",
            "2018-10-30 20:43:21.132330\n",
            "---- EPOCH 075 EVALUATION ----\n",
            "eval mean loss: 0.387415\n",
            "eval accuracy: 0.888574\n",
            "eval avg class acc: 0.867895\n",
            "**** EPOCH 076 ****\n",
            "2018-10-30 20:43:33.425714\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.182524\n",
            "accuracy: 0.938750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.213670\n",
            "accuracy: 0.916250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.239661\n",
            "accuracy: 0.912500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.209909\n",
            "accuracy: 0.930000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.238319\n",
            "accuracy: 0.913750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.250544\n",
            "accuracy: 0.915000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.196273\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.189561\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.175247\n",
            "accuracy: 0.937500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.218363\n",
            "accuracy: 0.931250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.180447\n",
            "accuracy: 0.932500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.196540\n",
            "accuracy: 0.932500\n",
            "2018-10-30 20:46:17.447226\n",
            "---- EPOCH 076 EVALUATION ----\n",
            "eval mean loss: 0.384138\n",
            "eval accuracy: 0.891410\n",
            "eval avg class acc: 0.863814\n",
            "**** EPOCH 077 ****\n",
            "2018-10-30 20:46:29.752454\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.185641\n",
            "accuracy: 0.935000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.168904\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.293226\n",
            "accuracy: 0.920000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.178347\n",
            "accuracy: 0.928750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.192034\n",
            "accuracy: 0.928750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.225086\n",
            "accuracy: 0.930000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.190503\n",
            "accuracy: 0.940000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.243593\n",
            "accuracy: 0.925000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.224807\n",
            "accuracy: 0.925000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.197430\n",
            "accuracy: 0.925000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.225106\n",
            "accuracy: 0.920000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.187578\n",
            "accuracy: 0.948750\n",
            "2018-10-30 20:49:13.880280\n",
            "---- EPOCH 077 EVALUATION ----\n",
            "eval mean loss: 0.383169\n",
            "eval accuracy: 0.889384\n",
            "eval avg class acc: 0.868977\n",
            "**** EPOCH 078 ****\n",
            "2018-10-30 20:49:26.177988\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.160952\n",
            "accuracy: 0.935000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.215420\n",
            "accuracy: 0.931250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.195452\n",
            "accuracy: 0.931250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.203249\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.172054\n",
            "accuracy: 0.931250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.196927\n",
            "accuracy: 0.930000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.203317\n",
            "accuracy: 0.926250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.187132\n",
            "accuracy: 0.928750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.186240\n",
            "accuracy: 0.942500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.171534\n",
            "accuracy: 0.937500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.204064\n",
            "accuracy: 0.932500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.189984\n",
            "accuracy: 0.930000\n",
            "2018-10-30 20:52:10.041730\n",
            "---- EPOCH 078 EVALUATION ----\n",
            "eval mean loss: 0.372225\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873686\n",
            "**** EPOCH 079 ****\n",
            "2018-10-30 20:52:22.372742\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.202972\n",
            "accuracy: 0.935000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.167354\n",
            "accuracy: 0.942500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.173919\n",
            "accuracy: 0.933750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.171902\n",
            "accuracy: 0.941250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.192683\n",
            "accuracy: 0.937500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.183181\n",
            "accuracy: 0.936250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.183803\n",
            "accuracy: 0.933750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.185443\n",
            "accuracy: 0.932500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.213646\n",
            "accuracy: 0.926250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.222480\n",
            "accuracy: 0.913750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.164689\n",
            "accuracy: 0.941250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.249089\n",
            "accuracy: 0.912500\n",
            "2018-10-30 20:55:06.547569\n",
            "---- EPOCH 079 EVALUATION ----\n",
            "eval mean loss: 0.375299\n",
            "eval accuracy: 0.883306\n",
            "eval avg class acc: 0.858698\n",
            "**** EPOCH 080 ****\n",
            "2018-10-30 20:55:18.902700\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.183647\n",
            "accuracy: 0.923750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.170803\n",
            "accuracy: 0.941250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.222980\n",
            "accuracy: 0.931250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.169702\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.190099\n",
            "accuracy: 0.927500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.214228\n",
            "accuracy: 0.925000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.234465\n",
            "accuracy: 0.925000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.201283\n",
            "accuracy: 0.925000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.230907\n",
            "accuracy: 0.927500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.184591\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.174394\n",
            "accuracy: 0.933750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.208515\n",
            "accuracy: 0.930000\n",
            "2018-10-30 20:58:02.992321\n",
            "---- EPOCH 080 EVALUATION ----\n",
            "eval mean loss: 0.364111\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.867401\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 081 ****\n",
            "2018-10-30 20:58:15.725910\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.172892\n",
            "accuracy: 0.942500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.176028\n",
            "accuracy: 0.942500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.204902\n",
            "accuracy: 0.933750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.173739\n",
            "accuracy: 0.933750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.195397\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.175855\n",
            "accuracy: 0.938750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.214881\n",
            "accuracy: 0.927500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.189351\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.220175\n",
            "accuracy: 0.930000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.167830\n",
            "accuracy: 0.941250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.218780\n",
            "accuracy: 0.927500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.162047\n",
            "accuracy: 0.933750\n",
            "2018-10-30 21:00:59.623900\n",
            "---- EPOCH 081 EVALUATION ----\n",
            "eval mean loss: 0.367367\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.867052\n",
            "**** EPOCH 082 ****\n",
            "2018-10-30 21:01:11.958718\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.188770\n",
            "accuracy: 0.936250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.218983\n",
            "accuracy: 0.920000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.140869\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.187779\n",
            "accuracy: 0.928750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.174033\n",
            "accuracy: 0.937500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.195912\n",
            "accuracy: 0.935000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.184577\n",
            "accuracy: 0.942500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.179847\n",
            "accuracy: 0.946250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.173026\n",
            "accuracy: 0.931250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.192107\n",
            "accuracy: 0.938750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.144807\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.208300\n",
            "accuracy: 0.925000\n",
            "2018-10-30 21:03:55.940942\n",
            "---- EPOCH 082 EVALUATION ----\n",
            "eval mean loss: 0.372268\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.862262\n",
            "**** EPOCH 083 ****\n",
            "2018-10-30 21:04:08.248461\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.209200\n",
            "accuracy: 0.930000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.166744\n",
            "accuracy: 0.936250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.214522\n",
            "accuracy: 0.920000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.176994\n",
            "accuracy: 0.942500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.218645\n",
            "accuracy: 0.923750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.167229\n",
            "accuracy: 0.946250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.197919\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.162440\n",
            "accuracy: 0.938750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.164930\n",
            "accuracy: 0.943750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.176086\n",
            "accuracy: 0.932500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.167668\n",
            "accuracy: 0.941250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.167978\n",
            "accuracy: 0.938750\n",
            "2018-10-30 21:06:52.370461\n",
            "---- EPOCH 083 EVALUATION ----\n",
            "eval mean loss: 0.383132\n",
            "eval accuracy: 0.884522\n",
            "eval avg class acc: 0.862453\n",
            "**** EPOCH 084 ****\n",
            "2018-10-30 21:07:04.675640\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.176656\n",
            "accuracy: 0.930000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.142409\n",
            "accuracy: 0.948750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.139008\n",
            "accuracy: 0.951250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.193878\n",
            "accuracy: 0.937500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.167345\n",
            "accuracy: 0.937500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.167885\n",
            "accuracy: 0.937500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.171984\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.154163\n",
            "accuracy: 0.942500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.172963\n",
            "accuracy: 0.937500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.177785\n",
            "accuracy: 0.935000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.172779\n",
            "accuracy: 0.952500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.191246\n",
            "accuracy: 0.936250\n",
            "2018-10-30 21:09:48.628902\n",
            "---- EPOCH 084 EVALUATION ----\n",
            "eval mean loss: 0.367873\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.862936\n",
            "**** EPOCH 085 ****\n",
            "2018-10-30 21:10:00.987640\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.172692\n",
            "accuracy: 0.942500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.145897\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.146570\n",
            "accuracy: 0.940000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.183990\n",
            "accuracy: 0.928750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.177655\n",
            "accuracy: 0.938750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.176766\n",
            "accuracy: 0.936250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.181797\n",
            "accuracy: 0.935000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.182189\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.130118\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.206865\n",
            "accuracy: 0.925000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.214337\n",
            "accuracy: 0.928750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.169538\n",
            "accuracy: 0.937500\n",
            "2018-10-30 21:12:45.313675\n",
            "---- EPOCH 085 EVALUATION ----\n",
            "eval mean loss: 0.372524\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.867320\n",
            "**** EPOCH 086 ****\n",
            "2018-10-30 21:12:57.664377\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.141385\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.186838\n",
            "accuracy: 0.921250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.207730\n",
            "accuracy: 0.936250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.159579\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.177387\n",
            "accuracy: 0.935000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.173074\n",
            "accuracy: 0.948750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.176040\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.141700\n",
            "accuracy: 0.947500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.166087\n",
            "accuracy: 0.936250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.194404\n",
            "accuracy: 0.931250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.212249\n",
            "accuracy: 0.918750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.175001\n",
            "accuracy: 0.941250\n",
            "2018-10-30 21:15:41.867463\n",
            "---- EPOCH 086 EVALUATION ----\n",
            "eval mean loss: 0.379046\n",
            "eval accuracy: 0.891410\n",
            "eval avg class acc: 0.865192\n",
            "**** EPOCH 087 ****\n",
            "2018-10-30 21:15:54.195686\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.179900\n",
            "accuracy: 0.938750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.177135\n",
            "accuracy: 0.933750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.135028\n",
            "accuracy: 0.940000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.186885\n",
            "accuracy: 0.926250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.147337\n",
            "accuracy: 0.948750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.174750\n",
            "accuracy: 0.932500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.168744\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.176598\n",
            "accuracy: 0.935000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.185806\n",
            "accuracy: 0.938750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.194841\n",
            "accuracy: 0.927500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.209399\n",
            "accuracy: 0.931250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.152127\n",
            "accuracy: 0.945000\n",
            "2018-10-30 21:18:38.467639\n",
            "---- EPOCH 087 EVALUATION ----\n",
            "eval mean loss: 0.373072\n",
            "eval accuracy: 0.891005\n",
            "eval avg class acc: 0.866023\n",
            "**** EPOCH 088 ****\n",
            "2018-10-30 21:18:50.836936\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.135897\n",
            "accuracy: 0.953750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.136936\n",
            "accuracy: 0.947500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.157689\n",
            "accuracy: 0.942500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.188503\n",
            "accuracy: 0.927500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.146245\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.167547\n",
            "accuracy: 0.937500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.177283\n",
            "accuracy: 0.941250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.150637\n",
            "accuracy: 0.948750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.165230\n",
            "accuracy: 0.942500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.170769\n",
            "accuracy: 0.950000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.157421\n",
            "accuracy: 0.947500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.224561\n",
            "accuracy: 0.933750\n",
            "2018-10-30 21:21:34.971122\n",
            "---- EPOCH 088 EVALUATION ----\n",
            "eval mean loss: 0.379082\n",
            "eval accuracy: 0.887763\n",
            "eval avg class acc: 0.868227\n",
            "**** EPOCH 089 ****\n",
            "2018-10-30 21:21:47.261400\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.165835\n",
            "accuracy: 0.943750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.165598\n",
            "accuracy: 0.941250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.154147\n",
            "accuracy: 0.945000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.120105\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.169258\n",
            "accuracy: 0.938750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.203356\n",
            "accuracy: 0.931250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.186224\n",
            "accuracy: 0.938750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.158261\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.181748\n",
            "accuracy: 0.930000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.180296\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.164814\n",
            "accuracy: 0.937500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.174248\n",
            "accuracy: 0.940000\n",
            "2018-10-30 21:24:31.271584\n",
            "---- EPOCH 089 EVALUATION ----\n",
            "eval mean loss: 0.402887\n",
            "eval accuracy: 0.890600\n",
            "eval avg class acc: 0.866855\n",
            "**** EPOCH 090 ****\n",
            "2018-10-30 21:24:43.647321\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.156208\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.138687\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.168211\n",
            "accuracy: 0.948750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.185250\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.186274\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.199766\n",
            "accuracy: 0.932500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.186995\n",
            "accuracy: 0.926250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.189027\n",
            "accuracy: 0.931250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.157889\n",
            "accuracy: 0.948750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.148401\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.185871\n",
            "accuracy: 0.928750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.166453\n",
            "accuracy: 0.933750\n",
            "2018-10-30 21:27:27.685658\n",
            "---- EPOCH 090 EVALUATION ----\n",
            "eval mean loss: 0.379869\n",
            "eval accuracy: 0.893031\n",
            "eval avg class acc: 0.867355\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 091 ****\n",
            "2018-10-30 21:27:40.523953\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.174320\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.170077\n",
            "accuracy: 0.941250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.148659\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.137067\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.187060\n",
            "accuracy: 0.931250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.179927\n",
            "accuracy: 0.927500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.156095\n",
            "accuracy: 0.941250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.190531\n",
            "accuracy: 0.932500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.174313\n",
            "accuracy: 0.935000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.176357\n",
            "accuracy: 0.935000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.134400\n",
            "accuracy: 0.946250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.162488\n",
            "accuracy: 0.938750\n",
            "2018-10-30 21:30:24.555724\n",
            "---- EPOCH 091 EVALUATION ----\n",
            "eval mean loss: 0.370946\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.873267\n",
            "**** EPOCH 092 ****\n",
            "2018-10-30 21:30:36.867812\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.163581\n",
            "accuracy: 0.940000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.189051\n",
            "accuracy: 0.946250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.182100\n",
            "accuracy: 0.936250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.170267\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.174057\n",
            "accuracy: 0.943750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.155627\n",
            "accuracy: 0.945000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.168869\n",
            "accuracy: 0.940000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.128953\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.193640\n",
            "accuracy: 0.932500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.178363\n",
            "accuracy: 0.937500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.200300\n",
            "accuracy: 0.925000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.142979\n",
            "accuracy: 0.951250\n",
            "2018-10-30 21:33:21.170305\n",
            "---- EPOCH 092 EVALUATION ----\n",
            "eval mean loss: 0.368494\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.862512\n",
            "**** EPOCH 093 ****\n",
            "2018-10-30 21:33:33.508510\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.155550\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.140443\n",
            "accuracy: 0.950000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.173091\n",
            "accuracy: 0.941250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.150671\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.131985\n",
            "accuracy: 0.953750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.157386\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.170644\n",
            "accuracy: 0.940000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.158417\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.168637\n",
            "accuracy: 0.946250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.156857\n",
            "accuracy: 0.948750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.146349\n",
            "accuracy: 0.947500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.188532\n",
            "accuracy: 0.935000\n",
            "2018-10-30 21:36:17.629755\n",
            "---- EPOCH 093 EVALUATION ----\n",
            "eval mean loss: 0.380375\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.868692\n",
            "**** EPOCH 094 ****\n",
            "2018-10-30 21:36:29.969504\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.164581\n",
            "accuracy: 0.943750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.143883\n",
            "accuracy: 0.946250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.157667\n",
            "accuracy: 0.946250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.178274\n",
            "accuracy: 0.942500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.156572\n",
            "accuracy: 0.933750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.147433\n",
            "accuracy: 0.946250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.163352\n",
            "accuracy: 0.938750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.133258\n",
            "accuracy: 0.951250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.157848\n",
            "accuracy: 0.942500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.169954\n",
            "accuracy: 0.936250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.179525\n",
            "accuracy: 0.936250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.160207\n",
            "accuracy: 0.942500\n",
            "2018-10-30 21:39:14.289808\n",
            "---- EPOCH 094 EVALUATION ----\n",
            "eval mean loss: 0.365380\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.875320\n",
            "**** EPOCH 095 ****\n",
            "2018-10-30 21:39:26.686271\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.148468\n",
            "accuracy: 0.947500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.119647\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.145341\n",
            "accuracy: 0.948750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.184412\n",
            "accuracy: 0.940000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.167001\n",
            "accuracy: 0.938750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.164860\n",
            "accuracy: 0.937500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.135057\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.141097\n",
            "accuracy: 0.946250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.125752\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.207615\n",
            "accuracy: 0.932500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.159301\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.160510\n",
            "accuracy: 0.950000\n",
            "2018-10-30 21:42:10.845873\n",
            "---- EPOCH 095 EVALUATION ----\n",
            "eval mean loss: 0.377171\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.871227\n",
            "**** EPOCH 096 ****\n",
            "2018-10-30 21:42:23.165783\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.166756\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.151069\n",
            "accuracy: 0.938750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.168933\n",
            "accuracy: 0.945000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.143264\n",
            "accuracy: 0.945000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.160587\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.158302\n",
            "accuracy: 0.942500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.171041\n",
            "accuracy: 0.935000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.129602\n",
            "accuracy: 0.956250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.163381\n",
            "accuracy: 0.943750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.174818\n",
            "accuracy: 0.937500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.142260\n",
            "accuracy: 0.947500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.160006\n",
            "accuracy: 0.943750\n",
            "2018-10-30 21:45:07.460165\n",
            "---- EPOCH 096 EVALUATION ----\n",
            "eval mean loss: 0.385758\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.866849\n",
            "**** EPOCH 097 ****\n",
            "2018-10-30 21:45:19.803522\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.158217\n",
            "accuracy: 0.938750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.149457\n",
            "accuracy: 0.950000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.169104\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.161472\n",
            "accuracy: 0.941250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.183325\n",
            "accuracy: 0.930000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.139526\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.169133\n",
            "accuracy: 0.943750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.152013\n",
            "accuracy: 0.945000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.172592\n",
            "accuracy: 0.941250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.139033\n",
            "accuracy: 0.952500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.177528\n",
            "accuracy: 0.941250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.158842\n",
            "accuracy: 0.941250\n",
            "2018-10-30 21:48:04.523738\n",
            "---- EPOCH 097 EVALUATION ----\n",
            "eval mean loss: 0.374756\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.872552\n",
            "**** EPOCH 098 ****\n",
            "2018-10-30 21:48:16.869444\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.168827\n",
            "accuracy: 0.942500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.162437\n",
            "accuracy: 0.937500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.131976\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.146682\n",
            "accuracy: 0.946250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.167444\n",
            "accuracy: 0.941250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.165195\n",
            "accuracy: 0.938750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.165011\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.140191\n",
            "accuracy: 0.951250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.172602\n",
            "accuracy: 0.941250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.159517\n",
            "accuracy: 0.943750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.180672\n",
            "accuracy: 0.932500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.141842\n",
            "accuracy: 0.947500\n",
            "2018-10-30 21:51:01.472612\n",
            "---- EPOCH 098 EVALUATION ----\n",
            "eval mean loss: 0.376888\n",
            "eval accuracy: 0.899109\n",
            "eval avg class acc: 0.873227\n",
            "**** EPOCH 099 ****\n",
            "2018-10-30 21:51:13.858323\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.095057\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.178183\n",
            "accuracy: 0.943750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.173503\n",
            "accuracy: 0.937500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.138573\n",
            "accuracy: 0.946250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.139038\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.178734\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.156011\n",
            "accuracy: 0.948750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.127610\n",
            "accuracy: 0.956250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.140116\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.167836\n",
            "accuracy: 0.935000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.156118\n",
            "accuracy: 0.948750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.158703\n",
            "accuracy: 0.956250\n",
            "2018-10-30 21:53:58.397771\n",
            "---- EPOCH 099 EVALUATION ----\n",
            "eval mean loss: 0.405026\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.864436\n",
            "**** EPOCH 100 ****\n",
            "2018-10-30 21:54:10.795788\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.151820\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.185356\n",
            "accuracy: 0.936250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.155471\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.149210\n",
            "accuracy: 0.945000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.155699\n",
            "accuracy: 0.946250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.113232\n",
            "accuracy: 0.956250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.181733\n",
            "accuracy: 0.938750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.161390\n",
            "accuracy: 0.936250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.162139\n",
            "accuracy: 0.935000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.136015\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.179216\n",
            "accuracy: 0.938750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.163476\n",
            "accuracy: 0.940000\n",
            "2018-10-30 21:56:55.518210\n",
            "---- EPOCH 100 EVALUATION ----\n",
            "eval mean loss: 0.386498\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.872308\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 101 ****\n",
            "2018-10-30 21:57:08.339240\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.111640\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.152242\n",
            "accuracy: 0.938750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.165368\n",
            "accuracy: 0.936250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.165830\n",
            "accuracy: 0.940000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.156906\n",
            "accuracy: 0.946250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.137777\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.127585\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.168183\n",
            "accuracy: 0.936250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.142801\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.125614\n",
            "accuracy: 0.955000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.152655\n",
            "accuracy: 0.942500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.156569\n",
            "accuracy: 0.950000\n",
            "2018-10-30 21:59:52.883264\n",
            "---- EPOCH 101 EVALUATION ----\n",
            "eval mean loss: 0.385640\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.870965\n",
            "**** EPOCH 102 ****\n",
            "2018-10-30 22:00:05.233790\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.132399\n",
            "accuracy: 0.951250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.156798\n",
            "accuracy: 0.937500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.175699\n",
            "accuracy: 0.946250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.179953\n",
            "accuracy: 0.946250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.136233\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.147558\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.147291\n",
            "accuracy: 0.952500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.149472\n",
            "accuracy: 0.948750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.161096\n",
            "accuracy: 0.947500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.155067\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.153600\n",
            "accuracy: 0.941250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.155058\n",
            "accuracy: 0.948750\n",
            "2018-10-30 22:02:49.329516\n",
            "---- EPOCH 102 EVALUATION ----\n",
            "eval mean loss: 0.401253\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.873715\n",
            "**** EPOCH 103 ****\n",
            "2018-10-30 22:03:01.627577\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.157540\n",
            "accuracy: 0.945000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.140289\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.126963\n",
            "accuracy: 0.946250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.131544\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.141025\n",
            "accuracy: 0.938750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.139615\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.167269\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.167220\n",
            "accuracy: 0.938750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.147287\n",
            "accuracy: 0.952500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.161197\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.120661\n",
            "accuracy: 0.955000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.154416\n",
            "accuracy: 0.943750\n",
            "2018-10-30 22:05:45.811126\n",
            "---- EPOCH 103 EVALUATION ----\n",
            "eval mean loss: 0.399767\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.877064\n",
            "**** EPOCH 104 ****\n",
            "2018-10-30 22:05:58.145031\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.125279\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.137390\n",
            "accuracy: 0.952500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.162800\n",
            "accuracy: 0.938750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.122049\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.178895\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.166574\n",
            "accuracy: 0.942500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.121353\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.148307\n",
            "accuracy: 0.950000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.143423\n",
            "accuracy: 0.946250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.135869\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.140000\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.158359\n",
            "accuracy: 0.945000\n",
            "2018-10-30 22:08:42.416696\n",
            "---- EPOCH 104 EVALUATION ----\n",
            "eval mean loss: 0.397641\n",
            "eval accuracy: 0.888979\n",
            "eval avg class acc: 0.862733\n",
            "**** EPOCH 105 ****\n",
            "2018-10-30 22:08:54.734838\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.132162\n",
            "accuracy: 0.953750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.140712\n",
            "accuracy: 0.948750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.126312\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.132652\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.135868\n",
            "accuracy: 0.955000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.153348\n",
            "accuracy: 0.942500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.138935\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.176515\n",
            "accuracy: 0.935000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.112942\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.165671\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.131116\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.159086\n",
            "accuracy: 0.940000\n",
            "2018-10-30 22:11:39.080839\n",
            "---- EPOCH 105 EVALUATION ----\n",
            "eval mean loss: 0.399250\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.870552\n",
            "**** EPOCH 106 ****\n",
            "2018-10-30 22:11:51.399062\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.129128\n",
            "accuracy: 0.951250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.157097\n",
            "accuracy: 0.945000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.140120\n",
            "accuracy: 0.956250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.135402\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.144313\n",
            "accuracy: 0.948750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.196776\n",
            "accuracy: 0.930000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.157662\n",
            "accuracy: 0.945000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.148719\n",
            "accuracy: 0.942500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.131543\n",
            "accuracy: 0.948750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.131123\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.155638\n",
            "accuracy: 0.942500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.121274\n",
            "accuracy: 0.958750\n",
            "2018-10-30 22:14:35.610320\n",
            "---- EPOCH 106 EVALUATION ----\n",
            "eval mean loss: 0.411056\n",
            "eval accuracy: 0.886143\n",
            "eval avg class acc: 0.864023\n",
            "**** EPOCH 107 ****\n",
            "2018-10-30 22:14:47.912435\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.168652\n",
            "accuracy: 0.941250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.150116\n",
            "accuracy: 0.950000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.139911\n",
            "accuracy: 0.942500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.115740\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.143401\n",
            "accuracy: 0.957500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.124337\n",
            "accuracy: 0.952500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.166160\n",
            "accuracy: 0.941250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.146175\n",
            "accuracy: 0.940000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.144994\n",
            "accuracy: 0.952500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.140981\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.140177\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.130029\n",
            "accuracy: 0.956250\n",
            "2018-10-30 22:17:32.035023\n",
            "---- EPOCH 107 EVALUATION ----\n",
            "eval mean loss: 0.391421\n",
            "eval accuracy: 0.890600\n",
            "eval avg class acc: 0.867977\n",
            "**** EPOCH 108 ****\n",
            "2018-10-30 22:17:44.375530\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.112597\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113558\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.139493\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.126260\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.119964\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.124938\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.156638\n",
            "accuracy: 0.942500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.138536\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.132683\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.110849\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.133099\n",
            "accuracy: 0.957500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.119466\n",
            "accuracy: 0.953750\n",
            "2018-10-30 22:20:28.628857\n",
            "---- EPOCH 108 EVALUATION ----\n",
            "eval mean loss: 0.404656\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.870634\n",
            "**** EPOCH 109 ****\n",
            "2018-10-30 22:20:40.977345\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.118267\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.100585\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.163427\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.134372\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.133660\n",
            "accuracy: 0.943750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.170911\n",
            "accuracy: 0.943750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.118103\n",
            "accuracy: 0.956250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.146825\n",
            "accuracy: 0.946250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.137821\n",
            "accuracy: 0.938750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.135976\n",
            "accuracy: 0.952500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.144933\n",
            "accuracy: 0.938750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.125535\n",
            "accuracy: 0.953750\n",
            "2018-10-30 22:23:25.097624\n",
            "---- EPOCH 109 EVALUATION ----\n",
            "eval mean loss: 0.404904\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.865645\n",
            "**** EPOCH 110 ****\n",
            "2018-10-30 22:23:37.443306\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.149409\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.107340\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.152180\n",
            "accuracy: 0.946250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.149102\n",
            "accuracy: 0.946250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.152644\n",
            "accuracy: 0.946250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.138497\n",
            "accuracy: 0.946250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.150479\n",
            "accuracy: 0.953750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.152673\n",
            "accuracy: 0.945000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119115\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.170422\n",
            "accuracy: 0.943750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.134551\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.138955\n",
            "accuracy: 0.957500\n",
            "2018-10-30 22:26:21.577559\n",
            "---- EPOCH 110 EVALUATION ----\n",
            "eval mean loss: 0.403218\n",
            "eval accuracy: 0.891410\n",
            "eval avg class acc: 0.870436\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 111 ****\n",
            "2018-10-30 22:26:34.400898\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.133648\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.153631\n",
            "accuracy: 0.951250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.131888\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.148394\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.103208\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.132989\n",
            "accuracy: 0.952500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.149343\n",
            "accuracy: 0.945000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.158545\n",
            "accuracy: 0.936250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.154862\n",
            "accuracy: 0.945000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.130675\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.156421\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.143266\n",
            "accuracy: 0.951250\n",
            "2018-10-30 22:29:18.628197\n",
            "---- EPOCH 111 EVALUATION ----\n",
            "eval mean loss: 0.402546\n",
            "eval accuracy: 0.893031\n",
            "eval avg class acc: 0.862477\n",
            "**** EPOCH 112 ****\n",
            "2018-10-30 22:29:30.940456\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.140310\n",
            "accuracy: 0.948750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.160691\n",
            "accuracy: 0.947500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.130389\n",
            "accuracy: 0.956250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.125905\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.138948\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.145467\n",
            "accuracy: 0.953750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.143701\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.154822\n",
            "accuracy: 0.952500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.122292\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.173896\n",
            "accuracy: 0.940000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.100461\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.147859\n",
            "accuracy: 0.952500\n",
            "2018-10-30 22:32:15.022908\n",
            "---- EPOCH 112 EVALUATION ----\n",
            "eval mean loss: 0.414179\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.866523\n",
            "**** EPOCH 113 ****\n",
            "2018-10-30 22:32:27.356923\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.109595\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.144472\n",
            "accuracy: 0.947500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.143424\n",
            "accuracy: 0.945000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.164590\n",
            "accuracy: 0.937500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.089658\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.137826\n",
            "accuracy: 0.945000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.164406\n",
            "accuracy: 0.943750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.125638\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.116200\n",
            "accuracy: 0.952500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.160574\n",
            "accuracy: 0.931250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.125725\n",
            "accuracy: 0.951250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.159331\n",
            "accuracy: 0.937500\n",
            "2018-10-30 22:35:11.527172\n",
            "---- EPOCH 113 EVALUATION ----\n",
            "eval mean loss: 0.407277\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.877221\n",
            "**** EPOCH 114 ****\n",
            "2018-10-30 22:35:23.881951\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.123414\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.148578\n",
            "accuracy: 0.948750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.138254\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.137687\n",
            "accuracy: 0.945000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.139489\n",
            "accuracy: 0.948750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.111967\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.126007\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.117575\n",
            "accuracy: 0.948750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.146832\n",
            "accuracy: 0.948750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.139728\n",
            "accuracy: 0.947500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.152959\n",
            "accuracy: 0.948750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.131915\n",
            "accuracy: 0.958750\n",
            "2018-10-30 22:38:08.095085\n",
            "---- EPOCH 114 EVALUATION ----\n",
            "eval mean loss: 0.397818\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.876529\n",
            "**** EPOCH 115 ****\n",
            "2018-10-30 22:38:20.392629\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.133306\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.111355\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.151501\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.117058\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.152763\n",
            "accuracy: 0.940000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.143378\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.130791\n",
            "accuracy: 0.948750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.131176\n",
            "accuracy: 0.956250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.120539\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.142621\n",
            "accuracy: 0.950000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.135329\n",
            "accuracy: 0.947500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.110109\n",
            "accuracy: 0.958750\n",
            "2018-10-30 22:41:04.532207\n",
            "---- EPOCH 115 EVALUATION ----\n",
            "eval mean loss: 0.394252\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.872180\n",
            "**** EPOCH 116 ****\n",
            "2018-10-30 22:41:16.889627\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.149694\n",
            "accuracy: 0.951250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.194233\n",
            "accuracy: 0.943750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.094922\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.149113\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.131677\n",
            "accuracy: 0.951250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.147092\n",
            "accuracy: 0.943750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.141521\n",
            "accuracy: 0.956250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.128004\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.147899\n",
            "accuracy: 0.956250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.121109\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.126661\n",
            "accuracy: 0.957500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.150941\n",
            "accuracy: 0.948750\n",
            "2018-10-30 22:44:01.219740\n",
            "---- EPOCH 116 EVALUATION ----\n",
            "eval mean loss: 0.396053\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.876558\n",
            "**** EPOCH 117 ****\n",
            "2018-10-30 22:44:13.600562\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.146056\n",
            "accuracy: 0.937500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.122960\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.128566\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.131490\n",
            "accuracy: 0.952500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.154830\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.111420\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.133473\n",
            "accuracy: 0.953750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.108223\n",
            "accuracy: 0.956250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.134868\n",
            "accuracy: 0.943750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.129464\n",
            "accuracy: 0.947500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.142776\n",
            "accuracy: 0.948750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.145591\n",
            "accuracy: 0.946250\n",
            "2018-10-30 22:46:57.871570\n",
            "---- EPOCH 117 EVALUATION ----\n",
            "eval mean loss: 0.410317\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.865180\n",
            "**** EPOCH 118 ****\n",
            "2018-10-30 22:47:10.181334\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.109431\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.137742\n",
            "accuracy: 0.943750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.113490\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104962\n",
            "accuracy: 0.962500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.155171\n",
            "accuracy: 0.942500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.142735\n",
            "accuracy: 0.953750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.107736\n",
            "accuracy: 0.962500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.118826\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119203\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.123525\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.166409\n",
            "accuracy: 0.946250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.110290\n",
            "accuracy: 0.962500\n",
            "2018-10-30 22:49:54.497319\n",
            "---- EPOCH 118 EVALUATION ----\n",
            "eval mean loss: 0.414652\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.866477\n",
            "**** EPOCH 119 ****\n",
            "2018-10-30 22:50:06.917070\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.121004\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.136804\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.127832\n",
            "accuracy: 0.951250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.136281\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.132901\n",
            "accuracy: 0.953750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.143025\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.136067\n",
            "accuracy: 0.953750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.161470\n",
            "accuracy: 0.940000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.118312\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.126935\n",
            "accuracy: 0.947500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.135849\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.131963\n",
            "accuracy: 0.943750\n",
            "2018-10-30 22:52:51.189698\n",
            "---- EPOCH 119 EVALUATION ----\n",
            "eval mean loss: 0.410715\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.869012\n",
            "**** EPOCH 120 ****\n",
            "2018-10-30 22:53:03.546618\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.121288\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.125097\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.149115\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.120941\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.131311\n",
            "accuracy: 0.952500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.075354\n",
            "accuracy: 0.975000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.148651\n",
            "accuracy: 0.940000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.184825\n",
            "accuracy: 0.940000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119857\n",
            "accuracy: 0.953750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.158029\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.120077\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.140223\n",
            "accuracy: 0.946250\n",
            "2018-10-30 22:55:47.842224\n",
            "---- EPOCH 120 EVALUATION ----\n",
            "eval mean loss: 0.396967\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.871599\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 121 ****\n",
            "2018-10-30 22:56:00.668164\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.119352\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.129328\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.132285\n",
            "accuracy: 0.948750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.138621\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.123625\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.168266\n",
            "accuracy: 0.945000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.121040\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.118586\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.156977\n",
            "accuracy: 0.950000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.116785\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.131422\n",
            "accuracy: 0.945000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.144517\n",
            "accuracy: 0.943750\n",
            "2018-10-30 22:58:44.889007\n",
            "---- EPOCH 121 EVALUATION ----\n",
            "eval mean loss: 0.402392\n",
            "eval accuracy: 0.899514\n",
            "eval avg class acc: 0.871052\n",
            "**** EPOCH 122 ****\n",
            "2018-10-30 22:58:57.219107\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.127030\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.122406\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.115818\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.142621\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.137360\n",
            "accuracy: 0.955000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.124694\n",
            "accuracy: 0.950000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.107395\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.128283\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.139376\n",
            "accuracy: 0.943750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.115089\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.114271\n",
            "accuracy: 0.955000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.130891\n",
            "accuracy: 0.952500\n",
            "2018-10-30 23:01:41.583955\n",
            "---- EPOCH 122 EVALUATION ----\n",
            "eval mean loss: 0.399609\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.878517\n",
            "**** EPOCH 123 ****\n",
            "2018-10-30 23:01:53.910277\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.122799\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113257\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.123733\n",
            "accuracy: 0.957500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.133092\n",
            "accuracy: 0.943750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.131850\n",
            "accuracy: 0.955000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.128402\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.098438\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.100756\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.132715\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108821\n",
            "accuracy: 0.957500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.116391\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.103535\n",
            "accuracy: 0.962500\n",
            "2018-10-30 23:04:38.143305\n",
            "---- EPOCH 123 EVALUATION ----\n",
            "eval mean loss: 0.399761\n",
            "eval accuracy: 0.902755\n",
            "eval avg class acc: 0.877884\n",
            "**** EPOCH 124 ****\n",
            "2018-10-30 23:04:50.490479\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.146115\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.147975\n",
            "accuracy: 0.950000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.121551\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.135525\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.134529\n",
            "accuracy: 0.952500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.135353\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.135188\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.127156\n",
            "accuracy: 0.948750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.139130\n",
            "accuracy: 0.953750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108702\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.129428\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.115784\n",
            "accuracy: 0.952500\n",
            "2018-10-30 23:07:34.765274\n",
            "---- EPOCH 124 EVALUATION ----\n",
            "eval mean loss: 0.404082\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.873599\n",
            "**** EPOCH 125 ****\n",
            "2018-10-30 23:07:47.116911\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.109543\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.107554\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.112916\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.121762\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.121385\n",
            "accuracy: 0.946250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.108752\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.142853\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.117848\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.117026\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.102868\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.139738\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.133366\n",
            "accuracy: 0.950000\n",
            "2018-10-30 23:10:31.326192\n",
            "---- EPOCH 125 EVALUATION ----\n",
            "eval mean loss: 0.406207\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.871465\n",
            "**** EPOCH 126 ****\n",
            "2018-10-30 23:10:43.663527\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.103889\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.108012\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.148374\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082908\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.122181\n",
            "accuracy: 0.952500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.108079\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.137146\n",
            "accuracy: 0.951250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.125603\n",
            "accuracy: 0.951250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.129697\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108773\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095301\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.149071\n",
            "accuracy: 0.952500\n",
            "2018-10-30 23:13:27.734402\n",
            "---- EPOCH 126 EVALUATION ----\n",
            "eval mean loss: 0.402150\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873767\n",
            "**** EPOCH 127 ****\n",
            "2018-10-30 23:13:40.081282\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.123548\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.111904\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.111651\n",
            "accuracy: 0.960000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.121129\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.128728\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.140718\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.137787\n",
            "accuracy: 0.956250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.120478\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.113057\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.113603\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.147842\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.131717\n",
            "accuracy: 0.950000\n",
            "2018-10-30 23:16:24.306127\n",
            "---- EPOCH 127 EVALUATION ----\n",
            "eval mean loss: 0.403301\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.871017\n",
            "**** EPOCH 128 ****\n",
            "2018-10-30 23:16:36.654567\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.125172\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.126329\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.107967\n",
            "accuracy: 0.953750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.117296\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.130255\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.108676\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.090441\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.134080\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.094887\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.140831\n",
            "accuracy: 0.948750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.148585\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.105321\n",
            "accuracy: 0.958750\n",
            "2018-10-30 23:19:20.834873\n",
            "---- EPOCH 128 EVALUATION ----\n",
            "eval mean loss: 0.391853\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.872895\n",
            "**** EPOCH 129 ****\n",
            "2018-10-30 23:19:33.171620\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.118939\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.114057\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.129202\n",
            "accuracy: 0.956250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.118248\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.147555\n",
            "accuracy: 0.945000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.098301\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.108239\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.138794\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.123854\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.110863\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.130757\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.136067\n",
            "accuracy: 0.963750\n",
            "2018-10-30 23:22:17.324699\n",
            "---- EPOCH 129 EVALUATION ----\n",
            "eval mean loss: 0.403601\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.871017\n",
            "**** EPOCH 130 ****\n",
            "2018-10-30 23:22:29.614559\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099871\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.146308\n",
            "accuracy: 0.945000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.127417\n",
            "accuracy: 0.952500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.092234\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.126109\n",
            "accuracy: 0.943750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.176249\n",
            "accuracy: 0.935000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.094236\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.137706\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.113195\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.122223\n",
            "accuracy: 0.957500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.132587\n",
            "accuracy: 0.955000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.091817\n",
            "accuracy: 0.965000\n",
            "2018-10-30 23:25:13.615738\n",
            "---- EPOCH 130 EVALUATION ----\n",
            "eval mean loss: 0.395293\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.865442\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 131 ****\n",
            "2018-10-30 23:25:26.381232\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.123994\n",
            "accuracy: 0.955000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.107520\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.109848\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099531\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.122507\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.103993\n",
            "accuracy: 0.957500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.114345\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.115059\n",
            "accuracy: 0.952500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.125373\n",
            "accuracy: 0.956250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.116636\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.101648\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098061\n",
            "accuracy: 0.963750\n",
            "2018-10-30 23:28:10.602940\n",
            "---- EPOCH 131 EVALUATION ----\n",
            "eval mean loss: 0.398116\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.872971\n",
            "**** EPOCH 132 ****\n",
            "2018-10-30 23:28:22.910610\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.135634\n",
            "accuracy: 0.942500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.109585\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.118188\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.089664\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.102685\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.109609\n",
            "accuracy: 0.953750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.108917\n",
            "accuracy: 0.962500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.108765\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.110186\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.082911\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091580\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.138732\n",
            "accuracy: 0.953750\n",
            "2018-10-30 23:31:07.229561\n",
            "---- EPOCH 132 EVALUATION ----\n",
            "eval mean loss: 0.405193\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.864988\n",
            "**** EPOCH 133 ****\n",
            "2018-10-30 23:31:19.548865\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099094\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.091826\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.129811\n",
            "accuracy: 0.948750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.135770\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.122397\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.109292\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.136267\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.122663\n",
            "accuracy: 0.952500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.151363\n",
            "accuracy: 0.950000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.107756\n",
            "accuracy: 0.952500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.109723\n",
            "accuracy: 0.957500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.114974\n",
            "accuracy: 0.957500\n",
            "2018-10-30 23:34:03.796805\n",
            "---- EPOCH 133 EVALUATION ----\n",
            "eval mean loss: 0.403229\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.869930\n",
            "**** EPOCH 134 ****\n",
            "2018-10-30 23:34:16.139005\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.131241\n",
            "accuracy: 0.945000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113663\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.098471\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.108212\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.103307\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.087094\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.144341\n",
            "accuracy: 0.946250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.131247\n",
            "accuracy: 0.950000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.108769\n",
            "accuracy: 0.953750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.113633\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.107938\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.126004\n",
            "accuracy: 0.955000\n",
            "2018-10-30 23:37:00.464503\n",
            "---- EPOCH 134 EVALUATION ----\n",
            "eval mean loss: 0.406595\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.873930\n",
            "**** EPOCH 135 ****\n",
            "2018-10-30 23:37:12.802813\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.108827\n",
            "accuracy: 0.951250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.127627\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.105636\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.109367\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.130734\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.112105\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.092759\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.103269\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119110\n",
            "accuracy: 0.958750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.124235\n",
            "accuracy: 0.947500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.110786\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.118859\n",
            "accuracy: 0.951250\n",
            "2018-10-30 23:39:56.888564\n",
            "---- EPOCH 135 EVALUATION ----\n",
            "eval mean loss: 0.427546\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.867058\n",
            "**** EPOCH 136 ****\n",
            "2018-10-30 23:40:09.226812\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.106488\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.112471\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.154560\n",
            "accuracy: 0.943750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.109185\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.090161\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.151944\n",
            "accuracy: 0.943750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.122558\n",
            "accuracy: 0.946250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.122352\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.142185\n",
            "accuracy: 0.945000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.098843\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.129732\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100754\n",
            "accuracy: 0.968750\n",
            "2018-10-30 23:42:53.530224\n",
            "---- EPOCH 136 EVALUATION ----\n",
            "eval mean loss: 0.414079\n",
            "eval accuracy: 0.899109\n",
            "eval avg class acc: 0.875430\n",
            "**** EPOCH 137 ****\n",
            "2018-10-30 23:43:05.900187\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.117394\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.106639\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.084842\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.161679\n",
            "accuracy: 0.938750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.169834\n",
            "accuracy: 0.942500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.131258\n",
            "accuracy: 0.955000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.126089\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.108326\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.131048\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.104052\n",
            "accuracy: 0.955000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.101458\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.125313\n",
            "accuracy: 0.957500\n",
            "2018-10-30 23:45:50.176413\n",
            "---- EPOCH 137 EVALUATION ----\n",
            "eval mean loss: 0.420643\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.865180\n",
            "**** EPOCH 138 ****\n",
            "2018-10-30 23:46:02.511294\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.097595\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.116711\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.119093\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.097500\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.114840\n",
            "accuracy: 0.957500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.110316\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.133573\n",
            "accuracy: 0.956250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.115264\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.134264\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.135478\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.113755\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.091003\n",
            "accuracy: 0.963750\n",
            "2018-10-30 23:48:46.537449\n",
            "---- EPOCH 138 EVALUATION ----\n",
            "eval mean loss: 0.407793\n",
            "eval accuracy: 0.901945\n",
            "eval avg class acc: 0.877802\n",
            "**** EPOCH 139 ****\n",
            "2018-10-30 23:48:58.842523\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.093115\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.120508\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.119058\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.117656\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.169324\n",
            "accuracy: 0.945000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093906\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091003\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.124308\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.139908\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.147522\n",
            "accuracy: 0.946250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.125485\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100314\n",
            "accuracy: 0.960000\n",
            "2018-10-30 23:51:42.751984\n",
            "---- EPOCH 139 EVALUATION ----\n",
            "eval mean loss: 0.416199\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.874599\n",
            "**** EPOCH 140 ****\n",
            "2018-10-30 23:51:55.120080\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.108772\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.102923\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095134\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.119169\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.111143\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.098634\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.124894\n",
            "accuracy: 0.962500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.110771\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.127848\n",
            "accuracy: 0.947500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108809\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.132540\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.109216\n",
            "accuracy: 0.960000\n",
            "2018-10-30 23:54:39.202728\n",
            "---- EPOCH 140 EVALUATION ----\n",
            "eval mean loss: 0.412410\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.876930\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 141 ****\n",
            "2018-10-30 23:54:51.958274\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.105615\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.097932\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.108494\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.110647\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.104746\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.088023\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.127610\n",
            "accuracy: 0.948750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.113957\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.115437\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108041\n",
            "accuracy: 0.948750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097680\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.096006\n",
            "accuracy: 0.968750\n",
            "2018-10-30 23:57:36.096799\n",
            "---- EPOCH 141 EVALUATION ----\n",
            "eval mean loss: 0.414434\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.875145\n",
            "**** EPOCH 142 ****\n",
            "2018-10-30 23:57:48.482828\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.096575\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.105817\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.105836\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.087700\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.092477\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099731\n",
            "accuracy: 0.966250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.082326\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.100168\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.115276\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.086821\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.099733\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.136903\n",
            "accuracy: 0.950000\n",
            "2018-10-31 00:00:32.676181\n",
            "---- EPOCH 142 EVALUATION ----\n",
            "eval mean loss: 0.423264\n",
            "eval accuracy: 0.897893\n",
            "eval avg class acc: 0.869924\n",
            "**** EPOCH 143 ****\n",
            "2018-10-31 00:00:44.995396\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.117841\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.116640\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.089338\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.076499\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.114578\n",
            "accuracy: 0.958750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.118505\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.106495\n",
            "accuracy: 0.962500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.119080\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.079752\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108923\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.133559\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.107309\n",
            "accuracy: 0.957500\n",
            "2018-10-31 00:03:29.153764\n",
            "---- EPOCH 143 EVALUATION ----\n",
            "eval mean loss: 0.431660\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.876890\n",
            "**** EPOCH 144 ****\n",
            "2018-10-31 00:03:41.475545\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.112032\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.099740\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102235\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.115731\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.119784\n",
            "accuracy: 0.957500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.124324\n",
            "accuracy: 0.956250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.089811\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.116886\n",
            "accuracy: 0.958750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.121642\n",
            "accuracy: 0.956250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.077993\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.132484\n",
            "accuracy: 0.940000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.092660\n",
            "accuracy: 0.971250\n",
            "2018-10-31 00:06:25.481840\n",
            "---- EPOCH 144 EVALUATION ----\n",
            "eval mean loss: 0.417635\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.872605\n",
            "**** EPOCH 145 ****\n",
            "2018-10-31 00:06:37.847702\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.111743\n",
            "accuracy: 0.956250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113034\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.119944\n",
            "accuracy: 0.957500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082646\n",
            "accuracy: 0.980000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.105020\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.130640\n",
            "accuracy: 0.950000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.107385\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.101936\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.117479\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.090968\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.117225\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.116038\n",
            "accuracy: 0.946250\n",
            "2018-10-31 00:09:21.605406\n",
            "---- EPOCH 145 EVALUATION ----\n",
            "eval mean loss: 0.416996\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.880430\n",
            "**** EPOCH 146 ****\n",
            "2018-10-31 00:09:33.851250\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.084986\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074346\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.111363\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.127601\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.081403\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.101147\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.123422\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.113854\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.100375\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.115177\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.130585\n",
            "accuracy: 0.952500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.111528\n",
            "accuracy: 0.960000\n",
            "2018-10-31 00:12:17.576821\n",
            "---- EPOCH 146 EVALUATION ----\n",
            "eval mean loss: 0.414349\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.875890\n",
            "**** EPOCH 147 ****\n",
            "2018-10-31 00:12:29.858984\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.107370\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.117074\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.090003\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.124769\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.096164\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.120691\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.102038\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.066317\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.096240\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.088944\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.115348\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.105020\n",
            "accuracy: 0.961250\n",
            "2018-10-31 00:15:13.464875\n",
            "---- EPOCH 147 EVALUATION ----\n",
            "eval mean loss: 0.426392\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.870599\n",
            "**** EPOCH 148 ****\n",
            "2018-10-31 00:15:25.815235\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.115327\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.085520\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092062\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.121165\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.091692\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099057\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091230\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.080460\n",
            "accuracy: 0.973750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.114804\n",
            "accuracy: 0.956250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084287\n",
            "accuracy: 0.975000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.114719\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.099621\n",
            "accuracy: 0.958750\n",
            "2018-10-31 00:18:09.365036\n",
            "---- EPOCH 148 EVALUATION ----\n",
            "eval mean loss: 0.421092\n",
            "eval accuracy: 0.893031\n",
            "eval avg class acc: 0.867267\n",
            "**** EPOCH 149 ****\n",
            "2018-10-31 00:18:21.659147\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.089981\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.117128\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.116192\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099699\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.109198\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.122964\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.102302\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.094520\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.088425\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.126549\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.111095\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.096561\n",
            "accuracy: 0.967500\n",
            "2018-10-31 00:21:05.348172\n",
            "---- EPOCH 149 EVALUATION ----\n",
            "eval mean loss: 0.408371\n",
            "eval accuracy: 0.898298\n",
            "eval avg class acc: 0.874099\n",
            "**** EPOCH 150 ****\n",
            "2018-10-31 00:21:17.674863\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.107874\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.109261\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099209\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086705\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.104200\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.108122\n",
            "accuracy: 0.955000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.113606\n",
            "accuracy: 0.955000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.126964\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.065155\n",
            "accuracy: 0.977500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.106530\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.119750\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.114905\n",
            "accuracy: 0.958750\n",
            "2018-10-31 00:24:01.698674\n",
            "---- EPOCH 150 EVALUATION ----\n",
            "eval mean loss: 0.419187\n",
            "eval accuracy: 0.898298\n",
            "eval avg class acc: 0.870221\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 151 ****\n",
            "2018-10-31 00:24:14.509540\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099991\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113005\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.082377\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.115842\n",
            "accuracy: 0.956250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.103592\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.105538\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083240\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.096084\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.090149\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.130088\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097482\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.123032\n",
            "accuracy: 0.957500\n",
            "2018-10-31 00:26:58.630028\n",
            "---- EPOCH 151 EVALUATION ----\n",
            "eval mean loss: 0.418951\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.873517\n",
            "**** EPOCH 152 ****\n",
            "2018-10-31 00:27:10.937915\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.146905\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.096304\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.078729\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.093789\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.102149\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.094937\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.069743\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.115582\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.091505\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.082989\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.078427\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.086710\n",
            "accuracy: 0.966250\n",
            "2018-10-31 00:29:55.120293\n",
            "---- EPOCH 152 EVALUATION ----\n",
            "eval mean loss: 0.434241\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 153 ****\n",
            "2018-10-31 00:30:07.452757\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.108472\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.111982\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.096603\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.095333\n",
            "accuracy: 0.962500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.093049\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.125518\n",
            "accuracy: 0.955000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.110893\n",
            "accuracy: 0.951250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.113934\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.077399\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084438\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.102551\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098566\n",
            "accuracy: 0.970000\n",
            "2018-10-31 00:32:51.656761\n",
            "---- EPOCH 153 EVALUATION ----\n",
            "eval mean loss: 0.433903\n",
            "eval accuracy: 0.893031\n",
            "eval avg class acc: 0.870012\n",
            "**** EPOCH 154 ****\n",
            "2018-10-31 00:33:03.995936\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.115389\n",
            "accuracy: 0.955000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.109532\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.111756\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.117795\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.100919\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.085291\n",
            "accuracy: 0.973750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.104164\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.087295\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.120521\n",
            "accuracy: 0.952500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.087315\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.126157\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.106676\n",
            "accuracy: 0.960000\n",
            "2018-10-31 00:35:48.010327\n",
            "---- EPOCH 154 EVALUATION ----\n",
            "eval mean loss: 0.431420\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.870145\n",
            "**** EPOCH 155 ****\n",
            "2018-10-31 00:36:00.304215\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.112497\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.098432\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.086027\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.109349\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.111780\n",
            "accuracy: 0.958750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.092308\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083783\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.110697\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.089873\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.090342\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.104559\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.076513\n",
            "accuracy: 0.973750\n",
            "2018-10-31 00:38:44.452449\n",
            "---- EPOCH 155 EVALUATION ----\n",
            "eval mean loss: 0.437313\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.866727\n",
            "**** EPOCH 156 ****\n",
            "2018-10-31 00:38:56.762497\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.111925\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.072323\n",
            "accuracy: 0.977500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102048\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.089228\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.104679\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.103625\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.090582\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.076227\n",
            "accuracy: 0.973750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.087161\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.122924\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.106346\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.085878\n",
            "accuracy: 0.971250\n",
            "2018-10-31 00:41:40.932783\n",
            "---- EPOCH 156 EVALUATION ----\n",
            "eval mean loss: 0.439637\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.864808\n",
            "**** EPOCH 157 ****\n",
            "2018-10-31 00:41:53.276293\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.078652\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.108494\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.104098\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.071330\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.118778\n",
            "accuracy: 0.947500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078135\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083017\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.105301\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.139908\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.090655\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097076\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.134928\n",
            "accuracy: 0.961250\n",
            "2018-10-31 00:44:37.791927\n",
            "---- EPOCH 157 EVALUATION ----\n",
            "eval mean loss: 0.444792\n",
            "eval accuracy: 0.888979\n",
            "eval avg class acc: 0.865145\n",
            "**** EPOCH 158 ****\n",
            "2018-10-31 00:44:50.097398\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.086309\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.110059\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.100086\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.127547\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.086464\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093432\n",
            "accuracy: 0.962500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.132132\n",
            "accuracy: 0.948750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.095671\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119773\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.095715\n",
            "accuracy: 0.971250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.079901\n",
            "accuracy: 0.973750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.106341\n",
            "accuracy: 0.963750\n",
            "2018-10-31 00:47:34.278668\n",
            "---- EPOCH 158 EVALUATION ----\n",
            "eval mean loss: 0.434566\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.873145\n",
            "**** EPOCH 159 ****\n",
            "2018-10-31 00:47:46.661770\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.112124\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.096748\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095116\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.091200\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.112551\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.087627\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.132544\n",
            "accuracy: 0.951250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.102362\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.112234\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.075707\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.089143\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.090895\n",
            "accuracy: 0.976250\n",
            "2018-10-31 00:50:30.898923\n",
            "---- EPOCH 159 EVALUATION ----\n",
            "eval mean loss: 0.431335\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.875267\n",
            "**** EPOCH 160 ****\n",
            "2018-10-31 00:50:43.286200\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.103523\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.107382\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.108324\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.095503\n",
            "accuracy: 0.956250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.121601\n",
            "accuracy: 0.952500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.101939\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.105740\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.104421\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.133174\n",
            "accuracy: 0.958750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.141983\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091260\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100698\n",
            "accuracy: 0.966250\n",
            "2018-10-31 00:53:27.731928\n",
            "---- EPOCH 160 EVALUATION ----\n",
            "eval mean loss: 0.433343\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.870308\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 161 ****\n",
            "2018-10-31 00:53:40.549981\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.103943\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.071431\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095661\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.106623\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.118519\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.084874\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.112132\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.117904\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086010\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.091104\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.122266\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.111209\n",
            "accuracy: 0.955000\n",
            "2018-10-31 00:56:24.870395\n",
            "---- EPOCH 161 EVALUATION ----\n",
            "eval mean loss: 0.438775\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.868599\n",
            "**** EPOCH 162 ****\n",
            "2018-10-31 00:56:37.190593\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.113076\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.091552\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.127835\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.081837\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.103100\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.127471\n",
            "accuracy: 0.957500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088523\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.105747\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.110617\n",
            "accuracy: 0.962500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.110129\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091003\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.127030\n",
            "accuracy: 0.962500\n",
            "2018-10-31 00:59:21.568574\n",
            "---- EPOCH 162 EVALUATION ----\n",
            "eval mean loss: 0.435265\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.873721\n",
            "**** EPOCH 163 ****\n",
            "2018-10-31 00:59:33.869601\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.100647\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.081087\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.119312\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.123464\n",
            "accuracy: 0.952500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.100729\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.121494\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.114553\n",
            "accuracy: 0.951250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.102690\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.082424\n",
            "accuracy: 0.976250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.119669\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095101\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100215\n",
            "accuracy: 0.960000\n",
            "2018-10-31 01:02:18.263629\n",
            "---- EPOCH 163 EVALUATION ----\n",
            "eval mean loss: 0.429595\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 164 ****\n",
            "2018-10-31 01:02:30.608745\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.081034\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.094012\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092721\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.085313\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.109065\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099902\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086494\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.091860\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.093969\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.111459\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.080535\n",
            "accuracy: 0.976250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.101146\n",
            "accuracy: 0.963750\n",
            "2018-10-31 01:05:15.158192\n",
            "---- EPOCH 164 EVALUATION ----\n",
            "eval mean loss: 0.434266\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.870105\n",
            "**** EPOCH 165 ****\n",
            "2018-10-31 01:05:27.470977\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.092617\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074804\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.106537\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.098098\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.098804\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.120716\n",
            "accuracy: 0.950000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.094004\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.077040\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.098757\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.122896\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.086332\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.090569\n",
            "accuracy: 0.970000\n",
            "2018-10-31 01:08:11.750334\n",
            "---- EPOCH 165 EVALUATION ----\n",
            "eval mean loss: 0.426799\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.874395\n",
            "**** EPOCH 166 ****\n",
            "2018-10-31 01:08:24.104744\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.096842\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.087166\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099082\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.101109\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.085071\n",
            "accuracy: 0.977500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.094363\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.106858\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.076816\n",
            "accuracy: 0.971250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.098676\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.091803\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.092039\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.104333\n",
            "accuracy: 0.957500\n",
            "2018-10-31 01:11:08.543594\n",
            "---- EPOCH 166 EVALUATION ----\n",
            "eval mean loss: 0.426170\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.866936\n",
            "**** EPOCH 167 ****\n",
            "2018-10-31 01:11:20.904748\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.097745\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.077733\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092138\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.111097\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.142853\n",
            "accuracy: 0.947500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.092051\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.113152\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.066641\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.076593\n",
            "accuracy: 0.977500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.066687\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.080782\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.085567\n",
            "accuracy: 0.970000\n",
            "2018-10-31 01:14:05.465394\n",
            "---- EPOCH 167 EVALUATION ----\n",
            "eval mean loss: 0.432835\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.868936\n",
            "**** EPOCH 168 ****\n",
            "2018-10-31 01:14:17.814811\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087155\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.094206\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.077680\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.095315\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.094181\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.074083\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.101381\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.106262\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.085268\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.092233\n",
            "accuracy: 0.971250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.105794\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.073590\n",
            "accuracy: 0.971250\n",
            "2018-10-31 01:17:02.339728\n",
            "---- EPOCH 168 EVALUATION ----\n",
            "eval mean loss: 0.430982\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 169 ****\n",
            "2018-10-31 01:17:14.660794\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.084684\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.105270\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.091938\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086294\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.101994\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.104570\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.084142\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.095839\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.089889\n",
            "accuracy: 0.962500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.101889\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.131906\n",
            "accuracy: 0.951250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.087414\n",
            "accuracy: 0.970000\n",
            "2018-10-31 01:19:59.256219\n",
            "---- EPOCH 169 EVALUATION ----\n",
            "eval mean loss: 0.424673\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.875099\n",
            "**** EPOCH 170 ****\n",
            "2018-10-31 01:20:11.621085\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.082675\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.108514\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.089408\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.093332\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.115587\n",
            "accuracy: 0.953750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078626\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.106665\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.098872\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.089929\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.097492\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095862\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.113990\n",
            "accuracy: 0.962500\n",
            "2018-10-31 01:22:55.898840\n",
            "---- EPOCH 170 EVALUATION ----\n",
            "eval mean loss: 0.422949\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.868186\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 171 ****\n",
            "2018-10-31 01:23:08.708282\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.062984\n",
            "accuracy: 0.973750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.115229\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.100960\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082322\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.113589\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.094483\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.105693\n",
            "accuracy: 0.955000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.105114\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.106301\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.121051\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097227\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098986\n",
            "accuracy: 0.971250\n",
            "2018-10-31 01:25:53.272133\n",
            "---- EPOCH 171 EVALUATION ----\n",
            "eval mean loss: 0.427946\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873936\n",
            "**** EPOCH 172 ****\n",
            "2018-10-31 01:26:05.653500\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.072672\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.123563\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092108\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.118920\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.080867\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.088324\n",
            "accuracy: 0.973750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.095009\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.094551\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.084207\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.069294\n",
            "accuracy: 0.981250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095734\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.103318\n",
            "accuracy: 0.975000\n",
            "2018-10-31 01:28:49.862181\n",
            "---- EPOCH 172 EVALUATION ----\n",
            "eval mean loss: 0.428314\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.872517\n",
            "**** EPOCH 173 ****\n",
            "2018-10-31 01:29:02.189140\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.098588\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.098841\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.114529\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.106696\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.087062\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.089350\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088788\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.117112\n",
            "accuracy: 0.958750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.071389\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.098535\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.079102\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.099231\n",
            "accuracy: 0.967500\n",
            "2018-10-31 01:31:46.759430\n",
            "---- EPOCH 173 EVALUATION ----\n",
            "eval mean loss: 0.433414\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873977\n",
            "**** EPOCH 174 ****\n",
            "2018-10-31 01:31:59.140154\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.088659\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.069416\n",
            "accuracy: 0.977500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.087090\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104276\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.123326\n",
            "accuracy: 0.951250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093496\n",
            "accuracy: 0.962500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.092765\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.106358\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.075658\n",
            "accuracy: 0.981250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.101921\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097129\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.102925\n",
            "accuracy: 0.962500\n",
            "2018-10-31 01:34:43.813810\n",
            "---- EPOCH 174 EVALUATION ----\n",
            "eval mean loss: 0.438267\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.877186\n",
            "**** EPOCH 175 ****\n",
            "2018-10-31 01:34:56.147143\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.088952\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.065507\n",
            "accuracy: 0.978750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.103486\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.083548\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.092522\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.062300\n",
            "accuracy: 0.982500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.098671\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.089204\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.094053\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.080512\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.105504\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.089871\n",
            "accuracy: 0.967500\n",
            "2018-10-31 01:37:41.023599\n",
            "---- EPOCH 175 EVALUATION ----\n",
            "eval mean loss: 0.419688\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.875267\n",
            "**** EPOCH 176 ****\n",
            "2018-10-31 01:37:53.386207\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.107508\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.064274\n",
            "accuracy: 0.981250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.090471\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104381\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.083599\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.101426\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.101972\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.107061\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.073089\n",
            "accuracy: 0.982500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.099462\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.083982\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.096575\n",
            "accuracy: 0.968750\n",
            "2018-10-31 01:40:37.999418\n",
            "---- EPOCH 176 EVALUATION ----\n",
            "eval mean loss: 0.437767\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.872930\n",
            "**** EPOCH 177 ****\n",
            "2018-10-31 01:40:50.351415\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.114530\n",
            "accuracy: 0.955000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.094619\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.082996\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.081650\n",
            "accuracy: 0.978750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.086670\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.129031\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086302\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.109710\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.106199\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.111861\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.076885\n",
            "accuracy: 0.976250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.092578\n",
            "accuracy: 0.968750\n",
            "2018-10-31 01:43:34.845055\n",
            "---- EPOCH 177 EVALUATION ----\n",
            "eval mean loss: 0.428815\n",
            "eval accuracy: 0.899514\n",
            "eval avg class acc: 0.875849\n",
            "**** EPOCH 178 ****\n",
            "2018-10-31 01:43:47.229644\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099288\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.095788\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.101018\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.101994\n",
            "accuracy: 0.962500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.108954\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.086507\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086664\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.107738\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.103436\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.093003\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.103993\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.108247\n",
            "accuracy: 0.962500\n",
            "2018-10-31 01:46:31.765185\n",
            "---- EPOCH 178 EVALUATION ----\n",
            "eval mean loss: 0.429968\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.874936\n",
            "**** EPOCH 179 ****\n",
            "2018-10-31 01:46:44.104090\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085688\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.098152\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.087307\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.080787\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.077586\n",
            "accuracy: 0.973750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.073975\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.121318\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.064240\n",
            "accuracy: 0.980000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.078933\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.076655\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.085866\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100943\n",
            "accuracy: 0.963750\n",
            "2018-10-31 01:49:28.510589\n",
            "---- EPOCH 179 EVALUATION ----\n",
            "eval mean loss: 0.427026\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.870105\n",
            "**** EPOCH 180 ****\n",
            "2018-10-31 01:49:40.928693\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.105597\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.121522\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.105528\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.112548\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.109008\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.092789\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.085579\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.098788\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.083285\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.074230\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082568\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.111462\n",
            "accuracy: 0.957500\n",
            "2018-10-31 01:52:25.399945\n",
            "---- EPOCH 180 EVALUATION ----\n",
            "eval mean loss: 0.432520\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.874180\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 181 ****\n",
            "2018-10-31 01:52:38.209297\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.100119\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.105821\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.078868\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.064305\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071549\n",
            "accuracy: 0.975000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.089688\n",
            "accuracy: 0.966250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.081967\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.104370\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.102157\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.127774\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.081087\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.117216\n",
            "accuracy: 0.955000\n",
            "2018-10-31 01:55:22.685377\n",
            "---- EPOCH 181 EVALUATION ----\n",
            "eval mean loss: 0.425533\n",
            "eval accuracy: 0.899514\n",
            "eval avg class acc: 0.877849\n",
            "**** EPOCH 182 ****\n",
            "2018-10-31 01:55:35.013595\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.116869\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.080408\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092055\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099677\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.083001\n",
            "accuracy: 0.973750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.082296\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.072916\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.109482\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.112543\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.103841\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.086897\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.120534\n",
            "accuracy: 0.961250\n",
            "2018-10-31 01:58:19.414292\n",
            "---- EPOCH 182 EVALUATION ----\n",
            "eval mean loss: 0.441174\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.874227\n",
            "**** EPOCH 183 ****\n",
            "2018-10-31 01:58:31.746465\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.117785\n",
            "accuracy: 0.953750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.072416\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.075218\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.098923\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.101662\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.095816\n",
            "accuracy: 0.966250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.079588\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.096307\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.097586\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.102743\n",
            "accuracy: 0.955000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.108325\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.095085\n",
            "accuracy: 0.963750\n",
            "2018-10-31 02:01:16.245176\n",
            "---- EPOCH 183 EVALUATION ----\n",
            "eval mean loss: 0.434145\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.870977\n",
            "**** EPOCH 184 ****\n",
            "2018-10-31 02:01:28.606723\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.117919\n",
            "accuracy: 0.953750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.090453\n",
            "accuracy: 0.975000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.074192\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.121310\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.067717\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.091193\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.065909\n",
            "accuracy: 0.976250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.092485\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.096208\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084429\n",
            "accuracy: 0.971250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.089987\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.079820\n",
            "accuracy: 0.972500\n",
            "2018-10-31 02:04:13.261063\n",
            "---- EPOCH 184 EVALUATION ----\n",
            "eval mean loss: 0.441469\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.871762\n",
            "**** EPOCH 185 ****\n",
            "2018-10-31 02:04:25.618977\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.079613\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.112983\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.054352\n",
            "accuracy: 0.980000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.085928\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.093490\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.098501\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.075756\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.089209\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.094301\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.113721\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.125678\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.093353\n",
            "accuracy: 0.962500\n",
            "2018-10-31 02:07:10.301402\n",
            "---- EPOCH 185 EVALUATION ----\n",
            "eval mean loss: 0.435458\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.876099\n",
            "**** EPOCH 186 ****\n",
            "2018-10-31 02:07:22.680499\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.106079\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.080278\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.074113\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.108960\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.090036\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.071610\n",
            "accuracy: 0.975000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086681\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.093069\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080981\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.104762\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082778\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098670\n",
            "accuracy: 0.967500\n",
            "2018-10-31 02:10:07.047406\n",
            "---- EPOCH 186 EVALUATION ----\n",
            "eval mean loss: 0.438643\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.875349\n",
            "**** EPOCH 187 ****\n",
            "2018-10-31 02:10:19.454456\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.077420\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.089944\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.094467\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.088597\n",
            "accuracy: 0.975000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.099938\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.085073\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088495\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.075656\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.104335\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.095247\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.087269\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.095630\n",
            "accuracy: 0.966250\n",
            "2018-10-31 02:13:04.145656\n",
            "---- EPOCH 187 EVALUATION ----\n",
            "eval mean loss: 0.434064\n",
            "eval accuracy: 0.898298\n",
            "eval avg class acc: 0.876849\n",
            "**** EPOCH 188 ****\n",
            "2018-10-31 02:13:16.525769\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.076094\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.108512\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.101752\n",
            "accuracy: 0.953750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.084486\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.096970\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.090570\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088029\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.084537\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.082865\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.097519\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.086388\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.099521\n",
            "accuracy: 0.970000\n",
            "2018-10-31 02:16:00.954808\n",
            "---- EPOCH 188 EVALUATION ----\n",
            "eval mean loss: 0.440091\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.876849\n",
            "**** EPOCH 189 ****\n",
            "2018-10-31 02:16:13.286919\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087437\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.069679\n",
            "accuracy: 0.975000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.114000\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.097956\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.112918\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.090333\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.094799\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.076574\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.092378\n",
            "accuracy: 0.962500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.065022\n",
            "accuracy: 0.975000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.079824\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.107079\n",
            "accuracy: 0.961250\n",
            "2018-10-31 02:18:57.828375\n",
            "---- EPOCH 189 EVALUATION ----\n",
            "eval mean loss: 0.446502\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.876308\n",
            "**** EPOCH 190 ****\n",
            "2018-10-31 02:19:10.135116\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.068255\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.085351\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102880\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.087955\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.114321\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.087088\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.115194\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.083426\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.078561\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.086607\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.092381\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.080960\n",
            "accuracy: 0.976250\n",
            "2018-10-31 02:21:54.628439\n",
            "---- EPOCH 190 EVALUATION ----\n",
            "eval mean loss: 0.446390\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.870727\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 191 ****\n",
            "2018-10-31 02:22:07.454525\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.106452\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.092183\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.094612\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099189\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.079093\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.102991\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.060334\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.080010\n",
            "accuracy: 0.977500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.088151\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.076540\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.073250\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098667\n",
            "accuracy: 0.965000\n",
            "2018-10-31 02:24:51.762830\n",
            "---- EPOCH 191 EVALUATION ----\n",
            "eval mean loss: 0.437545\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.875308\n",
            "**** EPOCH 192 ****\n",
            "2018-10-31 02:25:04.131946\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085588\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.075170\n",
            "accuracy: 0.978750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.071053\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.072968\n",
            "accuracy: 0.978750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.081577\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.118033\n",
            "accuracy: 0.957500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.063982\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.067807\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.074158\n",
            "accuracy: 0.975000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.119289\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.090953\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.083422\n",
            "accuracy: 0.977500\n",
            "2018-10-31 02:27:48.814351\n",
            "---- EPOCH 192 EVALUATION ----\n",
            "eval mean loss: 0.434827\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.871477\n",
            "**** EPOCH 193 ****\n",
            "2018-10-31 02:28:01.213117\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.108628\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.090062\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.066194\n",
            "accuracy: 0.976250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.093983\n",
            "accuracy: 0.971250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.102190\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.076411\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.096275\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.064896\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.104427\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.069962\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.087357\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.072657\n",
            "accuracy: 0.963750\n",
            "2018-10-31 02:30:45.969914\n",
            "---- EPOCH 193 EVALUATION ----\n",
            "eval mean loss: 0.439955\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.874390\n",
            "**** EPOCH 194 ****\n",
            "2018-10-31 02:30:58.296806\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087620\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.071654\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102913\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.069732\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071458\n",
            "accuracy: 0.975000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.058469\n",
            "accuracy: 0.982500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091203\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.112161\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086562\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.106185\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.081551\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.083668\n",
            "accuracy: 0.968750\n",
            "2018-10-31 02:33:42.755824\n",
            "---- EPOCH 194 EVALUATION ----\n",
            "eval mean loss: 0.449069\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.876477\n",
            "**** EPOCH 195 ****\n",
            "2018-10-31 02:33:55.086981\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.088677\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.094341\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.064886\n",
            "accuracy: 0.975000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.090750\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.073750\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.066302\n",
            "accuracy: 0.981250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.084235\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.096319\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.108931\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.080238\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.072828\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.075104\n",
            "accuracy: 0.973750\n",
            "2018-10-31 02:36:39.291995\n",
            "---- EPOCH 195 EVALUATION ----\n",
            "eval mean loss: 0.441817\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873936\n",
            "**** EPOCH 196 ****\n",
            "2018-10-31 02:36:51.599470\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.086134\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.102068\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095885\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.092578\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.088371\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.060439\n",
            "accuracy: 0.973750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.098282\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.066217\n",
            "accuracy: 0.977500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.075211\n",
            "accuracy: 0.976250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.085643\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095296\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.114622\n",
            "accuracy: 0.955000\n",
            "2018-10-31 02:39:36.130044\n",
            "---- EPOCH 196 EVALUATION ----\n",
            "eval mean loss: 0.446995\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.876099\n",
            "**** EPOCH 197 ****\n",
            "2018-10-31 02:39:48.384026\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.083034\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.072132\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.079119\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.075524\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.066793\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.085359\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.066053\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.084066\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.093553\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.118063\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.077149\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.087282\n",
            "accuracy: 0.965000\n",
            "2018-10-31 02:42:32.778443\n",
            "---- EPOCH 197 EVALUATION ----\n",
            "eval mean loss: 0.444879\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.872186\n",
            "**** EPOCH 198 ****\n",
            "2018-10-31 02:42:45.038443\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.083067\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.082762\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102775\n",
            "accuracy: 0.960000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086706\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.081916\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078294\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083581\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.085009\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.090415\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.092479\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.088611\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098911\n",
            "accuracy: 0.965000\n",
            "2018-10-31 02:45:29.585633\n",
            "---- EPOCH 198 EVALUATION ----\n",
            "eval mean loss: 0.444215\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.872890\n",
            "**** EPOCH 199 ****\n",
            "2018-10-31 02:45:41.793371\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.093351\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.102771\n",
            "accuracy: 0.952500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.071366\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.087117\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.091307\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.072735\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.089474\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.073618\n",
            "accuracy: 0.977500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.100121\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.071542\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091748\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.101579\n",
            "accuracy: 0.961250\n",
            "2018-10-31 02:48:25.958987\n",
            "---- EPOCH 199 EVALUATION ----\n",
            "eval mean loss: 0.449449\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.873186\n",
            "**** EPOCH 200 ****\n",
            "2018-10-31 02:48:38.161533\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.091433\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.083940\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.101697\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082929\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.110864\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.072382\n",
            "accuracy: 0.975000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.095418\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.086216\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.063426\n",
            "accuracy: 0.975000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084110\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.088137\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.076845\n",
            "accuracy: 0.972500\n",
            "2018-10-31 02:51:21.952730\n",
            "---- EPOCH 200 EVALUATION ----\n",
            "eval mean loss: 0.439064\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.875395\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 201 ****\n",
            "2018-10-31 02:51:34.604003\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.075665\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.081560\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.073031\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.071350\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.101178\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078245\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.077617\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.080913\n",
            "accuracy: 0.971250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.093860\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.078705\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.094025\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.069860\n",
            "accuracy: 0.977500\n",
            "2018-10-31 02:54:18.237448\n",
            "---- EPOCH 201 EVALUATION ----\n",
            "eval mean loss: 0.437833\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.872558\n",
            "**** EPOCH 202 ****\n",
            "2018-10-31 02:54:30.473452\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.093091\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.084575\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099189\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.108153\n",
            "accuracy: 0.952500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071934\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093455\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.065821\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.098982\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.109511\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.090448\n",
            "accuracy: 0.963750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.079551\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.088845\n",
            "accuracy: 0.972500\n",
            "2018-10-31 02:57:14.868362\n",
            "---- EPOCH 202 EVALUATION ----\n",
            "eval mean loss: 0.436191\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.873977\n",
            "**** EPOCH 203 ****\n",
            "2018-10-31 02:57:27.131625\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.065768\n",
            "accuracy: 0.978750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.088599\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.086217\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086240\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.084958\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.080041\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091515\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.090420\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.108499\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.097391\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.073788\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.079772\n",
            "accuracy: 0.968750\n",
            "2018-10-31 03:00:11.726356\n",
            "---- EPOCH 203 EVALUATION ----\n",
            "eval mean loss: 0.441062\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.871355\n",
            "**** EPOCH 204 ****\n",
            "2018-10-31 03:00:23.966124\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087509\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.089722\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.103987\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.069896\n",
            "accuracy: 0.975000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.090081\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.067809\n",
            "accuracy: 0.980000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086293\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.063901\n",
            "accuracy: 0.980000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.094631\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.069272\n",
            "accuracy: 0.978750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.066426\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.080314\n",
            "accuracy: 0.971250\n",
            "2018-10-31 03:03:07.927520\n",
            "---- EPOCH 204 EVALUATION ----\n",
            "eval mean loss: 0.442351\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.874349\n",
            "**** EPOCH 205 ****\n",
            "2018-10-31 03:03:20.198160\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.074793\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.119220\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.077865\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.080838\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071871\n",
            "accuracy: 0.977500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.094350\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.075229\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.088128\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.088008\n",
            "accuracy: 0.962500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.080580\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.085147\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.071173\n",
            "accuracy: 0.977500\n",
            "2018-10-31 03:06:04.161612\n",
            "---- EPOCH 205 EVALUATION ----\n",
            "eval mean loss: 0.443121\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.873767\n",
            "**** EPOCH 206 ****\n",
            "2018-10-31 03:06:16.443605\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.072811\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.075629\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092725\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.102604\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.084808\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.089747\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.076409\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.079838\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086475\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.076268\n",
            "accuracy: 0.972500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.094503\n",
            "accuracy: 0.965000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.083880\n",
            "accuracy: 0.970000\n",
            "2018-10-31 03:09:00.612240\n",
            "---- EPOCH 206 EVALUATION ----\n",
            "eval mean loss: 0.445300\n",
            "eval accuracy: 0.897893\n",
            "eval avg class acc: 0.873390\n",
            "**** EPOCH 207 ****\n",
            "2018-10-31 03:09:12.885009\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.091501\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.068961\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.070198\n",
            "accuracy: 0.977500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.060518\n",
            "accuracy: 0.985000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.112822\n",
            "accuracy: 0.958750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.065620\n",
            "accuracy: 0.975000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086056\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.092617\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.068244\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.082447\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082905\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.077451\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:11:57.021432\n",
            "---- EPOCH 207 EVALUATION ----\n",
            "eval mean loss: 0.452326\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.871017\n",
            "**** EPOCH 208 ****\n",
            "2018-10-31 03:12:09.275086\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085752\n",
            "accuracy: 0.976250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.095952\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095608\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.080765\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.070606\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.079344\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.104072\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.093104\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080900\n",
            "accuracy: 0.975000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.058616\n",
            "accuracy: 0.986250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.114316\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.080448\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:14:53.792460\n",
            "---- EPOCH 208 EVALUATION ----\n",
            "eval mean loss: 0.445989\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.873767\n",
            "**** EPOCH 209 ****\n",
            "2018-10-31 03:15:06.059344\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.090860\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.088569\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.074260\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.088090\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.100723\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.071506\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.079043\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.082560\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080643\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.074733\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.099685\n",
            "accuracy: 0.965000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.052427\n",
            "accuracy: 0.982500\n",
            "2018-10-31 03:17:50.441593\n",
            "---- EPOCH 209 EVALUATION ----\n",
            "eval mean loss: 0.445703\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.873640\n",
            "**** EPOCH 210 ****\n",
            "2018-10-31 03:18:02.716061\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.076923\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.104846\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.082676\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.088423\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.094764\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.088219\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.075784\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.082730\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080520\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.106309\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.084445\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.085819\n",
            "accuracy: 0.966250\n",
            "2018-10-31 03:20:46.985117\n",
            "---- EPOCH 210 EVALUATION ----\n",
            "eval mean loss: 0.444480\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.872267\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 211 ****\n",
            "2018-10-31 03:20:59.712708\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.072686\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.082279\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.081033\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.088917\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.078475\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.076926\n",
            "accuracy: 0.966250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.097363\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.041761\n",
            "accuracy: 0.987500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.095425\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.109128\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.089737\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.077772\n",
            "accuracy: 0.963750\n",
            "2018-10-31 03:23:43.828509\n",
            "---- EPOCH 211 EVALUATION ----\n",
            "eval mean loss: 0.441283\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.870977\n",
            "**** EPOCH 212 ****\n",
            "2018-10-31 03:23:56.098537\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.070531\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.071248\n",
            "accuracy: 0.975000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.098282\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104793\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.086097\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099310\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.064826\n",
            "accuracy: 0.977500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.069236\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.099129\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.099973\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.085592\n",
            "accuracy: 0.965000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.073756\n",
            "accuracy: 0.970000\n",
            "2018-10-31 03:26:40.335841\n",
            "---- EPOCH 212 EVALUATION ----\n",
            "eval mean loss: 0.446269\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.876017\n",
            "**** EPOCH 213 ****\n",
            "2018-10-31 03:26:52.588209\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.074662\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.096004\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.079042\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.112697\n",
            "accuracy: 0.962500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.088293\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.092115\n",
            "accuracy: 0.962500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.093586\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.091709\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.076607\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.083005\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.078974\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.067386\n",
            "accuracy: 0.985000\n",
            "2018-10-31 03:29:36.996737\n",
            "---- EPOCH 213 EVALUATION ----\n",
            "eval mean loss: 0.441204\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.872977\n",
            "**** EPOCH 214 ****\n",
            "2018-10-31 03:29:49.303853\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.080530\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.070970\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.106031\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.079732\n",
            "accuracy: 0.975000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.074635\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078171\n",
            "accuracy: 0.977500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.103650\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.100532\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.093526\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084891\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.068375\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.073135\n",
            "accuracy: 0.973750\n",
            "2018-10-31 03:32:33.493732\n",
            "---- EPOCH 214 EVALUATION ----\n",
            "eval mean loss: 0.452773\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.874058\n",
            "**** EPOCH 215 ****\n",
            "2018-10-31 03:32:45.746323\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.081224\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.079044\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.067199\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.070478\n",
            "accuracy: 0.976250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.100367\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099163\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.098205\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.067501\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.096584\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.092641\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.055202\n",
            "accuracy: 0.983750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.068303\n",
            "accuracy: 0.976250\n",
            "2018-10-31 03:35:30.204508\n",
            "---- EPOCH 215 EVALUATION ----\n",
            "eval mean loss: 0.450171\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.874186\n",
            "**** EPOCH 216 ****\n",
            "2018-10-31 03:35:42.487466\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.096610\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.075962\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.085758\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.100940\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.082275\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.103496\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.058851\n",
            "accuracy: 0.977500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.087230\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.069349\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.096936\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.086829\n",
            "accuracy: 0.960000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.071028\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:38:26.748863\n",
            "---- EPOCH 216 EVALUATION ----\n",
            "eval mean loss: 0.450242\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.874895\n",
            "**** EPOCH 217 ****\n",
            "2018-10-31 03:38:39.040136\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087237\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.068709\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.078439\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.093703\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.078598\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.077184\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.090798\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.093837\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.060582\n",
            "accuracy: 0.980000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.085101\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.096870\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.077385\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:41:23.433540\n",
            "---- EPOCH 217 EVALUATION ----\n",
            "eval mean loss: 0.450011\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.873017\n",
            "**** EPOCH 218 ****\n",
            "2018-10-31 03:41:35.653932\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.074585\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.083539\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.078869\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082563\n",
            "accuracy: 0.971250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.076639\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.056357\n",
            "accuracy: 0.985000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086652\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.073050\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.075516\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.092039\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.062490\n",
            "accuracy: 0.976250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.081723\n",
            "accuracy: 0.968750\n",
            "2018-10-31 03:44:20.102155\n",
            "---- EPOCH 218 EVALUATION ----\n",
            "eval mean loss: 0.450296\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873971\n",
            "**** EPOCH 219 ****\n",
            "2018-10-31 03:44:32.435910\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.095888\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.070649\n",
            "accuracy: 0.977500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099099\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.091800\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.060967\n",
            "accuracy: 0.981250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083447\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.075408\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.075532\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.065327\n",
            "accuracy: 0.977500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.071295\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.110741\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.079820\n",
            "accuracy: 0.970000\n",
            "2018-10-31 03:47:16.832705\n",
            "---- EPOCH 219 EVALUATION ----\n",
            "eval mean loss: 0.452495\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 220 ****\n",
            "2018-10-31 03:47:29.136134\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.088357\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.067814\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.086460\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.084949\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.076523\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083648\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.069949\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.081633\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.085812\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.088292\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.077497\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.071969\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:50:13.650986\n",
            "---- EPOCH 220 EVALUATION ----\n",
            "eval mean loss: 0.447455\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.871890\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 221 ****\n",
            "2018-10-31 03:50:26.338710\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.098965\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.078427\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.069013\n",
            "accuracy: 0.976250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.078202\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.109772\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.082898\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.074822\n",
            "accuracy: 0.976250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.086743\n",
            "accuracy: 0.971250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.076357\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.102039\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095112\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.069550\n",
            "accuracy: 0.971250\n",
            "2018-10-31 03:53:10.688150\n",
            "---- EPOCH 221 EVALUATION ----\n",
            "eval mean loss: 0.449804\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.872599\n",
            "**** EPOCH 222 ****\n",
            "2018-10-31 03:53:22.994244\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.080036\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.086313\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.087808\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.072158\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.097335\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.063600\n",
            "accuracy: 0.980000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.096493\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.077750\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.081558\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.071790\n",
            "accuracy: 0.975000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.065088\n",
            "accuracy: 0.976250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100504\n",
            "accuracy: 0.961250\n",
            "2018-10-31 03:56:07.213903\n",
            "---- EPOCH 222 EVALUATION ----\n",
            "eval mean loss: 0.453552\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.871599\n",
            "**** EPOCH 223 ****\n",
            "2018-10-31 03:56:19.430753\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.095885\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.106913\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.074237\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.075007\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.083901\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.089147\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.061527\n",
            "accuracy: 0.973750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.099294\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.085982\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.063376\n",
            "accuracy: 0.981250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.063058\n",
            "accuracy: 0.978750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.085360\n",
            "accuracy: 0.968750\n",
            "2018-10-31 03:59:03.411025\n",
            "---- EPOCH 223 EVALUATION ----\n",
            "eval mean loss: 0.453607\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.870808\n",
            "**** EPOCH 224 ****\n",
            "2018-10-31 03:59:15.665420\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085907\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074361\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.084242\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.066572\n",
            "accuracy: 0.976250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.072506\n",
            "accuracy: 0.973750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.070659\n",
            "accuracy: 0.977500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.069556\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.061693\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.068294\n",
            "accuracy: 0.976250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.085548\n",
            "accuracy: 0.972500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.129021\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.092472\n",
            "accuracy: 0.962500\n",
            "2018-10-31 04:01:59.548530\n",
            "---- EPOCH 224 EVALUATION ----\n",
            "eval mean loss: 0.457231\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.870767\n",
            "**** EPOCH 225 ****\n",
            "2018-10-31 04:02:11.805730\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.051223\n",
            "accuracy: 0.985000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.088971\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.073481\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086533\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.082884\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.085434\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.084824\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.087012\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086423\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.077431\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.087443\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.070984\n",
            "accuracy: 0.975000\n",
            "2018-10-31 04:04:55.818834\n",
            "---- EPOCH 225 EVALUATION ----\n",
            "eval mean loss: 0.449469\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.874686\n",
            "**** EPOCH 226 ****\n",
            "2018-10-31 04:05:08.132886\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.082128\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.080122\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.083384\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.094711\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.084965\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.090735\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.047750\n",
            "accuracy: 0.983750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.092653\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.067354\n",
            "accuracy: 0.981250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.081756\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.099435\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.074385\n",
            "accuracy: 0.970000\n",
            "2018-10-31 04:07:52.247433\n",
            "---- EPOCH 226 EVALUATION ----\n",
            "eval mean loss: 0.459187\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.874849\n",
            "**** EPOCH 227 ****\n",
            "2018-10-31 04:08:04.567738\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.069234\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.071506\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.088179\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.067022\n",
            "accuracy: 0.978750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.063652\n",
            "accuracy: 0.982500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.102622\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088335\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.073912\n",
            "accuracy: 0.971250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086930\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.077391\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.081122\n",
            "accuracy: 0.977500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.067733\n",
            "accuracy: 0.977500\n",
            "2018-10-31 04:10:48.965162\n",
            "---- EPOCH 227 EVALUATION ----\n",
            "eval mean loss: 0.458740\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.871599\n",
            "**** EPOCH 228 ****\n",
            "2018-10-31 04:11:01.247881\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.064076\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.092031\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.049209\n",
            "accuracy: 0.985000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.081457\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.088161\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.076232\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091696\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.084166\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.078327\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.063225\n",
            "accuracy: 0.977500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.065940\n",
            "accuracy: 0.978750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.081027\n",
            "accuracy: 0.966250\n",
            "2018-10-31 04:13:45.556016\n",
            "---- EPOCH 228 EVALUATION ----\n",
            "eval mean loss: 0.458728\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.874599\n",
            "**** EPOCH 229 ****\n",
            "2018-10-31 04:13:57.869469\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.082583\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.095081\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.073893\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.061230\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.077027\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.070484\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083097\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.089607\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.082124\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.077592\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.084330\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.081683\n",
            "accuracy: 0.972500\n",
            "2018-10-31 04:16:42.287814\n",
            "---- EPOCH 229 EVALUATION ----\n",
            "eval mean loss: 0.456634\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.873349\n",
            "**** EPOCH 230 ****\n",
            "2018-10-31 04:16:54.552830\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099465\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.063523\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.081458\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.090576\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.087283\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.081616\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.059801\n",
            "accuracy: 0.981250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.062261\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086670\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.079683\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.074521\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.082265\n",
            "accuracy: 0.967500\n",
            "2018-10-31 04:19:38.763116\n",
            "---- EPOCH 230 EVALUATION ----\n",
            "eval mean loss: 0.460449\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.873686\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 231 ****\n",
            "2018-10-31 04:19:51.463999\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.064665\n",
            "accuracy: 0.980000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.085319\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.069738\n",
            "accuracy: 0.977500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.073740\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071968\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.066708\n",
            "accuracy: 0.982500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.062518\n",
            "accuracy: 0.976250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.075314\n",
            "accuracy: 0.973750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.095009\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.087020\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.084587\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.077521\n",
            "accuracy: 0.972500\n",
            "2018-10-31 04:22:35.733058\n",
            "---- EPOCH 231 EVALUATION ----\n",
            "eval mean loss: 0.457827\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.872517\n",
            "**** EPOCH 232 ****\n",
            "2018-10-31 04:22:48.045134\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.080297\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.083973\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.069373\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.079034\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.092807\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093664\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.074934\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.087138\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.101910\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.063563\n",
            "accuracy: 0.971250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.056466\n",
            "accuracy: 0.978750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.067593\n",
            "accuracy: 0.978750\n",
            "2018-10-31 04:25:32.167039\n",
            "---- EPOCH 232 EVALUATION ----\n",
            "eval mean loss: 0.459460\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.872599\n",
            "**** EPOCH 233 ****\n",
            "2018-10-31 04:25:44.446886\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.070586\n",
            "accuracy: 0.978750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.089490\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102004\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.071965\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.066600\n",
            "accuracy: 0.980000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083160\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.082054\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.078657\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080570\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.110972\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.080413\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.066506\n",
            "accuracy: 0.972500\n",
            "2018-10-31 04:28:28.526577\n",
            "---- EPOCH 233 EVALUATION ----\n",
            "eval mean loss: 0.459460\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.874390\n",
            "**** EPOCH 234 ****\n",
            "2018-10-31 04:28:40.753711\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.074571\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.066192\n",
            "accuracy: 0.977500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.090692\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082221\n",
            "accuracy: 0.976250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.062770\n",
            "accuracy: 0.977500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083896\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.073806\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.106349\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.091958\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.056816\n",
            "accuracy: 0.981250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082882\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.078044\n",
            "accuracy: 0.973750\n",
            "2018-10-31 04:31:24.613038\n",
            "---- EPOCH 234 EVALUATION ----\n",
            "eval mean loss: 0.462001\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.872017\n",
            "**** EPOCH 235 ****\n",
            "2018-10-31 04:31:36.867836\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.066924\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.063900\n",
            "accuracy: 0.975000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.064533\n",
            "accuracy: 0.980000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104111\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.059952\n",
            "accuracy: 0.978750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083551\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.080856\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.078525\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119828\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.070481\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091685\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.057651\n",
            "accuracy: 0.983750\n",
            "2018-10-31 04:34:20.750616\n",
            "---- EPOCH 235 EVALUATION ----\n",
            "eval mean loss: 0.459839\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 236 ****\n",
            "2018-10-31 04:34:33.026893\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.062489\n",
            "accuracy: 0.978750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.103968\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.089128\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.113063\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.087108\n",
            "accuracy: 0.973750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.073292\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.070295\n",
            "accuracy: 0.978750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.074644\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.081719\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.085601\n",
            "accuracy: 0.972500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.123467\n",
            "accuracy: 0.952500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.076031\n",
            "accuracy: 0.971250\n",
            "2018-10-31 04:37:16.968242\n",
            "---- EPOCH 236 EVALUATION ----\n",
            "eval mean loss: 0.456045\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.870099\n",
            "**** EPOCH 237 ****\n",
            "2018-10-31 04:37:29.227383\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085941\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074742\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.079486\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.111791\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.093560\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083420\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.082794\n",
            "accuracy: 0.973750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.091284\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.069516\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.088770\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.085690\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.093515\n",
            "accuracy: 0.973750\n",
            "2018-10-31 04:40:13.181497\n",
            "---- EPOCH 237 EVALUATION ----\n",
            "eval mean loss: 0.458868\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.872517\n",
            "**** EPOCH 238 ****\n",
            "2018-10-31 04:40:25.438118\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.104178\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.086701\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.086929\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099344\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.074585\n",
            "accuracy: 0.976250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.069713\n",
            "accuracy: 0.977500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.101977\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.085861\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.097172\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.068111\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.076050\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.063953\n",
            "accuracy: 0.978750\n",
            "2018-10-31 04:43:09.457875\n",
            "---- EPOCH 238 EVALUATION ----\n",
            "eval mean loss: 0.457023\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873895\n",
            "**** EPOCH 239 ****\n",
            "2018-10-31 04:43:21.691549\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.086875\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074125\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.059988\n",
            "accuracy: 0.981250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.080240\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.098691\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.082925\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.089326\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.097029\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.074543\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.086999\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.094962\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.080993\n",
            "accuracy: 0.972500\n",
            "2018-10-31 04:46:05.803373\n",
            "---- EPOCH 239 EVALUATION ----\n",
            "eval mean loss: 0.455870\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.871477\n",
            "**** EPOCH 240 ****\n",
            "2018-10-31 04:46:18.109725\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.095423\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.064290\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.077783\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.068221\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.086395\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.087110\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.071809\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.088583\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.089497\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.073027\n",
            "accuracy: 0.975000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091244\n",
            "accuracy: 0.965000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.062077\n",
            "accuracy: 0.977500\n",
            "2018-10-31 04:49:02.136417\n",
            "---- EPOCH 240 EVALUATION ----\n",
            "eval mean loss: 0.455987\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.874180\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 241 ****\n",
            "2018-10-31 04:49:14.840176\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.094367\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.083171\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.072158\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104299\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.088306\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.096555\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.058574\n",
            "accuracy: 0.977500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.065689\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.113263\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.098238\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.096177\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.092472\n",
            "accuracy: 0.967500\n",
            "2018-10-31 04:51:58.934473\n",
            "---- EPOCH 241 EVALUATION ----\n",
            "eval mean loss: 0.453782\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.872727\n",
            "**** EPOCH 242 ****\n",
            "2018-10-31 04:52:11.194851\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.081320\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.070351\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099291\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.077789\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.066425\n",
            "accuracy: 0.976250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.077059\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.100234\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.080291\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.085905\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.064297\n",
            "accuracy: 0.977500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082535\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.066129\n",
            "accuracy: 0.976250\n",
            "2018-10-31 04:54:55.301138\n",
            "---- EPOCH 242 EVALUATION ----\n",
            "eval mean loss: 0.451082\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.871895\n",
            "**** EPOCH 243 ****\n",
            "2018-10-31 04:55:07.566193\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.096314\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074050\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.061694\n",
            "accuracy: 0.975000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hrIjBOTwmMby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3768
        },
        "outputId": "c07081e6-c17f-4c4f-9188-56892b48ebc9"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2')\n",
        "\n",
        "!python evaluate.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/utils/pointnet_util.py:127: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "2018-10-31 05:29:54.430223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-31 05:29:54.430683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-10-31 05:29:54.430722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-10-31 05:29:55.383116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-31 05:29:55.383176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-10-31 05:29:55.383207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-10-31 05:29:55.383603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Model restored.\n",
            "Batch: 000, batch size: 16\n",
            "Batch: 001, batch size: 16\n",
            "Batch: 002, batch size: 16\n",
            "Batch: 003, batch size: 16\n",
            "Batch: 004, batch size: 16\n",
            "Batch: 005, batch size: 16\n",
            "Batch: 006, batch size: 16\n",
            "Batch: 007, batch size: 16\n",
            "Batch: 008, batch size: 16\n",
            "Batch: 009, batch size: 16\n",
            "Batch: 010, batch size: 16\n",
            "Batch: 011, batch size: 16\n",
            "Batch: 012, batch size: 16\n",
            "Batch: 013, batch size: 16\n",
            "Batch: 014, batch size: 16\n",
            "Batch: 015, batch size: 16\n",
            "Batch: 016, batch size: 16\n",
            "Batch: 017, batch size: 16\n",
            "Batch: 018, batch size: 16\n",
            "Batch: 019, batch size: 16\n",
            "Batch: 020, batch size: 16\n",
            "Batch: 021, batch size: 16\n",
            "Batch: 022, batch size: 16\n",
            "Batch: 023, batch size: 16\n",
            "Batch: 024, batch size: 16\n",
            "Batch: 025, batch size: 16\n",
            "Batch: 026, batch size: 16\n",
            "Batch: 027, batch size: 16\n",
            "Batch: 028, batch size: 16\n",
            "Batch: 029, batch size: 16\n",
            "Batch: 030, batch size: 16\n",
            "Batch: 031, batch size: 16\n",
            "Batch: 032, batch size: 16\n",
            "Batch: 033, batch size: 16\n",
            "Batch: 034, batch size: 16\n",
            "Batch: 035, batch size: 16\n",
            "Batch: 036, batch size: 16\n",
            "Batch: 037, batch size: 16\n",
            "Batch: 038, batch size: 16\n",
            "Batch: 039, batch size: 16\n",
            "Batch: 040, batch size: 16\n",
            "Batch: 041, batch size: 16\n",
            "Batch: 042, batch size: 16\n",
            "Batch: 043, batch size: 16\n",
            "Batch: 044, batch size: 16\n",
            "Batch: 045, batch size: 16\n",
            "Batch: 046, batch size: 16\n",
            "Batch: 047, batch size: 16\n",
            "Batch: 048, batch size: 16\n",
            "Batch: 049, batch size: 16\n",
            "Batch: 050, batch size: 16\n",
            "Batch: 051, batch size: 16\n",
            "Batch: 052, batch size: 16\n",
            "Batch: 053, batch size: 16\n",
            "Batch: 054, batch size: 16\n",
            "Batch: 055, batch size: 16\n",
            "Batch: 056, batch size: 16\n",
            "Batch: 057, batch size: 16\n",
            "Batch: 058, batch size: 16\n",
            "Batch: 059, batch size: 16\n",
            "Batch: 060, batch size: 16\n",
            "Batch: 061, batch size: 16\n",
            "Batch: 062, batch size: 16\n",
            "Batch: 063, batch size: 16\n",
            "Batch: 064, batch size: 16\n",
            "Batch: 065, batch size: 16\n",
            "Batch: 066, batch size: 16\n",
            "Batch: 067, batch size: 16\n",
            "Batch: 068, batch size: 16\n",
            "Batch: 069, batch size: 16\n",
            "Batch: 070, batch size: 16\n",
            "Batch: 071, batch size: 16\n",
            "Batch: 072, batch size: 16\n",
            "Batch: 073, batch size: 16\n",
            "Batch: 074, batch size: 16\n",
            "Batch: 075, batch size: 16\n",
            "Batch: 076, batch size: 16\n",
            "Batch: 077, batch size: 16\n",
            "Batch: 078, batch size: 16\n",
            "Batch: 079, batch size: 16\n",
            "Batch: 080, batch size: 16\n",
            "Batch: 081, batch size: 16\n",
            "Batch: 082, batch size: 16\n",
            "Batch: 083, batch size: 16\n",
            "Batch: 084, batch size: 16\n",
            "Batch: 085, batch size: 16\n",
            "Batch: 086, batch size: 16\n",
            "Batch: 087, batch size: 16\n",
            "Batch: 088, batch size: 16\n",
            "Batch: 089, batch size: 16\n",
            "Batch: 090, batch size: 16\n",
            "Batch: 091, batch size: 16\n",
            "Batch: 092, batch size: 16\n",
            "Batch: 093, batch size: 16\n",
            "Batch: 094, batch size: 16\n",
            "Batch: 095, batch size: 16\n",
            "Batch: 096, batch size: 16\n",
            "Batch: 097, batch size: 16\n",
            "Batch: 098, batch size: 16\n",
            "Batch: 099, batch size: 16\n",
            "Batch: 100, batch size: 16\n",
            "Batch: 101, batch size: 16\n",
            "Batch: 102, batch size: 16\n",
            "Batch: 103, batch size: 16\n",
            "Batch: 104, batch size: 16\n",
            "Batch: 105, batch size: 16\n",
            "Batch: 106, batch size: 16\n",
            "Batch: 107, batch size: 16\n",
            "Batch: 108, batch size: 16\n",
            "Batch: 109, batch size: 16\n",
            "Batch: 110, batch size: 16\n",
            "Batch: 111, batch size: 16\n",
            "Batch: 112, batch size: 16\n",
            "Batch: 113, batch size: 16\n",
            "Batch: 114, batch size: 16\n",
            "Batch: 115, batch size: 16\n",
            "Batch: 116, batch size: 16\n",
            "Batch: 117, batch size: 16\n",
            "Batch: 118, batch size: 16\n",
            "Batch: 119, batch size: 16\n",
            "Batch: 120, batch size: 16\n",
            "Batch: 121, batch size: 16\n",
            "Batch: 122, batch size: 16\n",
            "Batch: 123, batch size: 16\n",
            "Batch: 124, batch size: 16\n",
            "Batch: 125, batch size: 16\n",
            "Batch: 126, batch size: 16\n",
            "Batch: 127, batch size: 16\n",
            "Batch: 128, batch size: 16\n",
            "Batch: 129, batch size: 16\n",
            "Batch: 130, batch size: 16\n",
            "Batch: 131, batch size: 16\n",
            "Batch: 132, batch size: 16\n",
            "Batch: 133, batch size: 16\n",
            "Batch: 134, batch size: 16\n",
            "Batch: 135, batch size: 16\n",
            "Batch: 136, batch size: 16\n",
            "Batch: 137, batch size: 16\n",
            "Batch: 138, batch size: 16\n",
            "Batch: 139, batch size: 16\n",
            "Batch: 140, batch size: 16\n",
            "Batch: 141, batch size: 16\n",
            "Batch: 142, batch size: 16\n",
            "Batch: 143, batch size: 16\n",
            "Batch: 144, batch size: 16\n",
            "Batch: 145, batch size: 16\n",
            "Batch: 146, batch size: 16\n",
            "Batch: 147, batch size: 16\n",
            "Batch: 148, batch size: 16\n",
            "Batch: 149, batch size: 16\n",
            "Batch: 150, batch size: 16\n",
            "Batch: 151, batch size: 16\n",
            "Batch: 152, batch size: 16\n",
            "Batch: 153, batch size: 16\n",
            "Batch: 154, batch size: 4\n",
            "eval mean loss: 0.453525\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.873308\n",
            "  airplane:\t1.000\n",
            "   bathtub:\t0.940\n",
            "       bed:\t0.970\n",
            "     bench:\t0.800\n",
            " bookshelf:\t0.950\n",
            "    bottle:\t0.940\n",
            "      bowl:\t0.950\n",
            "       car:\t0.970\n",
            "     chair:\t0.970\n",
            "      cone:\t0.950\n",
            "       cup:\t0.800\n",
            "   curtain:\t0.850\n",
            "      desk:\t0.860\n",
            "      door:\t0.950\n",
            "   dresser:\t0.663\n",
            "flower_pot:\t0.200\n",
            " glass_box:\t0.940\n",
            "    guitar:\t1.000\n",
            "  keyboard:\t1.000\n",
            "      lamp:\t0.850\n",
            "    laptop:\t1.000\n",
            "    mantel:\t0.970\n",
            "   monitor:\t0.980\n",
            "night_stand:\t0.779\n",
            "    person:\t0.850\n",
            "     piano:\t0.960\n",
            "     plant:\t0.750\n",
            "     radio:\t0.800\n",
            "range_hood:\t0.930\n",
            "      sink:\t0.850\n",
            "      sofa:\t0.930\n",
            "    stairs:\t0.950\n",
            "     stool:\t0.750\n",
            "     table:\t0.790\n",
            "      tent:\t0.950\n",
            "    toilet:\t0.990\n",
            "  tv_stand:\t0.860\n",
            "      vase:\t0.740\n",
            "  wardrobe:\t0.850\n",
            "      xbox:\t0.700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HrqElhJv4U6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urpBMxFMwZp0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running tensorboard with the pointnet 2 result\n",
        "https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/"
      ]
    },
    {
      "metadata": {
        "id": "IQr6PJmEyDoA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "7fbfba6c-044b-43dd-803d-37aad0b03e1b"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-31 07:30:54--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.199.255.1, 34.196.237.103, 52.204.188.97, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.199.255.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  6.36MB/s    in 0.8s    \n",
            "\n",
            "2018-10-31 07:30:56 (6.36 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4zqMn0V3yHfl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2')\n",
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet2/pointnet2')\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7Et00urGZpi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6007 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSEyxJBXFwKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2eecc9c6-0580-4f28-dd16-d7f4f8b44084"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://c0859e76.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v-_9M7rBJWlj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jQsVx4w1JYHY"
      },
      "cell_type": "markdown",
      "source": [
        "## Running 3DmFV-Net\n",
        "\n",
        "Mount the google drive and point to the folder containing the train.py and run the code from there with a slight modification.\n"
      ]
    },
    {
      "metadata": {
        "id": "VdXudP48JjqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 19704
        },
        "outputId": "a33c68f3-8650-4bd6-b63e-c217d1ecef60"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/3DmFV-Net-master')\n",
        "#os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/')\n",
        "\n",
        "\n",
        "!python train_cls.py --gpu=0 #--batch_size=128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Modelnet40\n",
            "Log dir already exists! creating a new one..............\n",
            "New log dir:log/modelnet40/3dmfv_net_cls/grid5_log_trial/2\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/KE5208_Sense_Making/Code/3DmFV-Net-master/utils/tf_util.py:606: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:224: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:201: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/KE5208_Sense_Making/Code/3DmFV-Net-master/utils/tf_util.py:637: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "2018-11-03 03:49:51.995228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-03 03:49:51.995721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-11-03 03:49:51.995764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-03 03:49:52.413884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-03 03:49:52.413938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-03 03:49:52.413971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-03 03:49:52.414284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.035065\n",
            "accuracy: 0.250000\n",
            "----1-----\n",
            "mean loss: 2.325030\n",
            "accuracy: 0.413750\n",
            "----2-----\n",
            "mean loss: 2.026811\n",
            "accuracy: 0.484375\n",
            "----3-----\n",
            "mean loss: 1.860796\n",
            "accuracy: 0.506348\n",
            "----4-----\n",
            "mean loss: 1.663190\n",
            "accuracy: 0.555664\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.437027\n",
            "eval accuracy: 0.579770\n",
            "eval avg class acc: 0.446590\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/2/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 1.540614\n",
            "accuracy: 0.573730\n",
            "----1-----\n",
            "mean loss: 1.442804\n",
            "accuracy: 0.602051\n",
            "----2-----\n",
            "mean loss: 1.319169\n",
            "accuracy: 0.635625\n",
            "----3-----\n",
            "mean loss: 1.291756\n",
            "accuracy: 0.643555\n",
            "----4-----\n",
            "mean loss: 1.263968\n",
            "accuracy: 0.631348\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.009068\n",
            "eval accuracy: 0.695312\n",
            "eval avg class acc: 0.593021\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.194833\n",
            "accuracy: 0.662109\n",
            "----1-----\n",
            "mean loss: 1.174994\n",
            "accuracy: 0.669434\n",
            "----2-----\n",
            "mean loss: 1.121332\n",
            "accuracy: 0.680664\n",
            "----3-----\n",
            "mean loss: 1.100769\n",
            "accuracy: 0.678711\n",
            "----4-----\n",
            "mean loss: 1.007820\n",
            "accuracy: 0.704375\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.903456\n",
            "eval accuracy: 0.738487\n",
            "eval avg class acc: 0.630600\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.026530\n",
            "accuracy: 0.709473\n",
            "----1-----\n",
            "mean loss: 0.968686\n",
            "accuracy: 0.707500\n",
            "----2-----\n",
            "mean loss: 0.988112\n",
            "accuracy: 0.706543\n",
            "----3-----\n",
            "mean loss: 0.957553\n",
            "accuracy: 0.713867\n",
            "----4-----\n",
            "mean loss: 0.975446\n",
            "accuracy: 0.725586\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.715919\n",
            "eval accuracy: 0.783717\n",
            "eval avg class acc: 0.658323\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 0.900922\n",
            "accuracy: 0.729492\n",
            "----1-----\n",
            "mean loss: 0.894250\n",
            "accuracy: 0.728516\n",
            "----2-----\n",
            "mean loss: 0.854230\n",
            "accuracy: 0.743750\n",
            "----3-----\n",
            "mean loss: 0.877140\n",
            "accuracy: 0.731445\n",
            "----4-----\n",
            "mean loss: 0.919491\n",
            "accuracy: 0.718750\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.684615\n",
            "eval accuracy: 0.792763\n",
            "eval avg class acc: 0.685580\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 0.802650\n",
            "accuracy: 0.746250\n",
            "----1-----\n",
            "mean loss: 0.805344\n",
            "accuracy: 0.757324\n",
            "----2-----\n",
            "mean loss: 0.845675\n",
            "accuracy: 0.729980\n",
            "----3-----\n",
            "mean loss: 0.847950\n",
            "accuracy: 0.742676\n",
            "----4-----\n",
            "mean loss: 0.835730\n",
            "accuracy: 0.754883\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.689604\n",
            "eval accuracy: 0.788651\n",
            "eval avg class acc: 0.693886\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 0.799347\n",
            "accuracy: 0.755000\n",
            "----1-----\n",
            "mean loss: 0.810585\n",
            "accuracy: 0.752441\n",
            "----2-----\n",
            "mean loss: 0.830819\n",
            "accuracy: 0.754395\n",
            "----3-----\n",
            "mean loss: 0.750425\n",
            "accuracy: 0.768066\n",
            "----4-----\n",
            "mean loss: 0.761304\n",
            "accuracy: 0.764648\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.631512\n",
            "eval accuracy: 0.807155\n",
            "eval avg class acc: 0.724739\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 0.753564\n",
            "accuracy: 0.772461\n",
            "----1-----\n",
            "mean loss: 0.726723\n",
            "accuracy: 0.774414\n",
            "----2-----\n",
            "mean loss: 0.726289\n",
            "accuracy: 0.765625\n",
            "----3-----\n",
            "mean loss: 0.747693\n",
            "accuracy: 0.763184\n",
            "----4-----\n",
            "mean loss: 0.769758\n",
            "accuracy: 0.764160\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.554761\n",
            "eval accuracy: 0.831826\n",
            "eval avg class acc: 0.755977\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 0.688368\n",
            "accuracy: 0.790039\n",
            "----1-----\n",
            "mean loss: 0.680404\n",
            "accuracy: 0.794434\n",
            "----2-----\n",
            "mean loss: 0.751038\n",
            "accuracy: 0.767090\n",
            "----3-----\n",
            "mean loss: 0.689001\n",
            "accuracy: 0.791250\n",
            "----4-----\n",
            "mean loss: 0.727130\n",
            "accuracy: 0.773438\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.574485\n",
            "eval accuracy: 0.830592\n",
            "eval avg class acc: 0.756190\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.676516\n",
            "accuracy: 0.789551\n",
            "----1-----\n",
            "mean loss: 0.666796\n",
            "accuracy: 0.780000\n",
            "----2-----\n",
            "mean loss: 0.684547\n",
            "accuracy: 0.782715\n",
            "----3-----\n",
            "mean loss: 0.683849\n",
            "accuracy: 0.791992\n",
            "----4-----\n",
            "mean loss: 0.652971\n",
            "accuracy: 0.794434\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.526747\n",
            "eval accuracy: 0.840461\n",
            "eval avg class acc: 0.769309\n",
            "**** EPOCH 010 ****\n",
            "----0-----\n",
            "mean loss: 0.639579\n",
            "accuracy: 0.811035\n",
            "----1-----\n",
            "mean loss: 0.569767\n",
            "accuracy: 0.811523\n",
            "----2-----\n",
            "mean loss: 0.614522\n",
            "accuracy: 0.793945\n",
            "----3-----\n",
            "mean loss: 0.654911\n",
            "accuracy: 0.792969\n",
            "----4-----\n",
            "mean loss: 0.633910\n",
            "accuracy: 0.800625\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.521939\n",
            "eval accuracy: 0.839227\n",
            "eval avg class acc: 0.770281\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/2/model.ckpt\n",
            "**** EPOCH 011 ****\n",
            "----0-----\n",
            "mean loss: 0.628671\n",
            "accuracy: 0.796387\n",
            "----1-----\n",
            "mean loss: 0.570890\n",
            "accuracy: 0.805625\n",
            "----2-----\n",
            "mean loss: 0.637914\n",
            "accuracy: 0.797852\n",
            "----3-----\n",
            "mean loss: 0.629292\n",
            "accuracy: 0.801270\n",
            "----4-----\n",
            "mean loss: 0.669925\n",
            "accuracy: 0.795898\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.564169\n",
            "eval accuracy: 0.834704\n",
            "eval avg class acc: 0.781076\n",
            "**** EPOCH 012 ****\n",
            "----0-----\n",
            "mean loss: 0.614207\n",
            "accuracy: 0.814453\n",
            "----1-----\n",
            "mean loss: 0.602727\n",
            "accuracy: 0.813477\n",
            "----2-----\n",
            "mean loss: 0.558292\n",
            "accuracy: 0.824375\n",
            "----3-----\n",
            "mean loss: 0.583468\n",
            "accuracy: 0.824707\n",
            "----4-----\n",
            "mean loss: 0.573130\n",
            "accuracy: 0.819336\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.498680\n",
            "eval accuracy: 0.844984\n",
            "eval avg class acc: 0.788628\n",
            "**** EPOCH 013 ****\n",
            "----0-----\n",
            "mean loss: 0.581082\n",
            "accuracy: 0.818750\n",
            "----1-----\n",
            "mean loss: 0.567149\n",
            "accuracy: 0.822754\n",
            "----2-----\n",
            "mean loss: 0.608936\n",
            "accuracy: 0.815430\n",
            "----3-----\n",
            "mean loss: 0.606694\n",
            "accuracy: 0.809082\n",
            "----4-----\n",
            "mean loss: 0.571393\n",
            "accuracy: 0.819336\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.495577\n",
            "eval accuracy: 0.853207\n",
            "eval avg class acc: 0.785734\n",
            "**** EPOCH 014 ****\n",
            "----0-----\n",
            "mean loss: 0.508984\n",
            "accuracy: 0.832500\n",
            "----1-----\n",
            "mean loss: 0.539242\n",
            "accuracy: 0.832520\n",
            "----2-----\n",
            "mean loss: 0.588635\n",
            "accuracy: 0.814453\n",
            "----3-----\n",
            "mean loss: 0.554949\n",
            "accuracy: 0.830566\n",
            "----4-----\n",
            "mean loss: 0.578141\n",
            "accuracy: 0.813477\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.477371\n",
            "eval accuracy: 0.852796\n",
            "eval avg class acc: 0.783797\n",
            "**** EPOCH 015 ****\n",
            "----0-----\n",
            "mean loss: 0.521152\n",
            "accuracy: 0.835938\n",
            "----1-----\n",
            "mean loss: 0.567123\n",
            "accuracy: 0.821777\n",
            "----2-----\n",
            "mean loss: 0.541074\n",
            "accuracy: 0.832500\n",
            "----3-----\n",
            "mean loss: 0.539368\n",
            "accuracy: 0.831055\n",
            "----4-----\n",
            "mean loss: 0.578509\n",
            "accuracy: 0.820312\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.459455\n",
            "eval accuracy: 0.864309\n",
            "eval avg class acc: 0.787584\n",
            "**** EPOCH 016 ****\n",
            "----0-----\n",
            "mean loss: 0.532018\n",
            "accuracy: 0.832031\n",
            "----1-----\n",
            "mean loss: 0.562630\n",
            "accuracy: 0.826172\n",
            "----2-----\n",
            "mean loss: 0.530590\n",
            "accuracy: 0.835625\n",
            "----3-----\n",
            "mean loss: 0.565350\n",
            "accuracy: 0.825684\n",
            "----4-----\n",
            "mean loss: 0.540108\n",
            "accuracy: 0.826660\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.433087\n",
            "eval accuracy: 0.868421\n",
            "eval avg class acc: 0.792490\n",
            "**** EPOCH 017 ****\n",
            "----0-----\n",
            "mean loss: 0.506613\n",
            "accuracy: 0.841797\n",
            "----1-----\n",
            "mean loss: 0.529939\n",
            "accuracy: 0.837402\n",
            "----2-----\n",
            "mean loss: 0.505481\n",
            "accuracy: 0.833496\n",
            "----3-----\n",
            "mean loss: 0.558911\n",
            "accuracy: 0.827637\n",
            "----4-----\n",
            "mean loss: 0.515831\n",
            "accuracy: 0.828125\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.441245\n",
            "eval accuracy: 0.867599\n",
            "eval avg class acc: 0.805121\n",
            "**** EPOCH 018 ****\n",
            "----0-----\n",
            "mean loss: 0.512236\n",
            "accuracy: 0.828125\n",
            "----1-----\n",
            "mean loss: 0.549121\n",
            "accuracy: 0.828613\n",
            "----2-----\n",
            "mean loss: 0.476640\n",
            "accuracy: 0.840625\n",
            "----3-----\n",
            "mean loss: 0.499641\n",
            "accuracy: 0.846680\n",
            "----4-----\n",
            "mean loss: 0.500138\n",
            "accuracy: 0.846680\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.440425\n",
            "eval accuracy: 0.864309\n",
            "eval avg class acc: 0.804807\n",
            "**** EPOCH 019 ****\n",
            "----0-----\n",
            "mean loss: 0.505195\n",
            "accuracy: 0.844238\n",
            "----1-----\n",
            "mean loss: 0.486103\n",
            "accuracy: 0.852051\n",
            "----2-----\n",
            "mean loss: 0.497593\n",
            "accuracy: 0.858887\n",
            "----3-----\n",
            "mean loss: 0.471877\n",
            "accuracy: 0.847500\n",
            "----4-----\n",
            "mean loss: 0.517548\n",
            "accuracy: 0.829102\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.476139\n",
            "eval accuracy: 0.856086\n",
            "eval avg class acc: 0.812637\n",
            "**** EPOCH 020 ****\n",
            "----0-----\n",
            "mean loss: 0.456868\n",
            "accuracy: 0.850000\n",
            "----1-----\n",
            "mean loss: 0.486461\n",
            "accuracy: 0.842285\n",
            "----2-----\n",
            "mean loss: 0.474920\n",
            "accuracy: 0.853516\n",
            "----3-----\n",
            "mean loss: 0.451650\n",
            "accuracy: 0.858887\n",
            "----4-----\n",
            "mean loss: 0.444678\n",
            "accuracy: 0.854980\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.433380\n",
            "eval accuracy: 0.871711\n",
            "eval avg class acc: 0.816101\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/2/model.ckpt\n",
            "**** EPOCH 021 ****\n",
            "----0-----\n",
            "mean loss: 0.438209\n",
            "accuracy: 0.854492\n",
            "----1-----\n",
            "mean loss: 0.434070\n",
            "accuracy: 0.864375\n",
            "----2-----\n",
            "mean loss: 0.432334\n",
            "accuracy: 0.864258\n",
            "----3-----\n",
            "mean loss: 0.435429\n",
            "accuracy: 0.856934\n",
            "----4-----\n",
            "mean loss: 0.469008\n",
            "accuracy: 0.850098\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.408411\n",
            "eval accuracy: 0.880757\n",
            "eval avg class acc: 0.827857\n",
            "**** EPOCH 022 ****\n",
            "----0-----\n",
            "mean loss: 0.407746\n",
            "accuracy: 0.868652\n",
            "----1-----\n",
            "mean loss: 0.419410\n",
            "accuracy: 0.864746\n",
            "----2-----\n",
            "mean loss: 0.396068\n",
            "accuracy: 0.871875\n",
            "----3-----\n",
            "mean loss: 0.478023\n",
            "accuracy: 0.859863\n",
            "----4-----\n",
            "mean loss: 0.416340\n",
            "accuracy: 0.870605\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.415592\n",
            "eval accuracy: 0.871711\n",
            "eval avg class acc: 0.820983\n",
            "**** EPOCH 023 ****\n",
            "----0-----\n",
            "mean loss: 0.420945\n",
            "accuracy: 0.869629\n",
            "----1-----\n",
            "mean loss: 0.452737\n",
            "accuracy: 0.856445\n",
            "----2-----\n",
            "mean loss: 0.424183\n",
            "accuracy: 0.861875\n",
            "----3-----\n",
            "mean loss: 0.426218\n",
            "accuracy: 0.868652\n",
            "----4-----\n",
            "mean loss: 0.448146\n",
            "accuracy: 0.847168\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.430188\n",
            "eval accuracy: 0.873766\n",
            "eval avg class acc: 0.824387\n",
            "**** EPOCH 024 ****\n",
            "----0-----\n",
            "mean loss: 0.383300\n",
            "accuracy: 0.870605\n",
            "----1-----\n",
            "mean loss: 0.393608\n",
            "accuracy: 0.876875\n",
            "----2-----\n",
            "mean loss: 0.414324\n",
            "accuracy: 0.870117\n",
            "----3-----\n",
            "mean loss: 0.411804\n",
            "accuracy: 0.862305\n",
            "----4-----\n",
            "mean loss: 0.418768\n",
            "accuracy: 0.877441\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.433693\n",
            "eval accuracy: 0.874589\n",
            "eval avg class acc: 0.814045\n",
            "**** EPOCH 025 ****\n",
            "----0-----\n",
            "mean loss: 0.407313\n",
            "accuracy: 0.873047\n",
            "----1-----\n",
            "mean loss: 0.410356\n",
            "accuracy: 0.861816\n",
            "----2-----\n",
            "mean loss: 0.383551\n",
            "accuracy: 0.884375\n",
            "----3-----\n",
            "mean loss: 0.434609\n",
            "accuracy: 0.854004\n",
            "----4-----\n",
            "mean loss: 0.410994\n",
            "accuracy: 0.868652\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.404758\n",
            "eval accuracy: 0.882401\n",
            "eval avg class acc: 0.819159\n",
            "**** EPOCH 026 ****\n",
            "----0-----\n",
            "mean loss: 0.393001\n",
            "accuracy: 0.872559\n",
            "----1-----\n",
            "mean loss: 0.430862\n",
            "accuracy: 0.866250\n",
            "----2-----\n",
            "mean loss: 0.431369\n",
            "accuracy: 0.861816\n",
            "----3-----\n",
            "mean loss: 0.415983\n",
            "accuracy: 0.870605\n",
            "----4-----\n",
            "mean loss: 0.410115\n",
            "accuracy: 0.862793\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.404869\n",
            "eval accuracy: 0.876234\n",
            "eval avg class acc: 0.832343\n",
            "**** EPOCH 027 ****\n",
            "----0-----\n",
            "mean loss: 0.422364\n",
            "accuracy: 0.866699\n",
            "----1-----\n",
            "mean loss: 0.384808\n",
            "accuracy: 0.876250\n",
            "----2-----\n",
            "mean loss: 0.394575\n",
            "accuracy: 0.875000\n",
            "----3-----\n",
            "mean loss: 0.408382\n",
            "accuracy: 0.871094\n",
            "----4-----\n",
            "mean loss: 0.385701\n",
            "accuracy: 0.874023\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.393965\n",
            "eval accuracy: 0.886513\n",
            "eval avg class acc: 0.824625\n",
            "**** EPOCH 028 ****\n",
            "----0-----\n",
            "mean loss: 0.385610\n",
            "accuracy: 0.874023\n",
            "----1-----\n",
            "mean loss: 0.369511\n",
            "accuracy: 0.883125\n",
            "----2-----\n",
            "mean loss: 0.420387\n",
            "accuracy: 0.871582\n",
            "----3-----\n",
            "mean loss: 0.408342\n",
            "accuracy: 0.864258\n",
            "----4-----\n",
            "mean loss: 0.391821\n",
            "accuracy: 0.874512\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.412334\n",
            "eval accuracy: 0.877056\n",
            "eval avg class acc: 0.821467\n",
            "**** EPOCH 029 ****\n",
            "----0-----\n",
            "mean loss: 0.360597\n",
            "accuracy: 0.889160\n",
            "----1-----\n",
            "mean loss: 0.383644\n",
            "accuracy: 0.871582\n",
            "----2-----\n",
            "mean loss: 0.374619\n",
            "accuracy: 0.881836\n",
            "----3-----\n",
            "mean loss: 0.363087\n",
            "accuracy: 0.875000\n",
            "----4-----\n",
            "mean loss: 0.384128\n",
            "accuracy: 0.878418\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.443841\n",
            "eval accuracy: 0.864720\n",
            "eval avg class acc: 0.822063\n",
            "**** EPOCH 030 ****\n",
            "----0-----\n",
            "mean loss: 0.349621\n",
            "accuracy: 0.890625\n",
            "----1-----\n",
            "mean loss: 0.390403\n",
            "accuracy: 0.879883\n",
            "----2-----\n",
            "mean loss: 0.385363\n",
            "accuracy: 0.871582\n",
            "----3-----\n",
            "mean loss: 0.414248\n",
            "accuracy: 0.866211\n",
            "----4-----\n",
            "mean loss: 0.358340\n",
            "accuracy: 0.883125\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.394045\n",
            "eval accuracy: 0.877467\n",
            "eval avg class acc: 0.833428\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/2/model.ckpt\n",
            "**** EPOCH 031 ****\n",
            "----0-----\n",
            "mean loss: 0.384297\n",
            "accuracy: 0.880371\n",
            "----1-----\n",
            "mean loss: 0.361155\n",
            "accuracy: 0.875977\n",
            "----2-----\n",
            "mean loss: 0.399383\n",
            "accuracy: 0.877930\n",
            "----3-----\n",
            "mean loss: 0.348471\n",
            "accuracy: 0.882812\n",
            "----4-----\n",
            "mean loss: 0.359232\n",
            "accuracy: 0.882500\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.429579\n",
            "eval accuracy: 0.867599\n",
            "eval avg class acc: 0.826727\n",
            "**** EPOCH 032 ****\n",
            "----0-----\n",
            "mean loss: 0.378070\n",
            "accuracy: 0.878906\n",
            "----1-----\n",
            "mean loss: 0.356631\n",
            "accuracy: 0.886230\n",
            "----2-----\n",
            "mean loss: 0.365537\n",
            "accuracy: 0.878750\n",
            "----3-----\n",
            "mean loss: 0.383948\n",
            "accuracy: 0.875488\n",
            "----4-----\n",
            "mean loss: 0.375107\n",
            "accuracy: 0.876465\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.378870\n",
            "eval accuracy: 0.888980\n",
            "eval avg class acc: 0.833512\n",
            "**** EPOCH 033 ****\n",
            "----0-----\n",
            "mean loss: 0.333190\n",
            "accuracy: 0.889648\n",
            "----1-----\n",
            "mean loss: 0.337584\n",
            "accuracy: 0.883301\n",
            "----2-----\n",
            "mean loss: 0.375359\n",
            "accuracy: 0.880859\n",
            "----3-----\n",
            "mean loss: 0.373079\n",
            "accuracy: 0.876465\n",
            "----4-----\n",
            "mean loss: 0.338137\n",
            "accuracy: 0.886250\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.399269\n",
            "eval accuracy: 0.879112\n",
            "eval avg class acc: 0.838127\n",
            "**** EPOCH 034 ****\n",
            "----0-----\n",
            "mean loss: 0.332896\n",
            "accuracy: 0.889648\n",
            "----1-----\n",
            "mean loss: 0.340234\n",
            "accuracy: 0.886719\n",
            "----2-----\n",
            "mean loss: 0.359752\n",
            "accuracy: 0.883301\n",
            "----3-----\n",
            "mean loss: 0.322548\n",
            "accuracy: 0.898125\n",
            "----4-----\n",
            "mean loss: 0.358863\n",
            "accuracy: 0.883789\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.393026\n",
            "eval accuracy: 0.880757\n",
            "eval avg class acc: 0.829112\n",
            "**** EPOCH 035 ****\n",
            "----0-----\n",
            "mean loss: 0.349782\n",
            "accuracy: 0.883125\n",
            "----1-----\n",
            "mean loss: 0.323411\n",
            "accuracy: 0.894043\n",
            "----2-----\n",
            "mean loss: 0.383963\n",
            "accuracy: 0.879395\n",
            "----3-----\n",
            "mean loss: 0.352020\n",
            "accuracy: 0.876465\n",
            "----4-----\n",
            "mean loss: 0.360606\n",
            "accuracy: 0.884277\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.442216\n",
            "eval accuracy: 0.876234\n",
            "eval avg class acc: 0.825925\n",
            "**** EPOCH 036 ****\n",
            "----0-----\n",
            "mean loss: 0.335007\n",
            "accuracy: 0.883301\n",
            "----1-----\n",
            "mean loss: 0.363024\n",
            "accuracy: 0.875000\n",
            "----2-----\n",
            "mean loss: 0.362887\n",
            "accuracy: 0.890137\n",
            "----3-----\n",
            "mean loss: 0.370972\n",
            "accuracy: 0.882500\n",
            "----4-----\n",
            "mean loss: 0.350143\n",
            "accuracy: 0.880859\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.402789\n",
            "eval accuracy: 0.878289\n",
            "eval avg class acc: 0.831819\n",
            "**** EPOCH 037 ****\n",
            "----0-----\n",
            "mean loss: 0.348334\n",
            "accuracy: 0.885254\n",
            "----1-----\n",
            "mean loss: 0.372219\n",
            "accuracy: 0.883789\n",
            "----2-----\n",
            "mean loss: 0.398661\n",
            "accuracy: 0.882812\n",
            "----3-----\n",
            "mean loss: 0.342556\n",
            "accuracy: 0.891250\n",
            "----4-----\n",
            "mean loss: 0.335572\n",
            "accuracy: 0.887695\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.398788\n",
            "eval accuracy: 0.884868\n",
            "eval avg class acc: 0.833122\n",
            "**** EPOCH 038 ****\n",
            "----0-----\n",
            "mean loss: 0.315366\n",
            "accuracy: 0.899902\n",
            "----1-----\n",
            "mean loss: 0.364668\n",
            "accuracy: 0.871094\n",
            "----2-----\n",
            "mean loss: 0.348912\n",
            "accuracy: 0.885742\n",
            "----3-----\n",
            "mean loss: 0.343526\n",
            "accuracy: 0.888750\n",
            "----4-----\n",
            "mean loss: 0.345685\n",
            "accuracy: 0.886230\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.403704\n",
            "eval accuracy: 0.885280\n",
            "eval avg class acc: 0.838958\n",
            "**** EPOCH 039 ****\n",
            "----0-----\n",
            "mean loss: 0.313699\n",
            "accuracy: 0.901367\n",
            "----1-----\n",
            "mean loss: 0.361531\n",
            "accuracy: 0.877930\n",
            "----2-----\n",
            "mean loss: 0.346189\n",
            "accuracy: 0.881348\n",
            "----3-----\n",
            "mean loss: 0.307857\n",
            "accuracy: 0.898125\n",
            "----4-----\n",
            "mean loss: 0.344420\n",
            "accuracy: 0.893555\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.374887\n",
            "eval accuracy: 0.884457\n",
            "eval avg class acc: 0.841893\n",
            "**** EPOCH 040 ****\n",
            "----0-----\n",
            "mean loss: 0.334269\n",
            "accuracy: 0.891602\n",
            "----1-----\n",
            "mean loss: 0.311907\n",
            "accuracy: 0.897949\n",
            "----2-----\n",
            "mean loss: 0.361148\n",
            "accuracy: 0.890625\n",
            "----3-----\n",
            "mean loss: 0.299115\n",
            "accuracy: 0.903125\n",
            "----4-----\n",
            "mean loss: 0.360074\n",
            "accuracy: 0.882324\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.410704\n",
            "eval accuracy: 0.879934\n",
            "eval avg class acc: 0.827668\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/2/model.ckpt\n",
            "**** EPOCH 041 ****\n",
            "----0-----\n",
            "mean loss: 0.296803\n",
            "accuracy: 0.899902\n",
            "----1-----\n",
            "mean loss: 0.318444\n",
            "accuracy: 0.900879\n",
            "----2-----\n",
            "mean loss: 0.313039\n",
            "accuracy: 0.888184\n",
            "----3-----\n",
            "mean loss: 0.292681\n",
            "accuracy: 0.911250\n",
            "----4-----\n",
            "mean loss: 0.310851\n",
            "accuracy: 0.900391\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.417512\n",
            "eval accuracy: 0.870066\n",
            "eval avg class acc: 0.819338\n",
            "**** EPOCH 042 ****\n",
            "----0-----\n",
            "mean loss: 0.285268\n",
            "accuracy: 0.908691\n",
            "----1-----\n",
            "mean loss: 0.291603\n",
            "accuracy: 0.903809\n",
            "----2-----\n",
            "mean loss: 0.307418\n",
            "accuracy: 0.899414\n",
            "----3-----\n",
            "mean loss: 0.288575\n",
            "accuracy: 0.899375\n",
            "----4-----\n",
            "mean loss: 0.293826\n",
            "accuracy: 0.910645\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.394986\n",
            "eval accuracy: 0.881990\n",
            "eval avg class acc: 0.840465\n",
            "**** EPOCH 043 ****\n",
            "----0-----\n",
            "mean loss: 0.300295\n",
            "accuracy: 0.900879\n",
            "----1-----\n",
            "mean loss: 0.308540\n",
            "accuracy: 0.897949\n",
            "----2-----\n",
            "mean loss: 0.303255\n",
            "accuracy: 0.899902\n",
            "----3-----\n",
            "mean loss: 0.297474\n",
            "accuracy: 0.903125\n",
            "----4-----\n",
            "mean loss: 0.283899\n",
            "accuracy: 0.904785\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.387998\n",
            "eval accuracy: 0.883635\n",
            "eval avg class acc: 0.841787\n",
            "**** EPOCH 044 ****\n",
            "----0-----\n",
            "mean loss: 0.290501\n",
            "accuracy: 0.903320\n",
            "----1-----\n",
            "mean loss: 0.294269\n",
            "accuracy: 0.906250\n",
            "----2-----\n",
            "mean loss: 0.257416\n",
            "accuracy: 0.920000\n",
            "----3-----\n",
            "mean loss: 0.279533\n",
            "accuracy: 0.912109\n",
            "----4-----\n",
            "mean loss: 0.282637\n",
            "accuracy: 0.902832\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.378880\n",
            "eval accuracy: 0.891036\n",
            "eval avg class acc: 0.841201\n",
            "**** EPOCH 045 ****\n",
            "----0-----\n",
            "mean loss: 0.289775\n",
            "accuracy: 0.897461\n",
            "----1-----\n",
            "mean loss: 0.278450\n",
            "accuracy: 0.909668\n",
            "----2-----\n",
            "mean loss: 0.272719\n",
            "accuracy: 0.911250\n",
            "----3-----\n",
            "mean loss: 0.292962\n",
            "accuracy: 0.898926\n",
            "----4-----\n",
            "mean loss: 0.277251\n",
            "accuracy: 0.903809\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.389341\n",
            "eval accuracy: 0.887747\n",
            "eval avg class acc: 0.848805\n",
            "**** EPOCH 046 ****\n",
            "----0-----\n",
            "mean loss: 0.288668\n",
            "accuracy: 0.900391\n",
            "----1-----\n",
            "mean loss: 0.286615\n",
            "accuracy: 0.904297\n",
            "----2-----\n",
            "mean loss: 0.281567\n",
            "accuracy: 0.902832\n",
            "----3-----\n",
            "mean loss: 0.263755\n",
            "accuracy: 0.913574\n",
            "----4-----\n",
            "mean loss: 0.260036\n",
            "accuracy: 0.907500\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.368980\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.849512\n",
            "**** EPOCH 047 ****\n",
            "----0-----\n",
            "mean loss: 0.240545\n",
            "accuracy: 0.913750\n",
            "----1-----\n",
            "mean loss: 0.261183\n",
            "accuracy: 0.913574\n",
            "----2-----\n",
            "mean loss: 0.285869\n",
            "accuracy: 0.907715\n",
            "----3-----\n",
            "mean loss: 0.270250\n",
            "accuracy: 0.909668\n",
            "----4-----\n",
            "mean loss: 0.291602\n",
            "accuracy: 0.904785\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.389788\n",
            "eval accuracy: 0.884046\n",
            "eval avg class acc: 0.828073\n",
            "**** EPOCH 048 ****\n",
            "----0-----\n",
            "mean loss: 0.256571\n",
            "accuracy: 0.916992\n",
            "----1-----\n",
            "mean loss: 0.271573\n",
            "accuracy: 0.910645\n",
            "----2-----\n",
            "mean loss: 0.263715\n",
            "accuracy: 0.908203\n",
            "----3-----\n",
            "mean loss: 0.272398\n",
            "accuracy: 0.907715\n",
            "----4-----\n",
            "mean loss: 0.260321\n",
            "accuracy: 0.916250\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.387498\n",
            "eval accuracy: 0.892270\n",
            "eval avg class acc: 0.850992\n",
            "**** EPOCH 049 ****\n",
            "----0-----\n",
            "mean loss: 0.254478\n",
            "accuracy: 0.909668\n",
            "----1-----\n",
            "mean loss: 0.274925\n",
            "accuracy: 0.910645\n",
            "----2-----\n",
            "mean loss: 0.274175\n",
            "accuracy: 0.903320\n",
            "----3-----\n",
            "mean loss: 0.272934\n",
            "accuracy: 0.906875\n",
            "----4-----\n",
            "mean loss: 0.283142\n",
            "accuracy: 0.902344\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.380390\n",
            "eval accuracy: 0.890625\n",
            "eval avg class acc: 0.829855\n",
            "**** EPOCH 050 ****\n",
            "----0-----\n",
            "mean loss: 0.232264\n",
            "accuracy: 0.922363\n",
            "----1-----\n",
            "mean loss: 0.254961\n",
            "accuracy: 0.916250\n",
            "----2-----\n",
            "mean loss: 0.274157\n",
            "accuracy: 0.903809\n",
            "----3-----\n",
            "mean loss: 0.264917\n",
            "accuracy: 0.917969\n",
            "----4-----\n",
            "mean loss: 0.283900\n",
            "accuracy: 0.904297\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.440554\n",
            "eval accuracy: 0.880345\n",
            "eval avg class acc: 0.842295\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/2/model.ckpt\n",
            "**** EPOCH 051 ****\n",
            "----0-----\n",
            "mean loss: 0.280349\n",
            "accuracy: 0.904297\n",
            "----1-----\n",
            "mean loss: 0.253175\n",
            "accuracy: 0.915000\n",
            "----2-----\n",
            "mean loss: 0.270107\n",
            "accuracy: 0.914062\n",
            "----3-----\n",
            "mean loss: 0.280103\n",
            "accuracy: 0.903809\n",
            "----4-----\n",
            "mean loss: 0.274898\n",
            "accuracy: 0.913574\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.410839\n",
            "eval accuracy: 0.877878\n",
            "eval avg class acc: 0.838169\n",
            "**** EPOCH 052 ****\n",
            "----0-----\n",
            "mean loss: 0.258368\n",
            "accuracy: 0.910000\n",
            "----1-----\n",
            "mean loss: 0.266366\n",
            "accuracy: 0.904785\n",
            "----2-----\n",
            "mean loss: 0.248032\n",
            "accuracy: 0.917480\n",
            "----3-----\n",
            "mean loss: 0.248815\n",
            "accuracy: 0.914551\n",
            "----4-----\n",
            "mean loss: 0.282038\n",
            "accuracy: 0.898438\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.402324\n",
            "eval accuracy: 0.889803\n",
            "eval avg class acc: 0.843844\n",
            "**** EPOCH 053 ****\n",
            "----0-----\n",
            "mean loss: 0.262564\n",
            "accuracy: 0.905273\n",
            "----1-----\n",
            "mean loss: 0.258625\n",
            "accuracy: 0.911875\n",
            "----2-----\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}