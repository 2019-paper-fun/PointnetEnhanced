{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pointnet Training and Evaluate",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "u22w3BFiOveA"
      },
      "cell_type": "markdown",
      "source": [
        "## Running pointnet\n",
        "\n",
        "Mount the google drive and point to the folder containing the train.py and run the code from there with a slight modification.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "outputId": "9d4f34b0-64e5-4cec-cd2d-6e2e21fb247f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zNEHrCdY4dsO",
        "colab_type": "code",
        "outputId": "1c20aa91-4bbb-4350-ef4f-fc1347a8b7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet00/')\n",
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/')\n",
        "\n",
        "\n",
        "!python train.py #--log_dir=\"log\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
            "2018-10-31 10:20:32.951964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-31 10:20:32.952421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-10-31 10:20:32.952462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-10-31 10:20:33.360434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-31 10:20:33.360498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-10-31 10:20:33.360529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-10-31 10:20:33.360873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.862819\n",
            "accuracy: 0.211397\n",
            "----1-----\n",
            "mean loss: 2.821400\n",
            "accuracy: 0.310059\n",
            "----2-----\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 265, in <module>\n",
            "    train()\n",
            "  File \"train.py\", line 164, in train\n",
            "    train_one_epoch(sess, ops, train_writer)\n",
            "  File \"train.py\", line 185, in train_one_epoch\n",
            "    current_data, current_label = provider.loadDataFile(TRAIN_FILES[train_file_idxs[fn]])\n",
            "  File \"/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/provider.py\", line 98, in loadDataFile\n",
            "    return load_h5(filename)\n",
            "  File \"/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/provider.py\", line 92, in load_h5\n",
            "    f = h5py.File(h5_filename)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\", line 312, in __init__\n",
            "    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\", line 162, in make_fid\n",
            "    fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open\n",
            "  File \"h5py/h5g.pyx\", line 266, in h5py.h5g.GroupID.__init__\n",
            "  File \"h5py/h5g.pyx\", line 267, in h5py.h5g.GroupID.__init__\n",
            "  File \"<frozen importlib._bootstrap>\", line 416, in parent\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5-2X59hAEUKD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "fAakEKduAND5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet00/')\n",
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/')\n",
        "\n",
        "!python evaluate.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uDaM9jejpevv"
      },
      "cell_type": "markdown",
      "source": [
        "## Running tensorboard with the pointnet result\n",
        "https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q1HvTklVpevy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Lk5LgRFxpev9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet')\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1mDHS17MpewG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d76abdce-5d73-40c7-9634-4e7370bd416f",
        "id": "YHCb450npewN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://c0859e76.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bFEMdCnvEXir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running pointnet 2"
      ]
    },
    {
      "metadata": {
        "id": "SoYtZ-4BbeCN",
        "colab_type": "code",
        "outputId": "0956df5a-6d3d-4944-a88d-2d30affb0754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/tf_ops/sampling')\n",
        "!bash tf_sampling_compile.sh"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Ktf_sampling.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:20:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(0), 2, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:22:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(1), 2, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:34:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(0), 3, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:47:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(0), 3, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_sampling.cpp:49:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     c->WithRank(c->input(1), 2, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_sampling.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pf9cvqQx2bik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "4c5dfc88-2893-41a5-deee-697d63212d2a"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/tf_ops/grouping')\n",
        "!bash tf_grouping_compile.sh"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Ktf_grouping.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_grouping.cpp:22:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(1), 3, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_grouping.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_grouping.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_grouping.cpp:47:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(0), 3, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_grouping.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_grouping.cpp:49:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(1), 3, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_grouping.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q3lp-iSx2ofl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "645463a4-098b-4cdc-f490-d59a4286a342"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/tf_ops/3d_interpolation')\n",
        "!bash tf_interpolate_compile.sh"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Ktf_interpolate.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ktf_interpolate.cpp:29:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(0), 3, &dims1)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_interpolate.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktf_interpolate.cpp:31:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ktensorflow::Status tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, tensorflow::int64, tensorflow::shape_inference::ShapeHandle*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         c->WithRank(c->input(1), 3, &dims2)\u001b[01;35m\u001b[K;\u001b[m\u001b[K\r\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ktf_interpolate.cpp:8:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/shape_inference.h:394:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   Status \u001b[01;36m\u001b[KWithRank\u001b[m\u001b[K(ShapeHandle shape, int64 rank,\n",
            "          \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "soaNJhOtEZud",
        "colab_type": "code",
        "outputId": "8e5e7333-a127-422a-e213-ce3abd6c0130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178569
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2')\n",
        "\n",
        "!python train.py #--gpu 0 # train_multi_gpu.py #--num_gpu=8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pid: 320\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/utils/pointnet_util.py:127: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "--- Get training operator\n",
            "2018-10-30 16:59:42.507595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-30 16:59:42.508064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-10-30 16:59:42.508105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-10-30 16:59:42.939796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-30 16:59:42.939888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-10-30 16:59:42.939914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-10-30 16:59:42.940283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "2018-10-30 16:59:44.181492\n",
            " ---- batch: 050 ----\n",
            "mean loss: 3.526222\n",
            "accuracy: 0.156250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 2.881351\n",
            "accuracy: 0.263750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 2.635329\n",
            "accuracy: 0.323750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 2.402624\n",
            "accuracy: 0.385000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 2.061759\n",
            "accuracy: 0.456250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 2.022208\n",
            "accuracy: 0.482500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 1.817767\n",
            "accuracy: 0.500000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 1.674554\n",
            "accuracy: 0.526250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 1.661777\n",
            "accuracy: 0.530000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 1.644472\n",
            "accuracy: 0.553750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 1.616432\n",
            "accuracy: 0.563750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 1.623406\n",
            "accuracy: 0.523750\n",
            "2018-10-30 17:02:47.530953\n",
            "---- EPOCH 000 EVALUATION ----\n",
            "eval mean loss: 1.162858\n",
            "eval accuracy: 0.649514\n",
            "eval avg class acc: 0.566471\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "2018-10-30 17:03:03.667238\n",
            " ---- batch: 050 ----\n",
            "mean loss: 1.529040\n",
            "accuracy: 0.552500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 1.441122\n",
            "accuracy: 0.592500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 1.486175\n",
            "accuracy: 0.578750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 1.381246\n",
            "accuracy: 0.577500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 1.322556\n",
            "accuracy: 0.615000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 1.325694\n",
            "accuracy: 0.615000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 1.271106\n",
            "accuracy: 0.638750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 1.284825\n",
            "accuracy: 0.632500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 1.365452\n",
            "accuracy: 0.603750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 1.233826\n",
            "accuracy: 0.645000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 1.251806\n",
            "accuracy: 0.643750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 1.125962\n",
            "accuracy: 0.673750\n",
            "2018-10-30 17:05:47.573005\n",
            "---- EPOCH 001 EVALUATION ----\n",
            "eval mean loss: 0.959724\n",
            "eval accuracy: 0.695300\n",
            "eval avg class acc: 0.630942\n",
            "**** EPOCH 002 ****\n",
            "2018-10-30 17:05:59.881353\n",
            " ---- batch: 050 ----\n",
            "mean loss: 1.155251\n",
            "accuracy: 0.668750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 1.117961\n",
            "accuracy: 0.676250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 1.158184\n",
            "accuracy: 0.661250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 1.159428\n",
            "accuracy: 0.652500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 1.040428\n",
            "accuracy: 0.703750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 1.159099\n",
            "accuracy: 0.686250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 1.119702\n",
            "accuracy: 0.667500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 1.019763\n",
            "accuracy: 0.688750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 1.040653\n",
            "accuracy: 0.682500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 1.058460\n",
            "accuracy: 0.711250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 1.061521\n",
            "accuracy: 0.671250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 1.241896\n",
            "accuracy: 0.638750\n",
            "2018-10-30 17:08:43.654814\n",
            "---- EPOCH 002 EVALUATION ----\n",
            "eval mean loss: 0.830632\n",
            "eval accuracy: 0.742707\n",
            "eval avg class acc: 0.683866\n",
            "**** EPOCH 003 ****\n",
            "2018-10-30 17:08:55.931568\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.988675\n",
            "accuracy: 0.715000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 1.057863\n",
            "accuracy: 0.698750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.979156\n",
            "accuracy: 0.698750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 1.018346\n",
            "accuracy: 0.692500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 1.045654\n",
            "accuracy: 0.713750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.974202\n",
            "accuracy: 0.706250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 1.032078\n",
            "accuracy: 0.701250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.875424\n",
            "accuracy: 0.731250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.975875\n",
            "accuracy: 0.701250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.856395\n",
            "accuracy: 0.743750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.873597\n",
            "accuracy: 0.741250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 1.030931\n",
            "accuracy: 0.683750\n",
            "2018-10-30 17:11:39.869129\n",
            "---- EPOCH 003 EVALUATION ----\n",
            "eval mean loss: 0.723140\n",
            "eval accuracy: 0.775932\n",
            "eval avg class acc: 0.724134\n",
            "**** EPOCH 004 ****\n",
            "2018-10-30 17:11:52.161703\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.916760\n",
            "accuracy: 0.730000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.950191\n",
            "accuracy: 0.711250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.871361\n",
            "accuracy: 0.735000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.901506\n",
            "accuracy: 0.727500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.824355\n",
            "accuracy: 0.745000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.885923\n",
            "accuracy: 0.728750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.956400\n",
            "accuracy: 0.731250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.945508\n",
            "accuracy: 0.715000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.910349\n",
            "accuracy: 0.718750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.901794\n",
            "accuracy: 0.731250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.889757\n",
            "accuracy: 0.718750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.901789\n",
            "accuracy: 0.718750\n",
            "2018-10-30 17:14:36.116356\n",
            "---- EPOCH 004 EVALUATION ----\n",
            "eval mean loss: 0.657637\n",
            "eval accuracy: 0.792545\n",
            "eval avg class acc: 0.735930\n",
            "**** EPOCH 005 ****\n",
            "2018-10-30 17:14:48.445741\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.870826\n",
            "accuracy: 0.726250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.903286\n",
            "accuracy: 0.733750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.821265\n",
            "accuracy: 0.743750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.800372\n",
            "accuracy: 0.736250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.782484\n",
            "accuracy: 0.743750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.884164\n",
            "accuracy: 0.733750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.876490\n",
            "accuracy: 0.732500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.824990\n",
            "accuracy: 0.738750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.940432\n",
            "accuracy: 0.741250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.905881\n",
            "accuracy: 0.712500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.801001\n",
            "accuracy: 0.777500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.818463\n",
            "accuracy: 0.737500\n",
            "2018-10-30 17:17:32.211284\n",
            "---- EPOCH 005 EVALUATION ----\n",
            "eval mean loss: 0.605685\n",
            "eval accuracy: 0.811183\n",
            "eval avg class acc: 0.745965\n",
            "**** EPOCH 006 ****\n",
            "2018-10-30 17:17:44.555032\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.765442\n",
            "accuracy: 0.773750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.705790\n",
            "accuracy: 0.763750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.778964\n",
            "accuracy: 0.758750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.838081\n",
            "accuracy: 0.736250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.839897\n",
            "accuracy: 0.745000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.728802\n",
            "accuracy: 0.753750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.823694\n",
            "accuracy: 0.746250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.805285\n",
            "accuracy: 0.758750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.822490\n",
            "accuracy: 0.743750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.831680\n",
            "accuracy: 0.733750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.857636\n",
            "accuracy: 0.735000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.799004\n",
            "accuracy: 0.750000\n",
            "2018-10-30 17:20:28.447713\n",
            "---- EPOCH 006 EVALUATION ----\n",
            "eval mean loss: 0.549487\n",
            "eval accuracy: 0.828606\n",
            "eval avg class acc: 0.774930\n",
            "**** EPOCH 007 ****\n",
            "2018-10-30 17:20:40.754648\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.824554\n",
            "accuracy: 0.750000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.678391\n",
            "accuracy: 0.775000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.723267\n",
            "accuracy: 0.781250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.711950\n",
            "accuracy: 0.793750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.746383\n",
            "accuracy: 0.776250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.807238\n",
            "accuracy: 0.742500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.727911\n",
            "accuracy: 0.768750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.819473\n",
            "accuracy: 0.765000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.694419\n",
            "accuracy: 0.788750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.685732\n",
            "accuracy: 0.783750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.757301\n",
            "accuracy: 0.770000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.752059\n",
            "accuracy: 0.781250\n",
            "2018-10-30 17:23:24.654208\n",
            "---- EPOCH 007 EVALUATION ----\n",
            "eval mean loss: 0.599749\n",
            "eval accuracy: 0.814830\n",
            "eval avg class acc: 0.773843\n",
            "**** EPOCH 008 ****\n",
            "2018-10-30 17:23:36.957781\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.677188\n",
            "accuracy: 0.798750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.724923\n",
            "accuracy: 0.768750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.749222\n",
            "accuracy: 0.767500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.823706\n",
            "accuracy: 0.762500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.708381\n",
            "accuracy: 0.765000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.751283\n",
            "accuracy: 0.772500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.682444\n",
            "accuracy: 0.772500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.665088\n",
            "accuracy: 0.792500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.688687\n",
            "accuracy: 0.775000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.669455\n",
            "accuracy: 0.787500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.710579\n",
            "accuracy: 0.792500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.717410\n",
            "accuracy: 0.767500\n",
            "2018-10-30 17:26:20.858215\n",
            "---- EPOCH 008 EVALUATION ----\n",
            "eval mean loss: 0.491309\n",
            "eval accuracy: 0.845219\n",
            "eval avg class acc: 0.788535\n",
            "**** EPOCH 009 ****\n",
            "2018-10-30 17:26:33.187243\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.666337\n",
            "accuracy: 0.810000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.697858\n",
            "accuracy: 0.796250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.674360\n",
            "accuracy: 0.801250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.687743\n",
            "accuracy: 0.776250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.803262\n",
            "accuracy: 0.756250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.673455\n",
            "accuracy: 0.786250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.738658\n",
            "accuracy: 0.777500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.711031\n",
            "accuracy: 0.776250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.662339\n",
            "accuracy: 0.796250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.769697\n",
            "accuracy: 0.763750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.633178\n",
            "accuracy: 0.792500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.705252\n",
            "accuracy: 0.793750\n",
            "2018-10-30 17:29:17.176998\n",
            "---- EPOCH 009 EVALUATION ----\n",
            "eval mean loss: 0.532429\n",
            "eval accuracy: 0.831848\n",
            "eval avg class acc: 0.775099\n",
            "**** EPOCH 010 ****\n",
            "2018-10-30 17:29:29.497064\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.650951\n",
            "accuracy: 0.796250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.673762\n",
            "accuracy: 0.783750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.671605\n",
            "accuracy: 0.783750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.663892\n",
            "accuracy: 0.801250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.721489\n",
            "accuracy: 0.773750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.708092\n",
            "accuracy: 0.776250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.672620\n",
            "accuracy: 0.786250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.669436\n",
            "accuracy: 0.791250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.655652\n",
            "accuracy: 0.776250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.642758\n",
            "accuracy: 0.812500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.622985\n",
            "accuracy: 0.802500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.651641\n",
            "accuracy: 0.797500\n",
            "2018-10-30 17:32:13.284461\n",
            "---- EPOCH 010 EVALUATION ----\n",
            "eval mean loss: 0.446233\n",
            "eval accuracy: 0.857780\n",
            "eval avg class acc: 0.794070\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 011 ****\n",
            "2018-10-30 17:32:25.968073\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.579460\n",
            "accuracy: 0.826250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.649297\n",
            "accuracy: 0.792500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.674319\n",
            "accuracy: 0.797500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.678956\n",
            "accuracy: 0.777500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.660505\n",
            "accuracy: 0.806250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.592822\n",
            "accuracy: 0.821250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.752911\n",
            "accuracy: 0.777500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.635808\n",
            "accuracy: 0.802500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.570940\n",
            "accuracy: 0.810000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.692109\n",
            "accuracy: 0.783750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.661639\n",
            "accuracy: 0.778750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.679496\n",
            "accuracy: 0.793750\n",
            "2018-10-30 17:35:09.987311\n",
            "---- EPOCH 011 EVALUATION ----\n",
            "eval mean loss: 0.456226\n",
            "eval accuracy: 0.858185\n",
            "eval avg class acc: 0.802779\n",
            "**** EPOCH 012 ****\n",
            "2018-10-30 17:35:22.270002\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.617487\n",
            "accuracy: 0.807500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.591148\n",
            "accuracy: 0.813750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.621740\n",
            "accuracy: 0.802500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.647029\n",
            "accuracy: 0.783750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.638623\n",
            "accuracy: 0.791250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.613831\n",
            "accuracy: 0.803750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.687738\n",
            "accuracy: 0.766250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.614462\n",
            "accuracy: 0.807500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.623437\n",
            "accuracy: 0.817500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.661502\n",
            "accuracy: 0.807500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.663122\n",
            "accuracy: 0.801250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.565350\n",
            "accuracy: 0.806250\n",
            "2018-10-30 17:38:06.142107\n",
            "---- EPOCH 012 EVALUATION ----\n",
            "eval mean loss: 0.513964\n",
            "eval accuracy: 0.834279\n",
            "eval avg class acc: 0.787831\n",
            "**** EPOCH 013 ****\n",
            "2018-10-30 17:38:18.461061\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.562271\n",
            "accuracy: 0.821250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.639604\n",
            "accuracy: 0.817500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.584481\n",
            "accuracy: 0.817500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.600969\n",
            "accuracy: 0.795000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.646413\n",
            "accuracy: 0.800000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.656504\n",
            "accuracy: 0.790000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.609144\n",
            "accuracy: 0.808750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.630316\n",
            "accuracy: 0.802500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.596824\n",
            "accuracy: 0.830000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.570733\n",
            "accuracy: 0.815000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.537933\n",
            "accuracy: 0.835000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.654413\n",
            "accuracy: 0.811250\n",
            "2018-10-30 17:41:02.335718\n",
            "---- EPOCH 013 EVALUATION ----\n",
            "eval mean loss: 0.449045\n",
            "eval accuracy: 0.865073\n",
            "eval avg class acc: 0.819628\n",
            "**** EPOCH 014 ****\n",
            "2018-10-30 17:41:14.645914\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.592978\n",
            "accuracy: 0.813750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.598209\n",
            "accuracy: 0.815000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.516029\n",
            "accuracy: 0.836250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.528350\n",
            "accuracy: 0.823750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.556987\n",
            "accuracy: 0.828750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.566383\n",
            "accuracy: 0.822500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.570559\n",
            "accuracy: 0.830000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.584777\n",
            "accuracy: 0.815000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.586259\n",
            "accuracy: 0.822500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.588720\n",
            "accuracy: 0.812500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.671410\n",
            "accuracy: 0.790000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.559671\n",
            "accuracy: 0.821250\n",
            "2018-10-30 17:43:58.513200\n",
            "---- EPOCH 014 EVALUATION ----\n",
            "eval mean loss: 0.483535\n",
            "eval accuracy: 0.847650\n",
            "eval avg class acc: 0.801727\n",
            "**** EPOCH 015 ****\n",
            "2018-10-30 17:44:10.867088\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.601080\n",
            "accuracy: 0.815000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.569251\n",
            "accuracy: 0.827500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.618652\n",
            "accuracy: 0.816250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.659199\n",
            "accuracy: 0.791250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.518803\n",
            "accuracy: 0.847500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.625326\n",
            "accuracy: 0.806250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.540380\n",
            "accuracy: 0.823750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.552942\n",
            "accuracy: 0.808750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.489860\n",
            "accuracy: 0.840000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.552387\n",
            "accuracy: 0.837500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.581575\n",
            "accuracy: 0.823750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.633880\n",
            "accuracy: 0.806250\n",
            "2018-10-30 17:46:54.829105\n",
            "---- EPOCH 015 EVALUATION ----\n",
            "eval mean loss: 0.465091\n",
            "eval accuracy: 0.855348\n",
            "eval avg class acc: 0.811250\n",
            "**** EPOCH 016 ****\n",
            "2018-10-30 17:47:07.177533\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.521605\n",
            "accuracy: 0.838750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.510557\n",
            "accuracy: 0.836250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.501828\n",
            "accuracy: 0.826250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.572355\n",
            "accuracy: 0.822500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.566757\n",
            "accuracy: 0.811250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.506157\n",
            "accuracy: 0.831250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.592316\n",
            "accuracy: 0.821250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.538497\n",
            "accuracy: 0.827500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.578151\n",
            "accuracy: 0.808750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.665321\n",
            "accuracy: 0.801250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.559415\n",
            "accuracy: 0.818750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.541833\n",
            "accuracy: 0.808750\n",
            "2018-10-30 17:49:51.522123\n",
            "---- EPOCH 016 EVALUATION ----\n",
            "eval mean loss: 0.489317\n",
            "eval accuracy: 0.848055\n",
            "eval avg class acc: 0.804250\n",
            "**** EPOCH 017 ****\n",
            "2018-10-30 17:50:03.812409\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.571233\n",
            "accuracy: 0.840000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.582451\n",
            "accuracy: 0.812500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.530856\n",
            "accuracy: 0.836250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.508445\n",
            "accuracy: 0.832500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.500338\n",
            "accuracy: 0.821250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.506202\n",
            "accuracy: 0.843750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.573393\n",
            "accuracy: 0.817500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.565002\n",
            "accuracy: 0.831250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.555105\n",
            "accuracy: 0.828750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.531312\n",
            "accuracy: 0.840000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.534384\n",
            "accuracy: 0.836250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.507753\n",
            "accuracy: 0.835000\n",
            "2018-10-30 17:52:47.770793\n",
            "---- EPOCH 017 EVALUATION ----\n",
            "eval mean loss: 0.424938\n",
            "eval accuracy: 0.861831\n",
            "eval avg class acc: 0.819901\n",
            "**** EPOCH 018 ****\n",
            "2018-10-30 17:53:00.132528\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.585463\n",
            "accuracy: 0.822500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.483344\n",
            "accuracy: 0.842500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.561613\n",
            "accuracy: 0.806250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.572694\n",
            "accuracy: 0.816250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.476934\n",
            "accuracy: 0.845000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.520203\n",
            "accuracy: 0.843750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.480407\n",
            "accuracy: 0.850000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.481748\n",
            "accuracy: 0.855000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.559899\n",
            "accuracy: 0.820000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.554665\n",
            "accuracy: 0.815000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.584717\n",
            "accuracy: 0.821250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.564649\n",
            "accuracy: 0.827500\n",
            "2018-10-30 17:55:44.205323\n",
            "---- EPOCH 018 EVALUATION ----\n",
            "eval mean loss: 0.412470\n",
            "eval accuracy: 0.861426\n",
            "eval avg class acc: 0.824738\n",
            "**** EPOCH 019 ****\n",
            "2018-10-30 17:55:56.558379\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.508654\n",
            "accuracy: 0.832500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.520000\n",
            "accuracy: 0.837500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.524184\n",
            "accuracy: 0.828750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.521586\n",
            "accuracy: 0.821250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.477908\n",
            "accuracy: 0.841250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.481443\n",
            "accuracy: 0.838750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.474636\n",
            "accuracy: 0.861250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.547904\n",
            "accuracy: 0.826250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.482295\n",
            "accuracy: 0.851250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.574130\n",
            "accuracy: 0.811250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.515417\n",
            "accuracy: 0.855000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.548722\n",
            "accuracy: 0.815000\n",
            "2018-10-30 17:58:40.540211\n",
            "---- EPOCH 019 EVALUATION ----\n",
            "eval mean loss: 0.460089\n",
            "eval accuracy: 0.846029\n",
            "eval avg class acc: 0.804401\n",
            "**** EPOCH 020 ****\n",
            "2018-10-30 17:58:52.878141\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.482666\n",
            "accuracy: 0.846250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.499657\n",
            "accuracy: 0.837500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.477013\n",
            "accuracy: 0.855000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.538320\n",
            "accuracy: 0.841250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.507080\n",
            "accuracy: 0.843750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.503551\n",
            "accuracy: 0.837500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.546624\n",
            "accuracy: 0.822500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.462482\n",
            "accuracy: 0.845000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.446635\n",
            "accuracy: 0.852500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.440801\n",
            "accuracy: 0.846250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.427526\n",
            "accuracy: 0.861250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.464511\n",
            "accuracy: 0.846250\n",
            "2018-10-30 18:01:36.897814\n",
            "---- EPOCH 020 EVALUATION ----\n",
            "eval mean loss: 0.381383\n",
            "eval accuracy: 0.878849\n",
            "eval avg class acc: 0.831326\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 021 ****\n",
            "2018-10-30 18:01:49.817554\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.448599\n",
            "accuracy: 0.853750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.448226\n",
            "accuracy: 0.850000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.424071\n",
            "accuracy: 0.861250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.402364\n",
            "accuracy: 0.862500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.476717\n",
            "accuracy: 0.850000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.510468\n",
            "accuracy: 0.846250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.444995\n",
            "accuracy: 0.847500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.429851\n",
            "accuracy: 0.866250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.533958\n",
            "accuracy: 0.826250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.391643\n",
            "accuracy: 0.875000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.489369\n",
            "accuracy: 0.843750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.403651\n",
            "accuracy: 0.865000\n",
            "2018-10-30 18:04:33.885220\n",
            "---- EPOCH 021 EVALUATION ----\n",
            "eval mean loss: 0.377589\n",
            "eval accuracy: 0.875608\n",
            "eval avg class acc: 0.840785\n",
            "**** EPOCH 022 ****\n",
            "2018-10-30 18:04:46.221262\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.427604\n",
            "accuracy: 0.850000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.466018\n",
            "accuracy: 0.860000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.432302\n",
            "accuracy: 0.876250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.387727\n",
            "accuracy: 0.862500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.503371\n",
            "accuracy: 0.838750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.386615\n",
            "accuracy: 0.880000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.425282\n",
            "accuracy: 0.867500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.468243\n",
            "accuracy: 0.850000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.476126\n",
            "accuracy: 0.840000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.478172\n",
            "accuracy: 0.843750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.419787\n",
            "accuracy: 0.885000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.418818\n",
            "accuracy: 0.851250\n",
            "2018-10-30 18:07:30.294011\n",
            "---- EPOCH 022 EVALUATION ----\n",
            "eval mean loss: 0.400673\n",
            "eval accuracy: 0.867909\n",
            "eval avg class acc: 0.833413\n",
            "**** EPOCH 023 ****\n",
            "2018-10-30 18:07:42.597727\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.440420\n",
            "accuracy: 0.865000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.418392\n",
            "accuracy: 0.876250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.364291\n",
            "accuracy: 0.885000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.395968\n",
            "accuracy: 0.872500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.428359\n",
            "accuracy: 0.860000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.453955\n",
            "accuracy: 0.841250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.389272\n",
            "accuracy: 0.886250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.521075\n",
            "accuracy: 0.831250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.450881\n",
            "accuracy: 0.846250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.420953\n",
            "accuracy: 0.860000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.423073\n",
            "accuracy: 0.861250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.412142\n",
            "accuracy: 0.865000\n",
            "2018-10-30 18:10:26.678790\n",
            "---- EPOCH 023 EVALUATION ----\n",
            "eval mean loss: 0.386063\n",
            "eval accuracy: 0.875608\n",
            "eval avg class acc: 0.822314\n",
            "**** EPOCH 024 ****\n",
            "2018-10-30 18:10:39.021628\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.390301\n",
            "accuracy: 0.880000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.473050\n",
            "accuracy: 0.866250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.421089\n",
            "accuracy: 0.861250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.442191\n",
            "accuracy: 0.852500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.413581\n",
            "accuracy: 0.866250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.400258\n",
            "accuracy: 0.858750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.489816\n",
            "accuracy: 0.852500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.436833\n",
            "accuracy: 0.863750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.464214\n",
            "accuracy: 0.857500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.448071\n",
            "accuracy: 0.858750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.421830\n",
            "accuracy: 0.860000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.464926\n",
            "accuracy: 0.856250\n",
            "2018-10-30 18:13:22.768800\n",
            "---- EPOCH 024 EVALUATION ----\n",
            "eval mean loss: 0.378339\n",
            "eval accuracy: 0.882901\n",
            "eval avg class acc: 0.834727\n",
            "**** EPOCH 025 ****\n",
            "2018-10-30 18:13:35.113280\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.454310\n",
            "accuracy: 0.860000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.459416\n",
            "accuracy: 0.851250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.401814\n",
            "accuracy: 0.872500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.415987\n",
            "accuracy: 0.866250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.407226\n",
            "accuracy: 0.862500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.382066\n",
            "accuracy: 0.872500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.438500\n",
            "accuracy: 0.851250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.427023\n",
            "accuracy: 0.862500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.431081\n",
            "accuracy: 0.861250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.415093\n",
            "accuracy: 0.862500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.404220\n",
            "accuracy: 0.873750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.407645\n",
            "accuracy: 0.873750\n",
            "2018-10-30 18:16:19.250848\n",
            "---- EPOCH 025 EVALUATION ----\n",
            "eval mean loss: 0.391912\n",
            "eval accuracy: 0.873987\n",
            "eval avg class acc: 0.836215\n",
            "**** EPOCH 026 ****\n",
            "2018-10-30 18:16:31.560318\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.439311\n",
            "accuracy: 0.853750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.351633\n",
            "accuracy: 0.887500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.441015\n",
            "accuracy: 0.868750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.451721\n",
            "accuracy: 0.860000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.459356\n",
            "accuracy: 0.833750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.424713\n",
            "accuracy: 0.862500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.424418\n",
            "accuracy: 0.868750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.429528\n",
            "accuracy: 0.847500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.374161\n",
            "accuracy: 0.883750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.398913\n",
            "accuracy: 0.876250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.399082\n",
            "accuracy: 0.862500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.423020\n",
            "accuracy: 0.866250\n",
            "2018-10-30 18:19:15.440093\n",
            "---- EPOCH 026 EVALUATION ----\n",
            "eval mean loss: 0.388681\n",
            "eval accuracy: 0.881280\n",
            "eval avg class acc: 0.851320\n",
            "**** EPOCH 027 ****\n",
            "2018-10-30 18:19:27.710836\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.397683\n",
            "accuracy: 0.867500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.442192\n",
            "accuracy: 0.865000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.365864\n",
            "accuracy: 0.883750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.394007\n",
            "accuracy: 0.881250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.456778\n",
            "accuracy: 0.845000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.366325\n",
            "accuracy: 0.881250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.367269\n",
            "accuracy: 0.887500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.466224\n",
            "accuracy: 0.866250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.396164\n",
            "accuracy: 0.872500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.407423\n",
            "accuracy: 0.882500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.431487\n",
            "accuracy: 0.862500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.418574\n",
            "accuracy: 0.871250\n",
            "2018-10-30 18:22:11.467328\n",
            "---- EPOCH 027 EVALUATION ----\n",
            "eval mean loss: 0.365110\n",
            "eval accuracy: 0.882496\n",
            "eval avg class acc: 0.841105\n",
            "**** EPOCH 028 ****\n",
            "2018-10-30 18:22:23.758424\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.396466\n",
            "accuracy: 0.877500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.396285\n",
            "accuracy: 0.873750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.374805\n",
            "accuracy: 0.882500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.406198\n",
            "accuracy: 0.868750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.390345\n",
            "accuracy: 0.876250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.434211\n",
            "accuracy: 0.837500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.369805\n",
            "accuracy: 0.871250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.457928\n",
            "accuracy: 0.842500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.381118\n",
            "accuracy: 0.881250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.376792\n",
            "accuracy: 0.878750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.402497\n",
            "accuracy: 0.865000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.339916\n",
            "accuracy: 0.897500\n",
            "2018-10-30 18:25:07.598423\n",
            "---- EPOCH 028 EVALUATION ----\n",
            "eval mean loss: 0.384355\n",
            "eval accuracy: 0.870340\n",
            "eval avg class acc: 0.831907\n",
            "**** EPOCH 029 ****\n",
            "2018-10-30 18:25:19.907456\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.397045\n",
            "accuracy: 0.860000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.403077\n",
            "accuracy: 0.876250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.344103\n",
            "accuracy: 0.881250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.371246\n",
            "accuracy: 0.875000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.379682\n",
            "accuracy: 0.881250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.339633\n",
            "accuracy: 0.883750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.405578\n",
            "accuracy: 0.868750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.368800\n",
            "accuracy: 0.867500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.405689\n",
            "accuracy: 0.861250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.444583\n",
            "accuracy: 0.863750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.370445\n",
            "accuracy: 0.867500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.357849\n",
            "accuracy: 0.880000\n",
            "2018-10-30 18:28:03.832581\n",
            "---- EPOCH 029 EVALUATION ----\n",
            "eval mean loss: 0.396377\n",
            "eval accuracy: 0.878039\n",
            "eval avg class acc: 0.845407\n",
            "**** EPOCH 030 ****\n",
            "2018-10-30 18:28:16.143318\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.376456\n",
            "accuracy: 0.861250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.440612\n",
            "accuracy: 0.861250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.341081\n",
            "accuracy: 0.893750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.384687\n",
            "accuracy: 0.877500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.425692\n",
            "accuracy: 0.858750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.439237\n",
            "accuracy: 0.856250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.392499\n",
            "accuracy: 0.862500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.376399\n",
            "accuracy: 0.876250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.451429\n",
            "accuracy: 0.855000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.364638\n",
            "accuracy: 0.875000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.415401\n",
            "accuracy: 0.868750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.405775\n",
            "accuracy: 0.866250\n",
            "2018-10-30 18:31:00.075380\n",
            "---- EPOCH 030 EVALUATION ----\n",
            "eval mean loss: 0.402071\n",
            "eval accuracy: 0.865073\n",
            "eval avg class acc: 0.834523\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 031 ****\n",
            "2018-10-30 18:31:12.841116\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.398443\n",
            "accuracy: 0.863750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.358763\n",
            "accuracy: 0.881250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.338146\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.363856\n",
            "accuracy: 0.880000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.439458\n",
            "accuracy: 0.868750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.389575\n",
            "accuracy: 0.861250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.393485\n",
            "accuracy: 0.877500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.353422\n",
            "accuracy: 0.880000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.359920\n",
            "accuracy: 0.880000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.350037\n",
            "accuracy: 0.888750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.377568\n",
            "accuracy: 0.881250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.406055\n",
            "accuracy: 0.853750\n",
            "2018-10-30 18:33:56.836179\n",
            "---- EPOCH 031 EVALUATION ----\n",
            "eval mean loss: 0.424086\n",
            "eval accuracy: 0.860211\n",
            "eval avg class acc: 0.819698\n",
            "**** EPOCH 032 ****\n",
            "2018-10-30 18:34:09.169798\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.358915\n",
            "accuracy: 0.876250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.400271\n",
            "accuracy: 0.881250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.365453\n",
            "accuracy: 0.871250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.346112\n",
            "accuracy: 0.880000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.382642\n",
            "accuracy: 0.875000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.396394\n",
            "accuracy: 0.867500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.346286\n",
            "accuracy: 0.882500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.390333\n",
            "accuracy: 0.885000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.424460\n",
            "accuracy: 0.871250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.366049\n",
            "accuracy: 0.880000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.431285\n",
            "accuracy: 0.851250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.338506\n",
            "accuracy: 0.897500\n",
            "2018-10-30 18:36:53.003608\n",
            "---- EPOCH 032 EVALUATION ----\n",
            "eval mean loss: 0.368135\n",
            "eval accuracy: 0.876418\n",
            "eval avg class acc: 0.840488\n",
            "**** EPOCH 033 ****\n",
            "2018-10-30 18:37:05.279345\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.374040\n",
            "accuracy: 0.866250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.427125\n",
            "accuracy: 0.852500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.401045\n",
            "accuracy: 0.871250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.312690\n",
            "accuracy: 0.888750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.411527\n",
            "accuracy: 0.867500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.378024\n",
            "accuracy: 0.871250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.352823\n",
            "accuracy: 0.890000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.320036\n",
            "accuracy: 0.890000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.350325\n",
            "accuracy: 0.897500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.396303\n",
            "accuracy: 0.855000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.372431\n",
            "accuracy: 0.866250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.367313\n",
            "accuracy: 0.878750\n",
            "2018-10-30 18:39:49.083241\n",
            "---- EPOCH 033 EVALUATION ----\n",
            "eval mean loss: 0.360680\n",
            "eval accuracy: 0.884927\n",
            "eval avg class acc: 0.839855\n",
            "**** EPOCH 034 ****\n",
            "2018-10-30 18:40:01.374975\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.417209\n",
            "accuracy: 0.871250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.394838\n",
            "accuracy: 0.876250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.323017\n",
            "accuracy: 0.893750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.391828\n",
            "accuracy: 0.870000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.393038\n",
            "accuracy: 0.877500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.413819\n",
            "accuracy: 0.876250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.375277\n",
            "accuracy: 0.875000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.354710\n",
            "accuracy: 0.885000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.401371\n",
            "accuracy: 0.872500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.365556\n",
            "accuracy: 0.873750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.328004\n",
            "accuracy: 0.896250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.333996\n",
            "accuracy: 0.896250\n",
            "2018-10-30 18:42:45.600075\n",
            "---- EPOCH 034 EVALUATION ----\n",
            "eval mean loss: 0.357303\n",
            "eval accuracy: 0.884927\n",
            "eval avg class acc: 0.857866\n",
            "**** EPOCH 035 ****\n",
            "2018-10-30 18:42:57.942618\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.319330\n",
            "accuracy: 0.896250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.340894\n",
            "accuracy: 0.887500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.370255\n",
            "accuracy: 0.892500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.364670\n",
            "accuracy: 0.870000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.342942\n",
            "accuracy: 0.892500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.306385\n",
            "accuracy: 0.913750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.378926\n",
            "accuracy: 0.867500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.359898\n",
            "accuracy: 0.866250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.341457\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.367999\n",
            "accuracy: 0.883750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.378978\n",
            "accuracy: 0.882500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.378958\n",
            "accuracy: 0.876250\n",
            "2018-10-30 18:45:41.894106\n",
            "---- EPOCH 035 EVALUATION ----\n",
            "eval mean loss: 0.355270\n",
            "eval accuracy: 0.887358\n",
            "eval avg class acc: 0.857529\n",
            "**** EPOCH 036 ****\n",
            "2018-10-30 18:45:54.188300\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.326232\n",
            "accuracy: 0.883750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.393474\n",
            "accuracy: 0.870000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.328122\n",
            "accuracy: 0.891250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.321035\n",
            "accuracy: 0.890000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.363605\n",
            "accuracy: 0.885000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.333645\n",
            "accuracy: 0.885000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.363139\n",
            "accuracy: 0.873750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.338250\n",
            "accuracy: 0.890000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.363740\n",
            "accuracy: 0.871250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.338461\n",
            "accuracy: 0.885000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.331947\n",
            "accuracy: 0.868750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.312725\n",
            "accuracy: 0.886250\n",
            "2018-10-30 18:48:38.320752\n",
            "---- EPOCH 036 EVALUATION ----\n",
            "eval mean loss: 0.385700\n",
            "eval accuracy: 0.884522\n",
            "eval avg class acc: 0.840552\n",
            "**** EPOCH 037 ****\n",
            "2018-10-30 18:48:50.646384\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.303815\n",
            "accuracy: 0.907500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.331051\n",
            "accuracy: 0.895000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.353669\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.351948\n",
            "accuracy: 0.862500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.328803\n",
            "accuracy: 0.882500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.327733\n",
            "accuracy: 0.878750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.373544\n",
            "accuracy: 0.878750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.339167\n",
            "accuracy: 0.883750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.328798\n",
            "accuracy: 0.881250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.411299\n",
            "accuracy: 0.872500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.341977\n",
            "accuracy: 0.891250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.365724\n",
            "accuracy: 0.883750\n",
            "2018-10-30 18:51:34.672247\n",
            "---- EPOCH 037 EVALUATION ----\n",
            "eval mean loss: 0.376504\n",
            "eval accuracy: 0.880875\n",
            "eval avg class acc: 0.855570\n",
            "**** EPOCH 038 ****\n",
            "2018-10-30 18:51:47.030100\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.353396\n",
            "accuracy: 0.882500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.301789\n",
            "accuracy: 0.895000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.425956\n",
            "accuracy: 0.863750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.293978\n",
            "accuracy: 0.905000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.307032\n",
            "accuracy: 0.895000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.308268\n",
            "accuracy: 0.885000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.298772\n",
            "accuracy: 0.906250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.434782\n",
            "accuracy: 0.875000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.356284\n",
            "accuracy: 0.880000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.340929\n",
            "accuracy: 0.885000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.349579\n",
            "accuracy: 0.876250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.386129\n",
            "accuracy: 0.876250\n",
            "2018-10-30 18:54:31.071575\n",
            "---- EPOCH 038 EVALUATION ----\n",
            "eval mean loss: 0.364482\n",
            "eval accuracy: 0.888979\n",
            "eval avg class acc: 0.859517\n",
            "**** EPOCH 039 ****\n",
            "2018-10-30 18:54:43.408538\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.364590\n",
            "accuracy: 0.880000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.348294\n",
            "accuracy: 0.878750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.346623\n",
            "accuracy: 0.887500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.370944\n",
            "accuracy: 0.873750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.320565\n",
            "accuracy: 0.905000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.403957\n",
            "accuracy: 0.865000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.334002\n",
            "accuracy: 0.891250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.313292\n",
            "accuracy: 0.900000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.329644\n",
            "accuracy: 0.881250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.336875\n",
            "accuracy: 0.876250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.329256\n",
            "accuracy: 0.883750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.344242\n",
            "accuracy: 0.895000\n",
            "2018-10-30 18:57:27.243907\n",
            "---- EPOCH 039 EVALUATION ----\n",
            "eval mean loss: 0.377677\n",
            "eval accuracy: 0.880875\n",
            "eval avg class acc: 0.843029\n",
            "**** EPOCH 040 ****\n",
            "2018-10-30 18:57:39.568113\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.324553\n",
            "accuracy: 0.887500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.347220\n",
            "accuracy: 0.886250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.318629\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.321767\n",
            "accuracy: 0.883750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.349386\n",
            "accuracy: 0.873750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.339648\n",
            "accuracy: 0.878750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.293737\n",
            "accuracy: 0.907500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.367474\n",
            "accuracy: 0.881250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.329268\n",
            "accuracy: 0.895000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.332348\n",
            "accuracy: 0.890000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.314019\n",
            "accuracy: 0.906250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.318759\n",
            "accuracy: 0.898750\n",
            "2018-10-30 19:00:23.643733\n",
            "---- EPOCH 040 EVALUATION ----\n",
            "eval mean loss: 0.370877\n",
            "eval accuracy: 0.878849\n",
            "eval avg class acc: 0.847157\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 041 ****\n",
            "2018-10-30 19:00:36.422752\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.295780\n",
            "accuracy: 0.892500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.351083\n",
            "accuracy: 0.880000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.307569\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.299388\n",
            "accuracy: 0.902500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.312978\n",
            "accuracy: 0.886250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.325360\n",
            "accuracy: 0.882500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.301540\n",
            "accuracy: 0.902500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.336067\n",
            "accuracy: 0.881250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.281953\n",
            "accuracy: 0.912500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.312091\n",
            "accuracy: 0.898750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.315217\n",
            "accuracy: 0.898750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.292538\n",
            "accuracy: 0.896250\n",
            "2018-10-30 19:03:20.378516\n",
            "---- EPOCH 041 EVALUATION ----\n",
            "eval mean loss: 0.353831\n",
            "eval accuracy: 0.888169\n",
            "eval avg class acc: 0.858558\n",
            "**** EPOCH 042 ****\n",
            "2018-10-30 19:03:32.695932\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.294231\n",
            "accuracy: 0.913750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.293000\n",
            "accuracy: 0.905000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.296775\n",
            "accuracy: 0.913750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.276348\n",
            "accuracy: 0.892500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.296382\n",
            "accuracy: 0.900000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.279298\n",
            "accuracy: 0.897500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.297938\n",
            "accuracy: 0.892500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.353748\n",
            "accuracy: 0.883750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.308726\n",
            "accuracy: 0.893750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.279960\n",
            "accuracy: 0.896250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.308743\n",
            "accuracy: 0.903750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.321696\n",
            "accuracy: 0.903750\n",
            "2018-10-30 19:06:16.976929\n",
            "---- EPOCH 042 EVALUATION ----\n",
            "eval mean loss: 0.353165\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.864105\n",
            "**** EPOCH 043 ****\n",
            "2018-10-30 19:06:29.326383\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.353430\n",
            "accuracy: 0.881250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.306101\n",
            "accuracy: 0.892500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.286812\n",
            "accuracy: 0.907500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.285946\n",
            "accuracy: 0.902500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.290854\n",
            "accuracy: 0.905000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.290037\n",
            "accuracy: 0.895000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.324013\n",
            "accuracy: 0.886250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.269175\n",
            "accuracy: 0.906250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.293532\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.264800\n",
            "accuracy: 0.910000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.326525\n",
            "accuracy: 0.891250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.334081\n",
            "accuracy: 0.883750\n",
            "2018-10-30 19:09:13.758944\n",
            "---- EPOCH 043 EVALUATION ----\n",
            "eval mean loss: 0.368004\n",
            "eval accuracy: 0.882901\n",
            "eval avg class acc: 0.851977\n",
            "**** EPOCH 044 ****\n",
            "2018-10-30 19:09:26.100286\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.244945\n",
            "accuracy: 0.913750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.262427\n",
            "accuracy: 0.911250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.294206\n",
            "accuracy: 0.897500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.314229\n",
            "accuracy: 0.897500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.258527\n",
            "accuracy: 0.903750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.283373\n",
            "accuracy: 0.892500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.284327\n",
            "accuracy: 0.896250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.343086\n",
            "accuracy: 0.882500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.279508\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.289642\n",
            "accuracy: 0.913750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.257292\n",
            "accuracy: 0.918750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.323608\n",
            "accuracy: 0.882500\n",
            "2018-10-30 19:12:10.412498\n",
            "---- EPOCH 044 EVALUATION ----\n",
            "eval mean loss: 0.377770\n",
            "eval accuracy: 0.877229\n",
            "eval avg class acc: 0.857564\n",
            "**** EPOCH 045 ****\n",
            "2018-10-30 19:12:22.760183\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.289713\n",
            "accuracy: 0.902500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.300538\n",
            "accuracy: 0.891250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.307245\n",
            "accuracy: 0.903750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.266670\n",
            "accuracy: 0.906250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.281554\n",
            "accuracy: 0.897500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.326730\n",
            "accuracy: 0.881250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.265358\n",
            "accuracy: 0.907500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.293113\n",
            "accuracy: 0.900000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.266276\n",
            "accuracy: 0.905000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.274010\n",
            "accuracy: 0.901250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.250557\n",
            "accuracy: 0.916250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.327972\n",
            "accuracy: 0.895000\n",
            "2018-10-30 19:15:06.916696\n",
            "---- EPOCH 045 EVALUATION ----\n",
            "eval mean loss: 0.379038\n",
            "eval accuracy: 0.872366\n",
            "eval avg class acc: 0.837372\n",
            "**** EPOCH 046 ****\n",
            "2018-10-30 19:15:19.237329\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.310006\n",
            "accuracy: 0.883750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.277409\n",
            "accuracy: 0.912500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.300190\n",
            "accuracy: 0.892500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.315371\n",
            "accuracy: 0.905000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.261242\n",
            "accuracy: 0.908750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.295151\n",
            "accuracy: 0.903750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.265855\n",
            "accuracy: 0.903750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.304763\n",
            "accuracy: 0.891250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.316695\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.275485\n",
            "accuracy: 0.906250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.284536\n",
            "accuracy: 0.906250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.295004\n",
            "accuracy: 0.898750\n",
            "2018-10-30 19:18:03.007782\n",
            "---- EPOCH 046 EVALUATION ----\n",
            "eval mean loss: 0.351138\n",
            "eval accuracy: 0.886953\n",
            "eval avg class acc: 0.851767\n",
            "**** EPOCH 047 ****\n",
            "2018-10-30 19:18:15.272791\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.285894\n",
            "accuracy: 0.905000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.326244\n",
            "accuracy: 0.888750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.341441\n",
            "accuracy: 0.890000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.251377\n",
            "accuracy: 0.912500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.289950\n",
            "accuracy: 0.902500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.304160\n",
            "accuracy: 0.898750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.277235\n",
            "accuracy: 0.920000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.314265\n",
            "accuracy: 0.887500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.302666\n",
            "accuracy: 0.901250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.287072\n",
            "accuracy: 0.901250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.274098\n",
            "accuracy: 0.905000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.322057\n",
            "accuracy: 0.893750\n",
            "2018-10-30 19:20:59.281133\n",
            "---- EPOCH 047 EVALUATION ----\n",
            "eval mean loss: 0.380649\n",
            "eval accuracy: 0.882091\n",
            "eval avg class acc: 0.862936\n",
            "**** EPOCH 048 ****\n",
            "2018-10-30 19:21:11.589197\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.287949\n",
            "accuracy: 0.901250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.286724\n",
            "accuracy: 0.908750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.274007\n",
            "accuracy: 0.902500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.255806\n",
            "accuracy: 0.920000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.298271\n",
            "accuracy: 0.898750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.308680\n",
            "accuracy: 0.902500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.281228\n",
            "accuracy: 0.910000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.248972\n",
            "accuracy: 0.918750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.303551\n",
            "accuracy: 0.897500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.324067\n",
            "accuracy: 0.880000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.272059\n",
            "accuracy: 0.893750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.284284\n",
            "accuracy: 0.907500\n",
            "2018-10-30 19:23:55.969251\n",
            "---- EPOCH 048 EVALUATION ----\n",
            "eval mean loss: 0.358851\n",
            "eval accuracy: 0.891410\n",
            "eval avg class acc: 0.851390\n",
            "**** EPOCH 049 ****\n",
            "2018-10-30 19:24:08.334609\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.254014\n",
            "accuracy: 0.922500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.292746\n",
            "accuracy: 0.896250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.286246\n",
            "accuracy: 0.903750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.290237\n",
            "accuracy: 0.905000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.274354\n",
            "accuracy: 0.905000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.288918\n",
            "accuracy: 0.900000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.249968\n",
            "accuracy: 0.921250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.250876\n",
            "accuracy: 0.907500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.261901\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.351290\n",
            "accuracy: 0.892500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.306530\n",
            "accuracy: 0.905000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.259082\n",
            "accuracy: 0.911250\n",
            "2018-10-30 19:26:52.492059\n",
            "---- EPOCH 049 EVALUATION ----\n",
            "eval mean loss: 0.397119\n",
            "eval accuracy: 0.864668\n",
            "eval avg class acc: 0.844924\n",
            "**** EPOCH 050 ****\n",
            "2018-10-30 19:27:04.808512\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.256706\n",
            "accuracy: 0.910000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.327650\n",
            "accuracy: 0.888750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.294198\n",
            "accuracy: 0.900000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.242447\n",
            "accuracy: 0.915000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.257250\n",
            "accuracy: 0.911250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.265224\n",
            "accuracy: 0.917500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.273981\n",
            "accuracy: 0.910000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.293609\n",
            "accuracy: 0.898750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.330457\n",
            "accuracy: 0.890000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.317389\n",
            "accuracy: 0.898750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.278170\n",
            "accuracy: 0.903750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.296817\n",
            "accuracy: 0.893750\n",
            "2018-10-30 19:29:48.975814\n",
            "---- EPOCH 050 EVALUATION ----\n",
            "eval mean loss: 0.384368\n",
            "eval accuracy: 0.880875\n",
            "eval avg class acc: 0.857413\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 051 ****\n",
            "2018-10-30 19:30:01.761745\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.296760\n",
            "accuracy: 0.901250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.281740\n",
            "accuracy: 0.905000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.238023\n",
            "accuracy: 0.911250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.271397\n",
            "accuracy: 0.908750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.328824\n",
            "accuracy: 0.901250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.233470\n",
            "accuracy: 0.923750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.293348\n",
            "accuracy: 0.892500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.230221\n",
            "accuracy: 0.917500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.276981\n",
            "accuracy: 0.917500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.270217\n",
            "accuracy: 0.911250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.288061\n",
            "accuracy: 0.906250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.264639\n",
            "accuracy: 0.901250\n",
            "2018-10-30 19:32:46.097578\n",
            "---- EPOCH 051 EVALUATION ----\n",
            "eval mean loss: 0.383558\n",
            "eval accuracy: 0.875203\n",
            "eval avg class acc: 0.849593\n",
            "**** EPOCH 052 ****\n",
            "2018-10-30 19:32:58.411180\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.262860\n",
            "accuracy: 0.906250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.261530\n",
            "accuracy: 0.906250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.283390\n",
            "accuracy: 0.907500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.307189\n",
            "accuracy: 0.903750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.255918\n",
            "accuracy: 0.918750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.285075\n",
            "accuracy: 0.908750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.247851\n",
            "accuracy: 0.917500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.307108\n",
            "accuracy: 0.893750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.234628\n",
            "accuracy: 0.922500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.272563\n",
            "accuracy: 0.908750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.343558\n",
            "accuracy: 0.902500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.262476\n",
            "accuracy: 0.907500\n",
            "2018-10-30 19:35:42.366726\n",
            "---- EPOCH 052 EVALUATION ----\n",
            "eval mean loss: 0.371499\n",
            "eval accuracy: 0.887358\n",
            "eval avg class acc: 0.861651\n",
            "**** EPOCH 053 ****\n",
            "2018-10-30 19:35:54.650339\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.252084\n",
            "accuracy: 0.911250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.250699\n",
            "accuracy: 0.912500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.284330\n",
            "accuracy: 0.898750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.233772\n",
            "accuracy: 0.925000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.262038\n",
            "accuracy: 0.905000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.278120\n",
            "accuracy: 0.900000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.255625\n",
            "accuracy: 0.903750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.335310\n",
            "accuracy: 0.891250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.288604\n",
            "accuracy: 0.901250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.261108\n",
            "accuracy: 0.923750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.234230\n",
            "accuracy: 0.921250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.278344\n",
            "accuracy: 0.913750\n",
            "2018-10-30 19:38:38.632323\n",
            "---- EPOCH 053 EVALUATION ----\n",
            "eval mean loss: 0.344577\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.860395\n",
            "**** EPOCH 054 ****\n",
            "2018-10-30 19:38:50.952705\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.296757\n",
            "accuracy: 0.907500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.234591\n",
            "accuracy: 0.917500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.243494\n",
            "accuracy: 0.913750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.283970\n",
            "accuracy: 0.903750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.235757\n",
            "accuracy: 0.908750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.253047\n",
            "accuracy: 0.921250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.259233\n",
            "accuracy: 0.897500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.274891\n",
            "accuracy: 0.905000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.266210\n",
            "accuracy: 0.915000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.243272\n",
            "accuracy: 0.921250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.269950\n",
            "accuracy: 0.905000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.291773\n",
            "accuracy: 0.907500\n",
            "2018-10-30 19:41:35.090249\n",
            "---- EPOCH 054 EVALUATION ----\n",
            "eval mean loss: 0.378300\n",
            "eval accuracy: 0.883712\n",
            "eval avg class acc: 0.856012\n",
            "**** EPOCH 055 ****\n",
            "2018-10-30 19:41:47.406879\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.221370\n",
            "accuracy: 0.916250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.272684\n",
            "accuracy: 0.901250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.236751\n",
            "accuracy: 0.912500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.279056\n",
            "accuracy: 0.903750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.275891\n",
            "accuracy: 0.897500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.297191\n",
            "accuracy: 0.888750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.278630\n",
            "accuracy: 0.900000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.256242\n",
            "accuracy: 0.910000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.295121\n",
            "accuracy: 0.896250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.252058\n",
            "accuracy: 0.916250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.274942\n",
            "accuracy: 0.907500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.255756\n",
            "accuracy: 0.911250\n",
            "2018-10-30 19:44:31.504436\n",
            "---- EPOCH 055 EVALUATION ----\n",
            "eval mean loss: 0.340559\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.859064\n",
            "**** EPOCH 056 ****\n",
            "2018-10-30 19:44:43.859690\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.236701\n",
            "accuracy: 0.910000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.242668\n",
            "accuracy: 0.922500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.269974\n",
            "accuracy: 0.907500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.232243\n",
            "accuracy: 0.925000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.257989\n",
            "accuracy: 0.925000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.266055\n",
            "accuracy: 0.915000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.202365\n",
            "accuracy: 0.931250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.271317\n",
            "accuracy: 0.900000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.268143\n",
            "accuracy: 0.907500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.255130\n",
            "accuracy: 0.920000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.273982\n",
            "accuracy: 0.908750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.237252\n",
            "accuracy: 0.923750\n",
            "2018-10-30 19:47:27.912859\n",
            "---- EPOCH 056 EVALUATION ----\n",
            "eval mean loss: 0.381286\n",
            "eval accuracy: 0.880065\n",
            "eval avg class acc: 0.848802\n",
            "**** EPOCH 057 ****\n",
            "2018-10-30 19:47:40.237763\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.200237\n",
            "accuracy: 0.936250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.270039\n",
            "accuracy: 0.910000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.287369\n",
            "accuracy: 0.908750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.221612\n",
            "accuracy: 0.930000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.264618\n",
            "accuracy: 0.902500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.283519\n",
            "accuracy: 0.896250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.231421\n",
            "accuracy: 0.908750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.309370\n",
            "accuracy: 0.892500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.247903\n",
            "accuracy: 0.913750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.310603\n",
            "accuracy: 0.898750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.291327\n",
            "accuracy: 0.892500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.254234\n",
            "accuracy: 0.903750\n",
            "2018-10-30 19:50:24.278386\n",
            "---- EPOCH 057 EVALUATION ----\n",
            "eval mean loss: 0.355761\n",
            "eval accuracy: 0.881686\n",
            "eval avg class acc: 0.852785\n",
            "**** EPOCH 058 ****\n",
            "2018-10-30 19:50:36.588437\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.223259\n",
            "accuracy: 0.918750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.267492\n",
            "accuracy: 0.910000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.208071\n",
            "accuracy: 0.922500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.243713\n",
            "accuracy: 0.916250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.253927\n",
            "accuracy: 0.915000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.284684\n",
            "accuracy: 0.901250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.240221\n",
            "accuracy: 0.923750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.281946\n",
            "accuracy: 0.897500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.305387\n",
            "accuracy: 0.910000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.238157\n",
            "accuracy: 0.922500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.251911\n",
            "accuracy: 0.923750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.290031\n",
            "accuracy: 0.902500\n",
            "2018-10-30 19:53:20.749883\n",
            "---- EPOCH 058 EVALUATION ----\n",
            "eval mean loss: 0.356898\n",
            "eval accuracy: 0.890194\n",
            "eval avg class acc: 0.862686\n",
            "**** EPOCH 059 ****\n",
            "2018-10-30 19:53:33.087485\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.250295\n",
            "accuracy: 0.921250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.235400\n",
            "accuracy: 0.922500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.280442\n",
            "accuracy: 0.903750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.234434\n",
            "accuracy: 0.921250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.261533\n",
            "accuracy: 0.910000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.244344\n",
            "accuracy: 0.917500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.206977\n",
            "accuracy: 0.928750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.270703\n",
            "accuracy: 0.916250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.267495\n",
            "accuracy: 0.903750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.251146\n",
            "accuracy: 0.920000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.279111\n",
            "accuracy: 0.908750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.251469\n",
            "accuracy: 0.925000\n",
            "2018-10-30 19:56:17.164117\n",
            "---- EPOCH 059 EVALUATION ----\n",
            "eval mean loss: 0.379001\n",
            "eval accuracy: 0.890600\n",
            "eval avg class acc: 0.864186\n",
            "**** EPOCH 060 ****\n",
            "2018-10-30 19:56:29.446466\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.226552\n",
            "accuracy: 0.920000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.215132\n",
            "accuracy: 0.926250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.277067\n",
            "accuracy: 0.917500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.247202\n",
            "accuracy: 0.920000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.294212\n",
            "accuracy: 0.910000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.235386\n",
            "accuracy: 0.903750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.223237\n",
            "accuracy: 0.916250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.236832\n",
            "accuracy: 0.912500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.211942\n",
            "accuracy: 0.930000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.310397\n",
            "accuracy: 0.898750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.269328\n",
            "accuracy: 0.908750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.223172\n",
            "accuracy: 0.918750\n",
            "2018-10-30 19:59:13.257953\n",
            "---- EPOCH 060 EVALUATION ----\n",
            "eval mean loss: 0.365834\n",
            "eval accuracy: 0.891005\n",
            "eval avg class acc: 0.858314\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 061 ****\n",
            "2018-10-30 19:59:26.025067\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.210128\n",
            "accuracy: 0.927500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.254194\n",
            "accuracy: 0.923750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.227609\n",
            "accuracy: 0.926250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.273120\n",
            "accuracy: 0.912500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.216447\n",
            "accuracy: 0.931250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.267663\n",
            "accuracy: 0.910000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.255588\n",
            "accuracy: 0.907500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.255343\n",
            "accuracy: 0.908750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.263327\n",
            "accuracy: 0.907500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.210735\n",
            "accuracy: 0.925000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.262054\n",
            "accuracy: 0.911250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.237243\n",
            "accuracy: 0.921250\n",
            "2018-10-30 20:02:10.002109\n",
            "---- EPOCH 061 EVALUATION ----\n",
            "eval mean loss: 0.362526\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.870430\n",
            "**** EPOCH 062 ****\n",
            "2018-10-30 20:02:22.301994\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.228208\n",
            "accuracy: 0.927500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.247983\n",
            "accuracy: 0.933750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.216251\n",
            "accuracy: 0.925000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.218922\n",
            "accuracy: 0.918750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.227078\n",
            "accuracy: 0.908750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.232151\n",
            "accuracy: 0.906250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.234693\n",
            "accuracy: 0.923750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.253678\n",
            "accuracy: 0.911250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.212406\n",
            "accuracy: 0.921250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.242530\n",
            "accuracy: 0.921250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.229496\n",
            "accuracy: 0.925000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.204528\n",
            "accuracy: 0.931250\n",
            "2018-10-30 20:05:06.266432\n",
            "---- EPOCH 062 EVALUATION ----\n",
            "eval mean loss: 0.358295\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.864227\n",
            "**** EPOCH 063 ****\n",
            "2018-10-30 20:05:18.591519\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.237010\n",
            "accuracy: 0.922500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.210969\n",
            "accuracy: 0.923750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.167172\n",
            "accuracy: 0.941250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.256867\n",
            "accuracy: 0.915000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.243293\n",
            "accuracy: 0.913750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.184865\n",
            "accuracy: 0.936250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.277670\n",
            "accuracy: 0.911250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.252950\n",
            "accuracy: 0.920000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.216559\n",
            "accuracy: 0.925000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.242210\n",
            "accuracy: 0.912500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.283462\n",
            "accuracy: 0.903750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.236936\n",
            "accuracy: 0.917500\n",
            "2018-10-30 20:08:02.580468\n",
            "---- EPOCH 063 EVALUATION ----\n",
            "eval mean loss: 0.363997\n",
            "eval accuracy: 0.885332\n",
            "eval avg class acc: 0.857267\n",
            "**** EPOCH 064 ****\n",
            "2018-10-30 20:08:14.905437\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.237372\n",
            "accuracy: 0.923750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.213788\n",
            "accuracy: 0.928750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.214419\n",
            "accuracy: 0.932500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.233862\n",
            "accuracy: 0.921250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.235989\n",
            "accuracy: 0.913750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.191599\n",
            "accuracy: 0.933750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.223938\n",
            "accuracy: 0.920000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.219214\n",
            "accuracy: 0.928750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.251020\n",
            "accuracy: 0.907500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.199145\n",
            "accuracy: 0.930000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.217954\n",
            "accuracy: 0.923750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.211210\n",
            "accuracy: 0.922500\n",
            "2018-10-30 20:10:58.900845\n",
            "---- EPOCH 064 EVALUATION ----\n",
            "eval mean loss: 0.362384\n",
            "eval accuracy: 0.888169\n",
            "eval avg class acc: 0.857477\n",
            "**** EPOCH 065 ****\n",
            "2018-10-30 20:11:11.226875\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.204377\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.214162\n",
            "accuracy: 0.928750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.208643\n",
            "accuracy: 0.935000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.189751\n",
            "accuracy: 0.930000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.186133\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.214247\n",
            "accuracy: 0.926250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.287428\n",
            "accuracy: 0.902500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.225222\n",
            "accuracy: 0.928750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.229515\n",
            "accuracy: 0.925000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.247254\n",
            "accuracy: 0.913750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.243765\n",
            "accuracy: 0.923750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.245341\n",
            "accuracy: 0.916250\n",
            "2018-10-30 20:13:55.242793\n",
            "---- EPOCH 065 EVALUATION ----\n",
            "eval mean loss: 0.369795\n",
            "eval accuracy: 0.888979\n",
            "eval avg class acc: 0.857058\n",
            "**** EPOCH 066 ****\n",
            "2018-10-30 20:14:07.564615\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.250311\n",
            "accuracy: 0.922500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.253219\n",
            "accuracy: 0.915000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.207771\n",
            "accuracy: 0.927500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.194276\n",
            "accuracy: 0.926250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.226131\n",
            "accuracy: 0.927500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.243140\n",
            "accuracy: 0.915000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.268805\n",
            "accuracy: 0.907500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.217344\n",
            "accuracy: 0.923750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.184863\n",
            "accuracy: 0.938750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.230362\n",
            "accuracy: 0.921250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.203942\n",
            "accuracy: 0.922500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.224059\n",
            "accuracy: 0.921250\n",
            "2018-10-30 20:16:51.958361\n",
            "---- EPOCH 066 EVALUATION ----\n",
            "eval mean loss: 0.385001\n",
            "eval accuracy: 0.887358\n",
            "eval avg class acc: 0.860971\n",
            "**** EPOCH 067 ****\n",
            "2018-10-30 20:17:04.258415\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.190975\n",
            "accuracy: 0.930000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.169422\n",
            "accuracy: 0.945000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.194610\n",
            "accuracy: 0.942500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.199776\n",
            "accuracy: 0.933750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.220704\n",
            "accuracy: 0.926250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.225687\n",
            "accuracy: 0.926250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.171423\n",
            "accuracy: 0.931250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.223002\n",
            "accuracy: 0.927500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.267581\n",
            "accuracy: 0.912500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.210380\n",
            "accuracy: 0.925000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.191776\n",
            "accuracy: 0.927500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.233400\n",
            "accuracy: 0.923750\n",
            "2018-10-30 20:19:48.337181\n",
            "---- EPOCH 067 EVALUATION ----\n",
            "eval mean loss: 0.372654\n",
            "eval accuracy: 0.891005\n",
            "eval avg class acc: 0.858151\n",
            "**** EPOCH 068 ****\n",
            "2018-10-30 20:20:00.639418\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.191638\n",
            "accuracy: 0.936250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.208721\n",
            "accuracy: 0.922500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.214837\n",
            "accuracy: 0.931250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.184790\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.220664\n",
            "accuracy: 0.926250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.208783\n",
            "accuracy: 0.925000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.219680\n",
            "accuracy: 0.915000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.236855\n",
            "accuracy: 0.925000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.225884\n",
            "accuracy: 0.920000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.202021\n",
            "accuracy: 0.917500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.247055\n",
            "accuracy: 0.912500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.197990\n",
            "accuracy: 0.935000\n",
            "2018-10-30 20:22:44.937841\n",
            "---- EPOCH 068 EVALUATION ----\n",
            "eval mean loss: 0.364684\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.866599\n",
            "**** EPOCH 069 ****\n",
            "2018-10-30 20:22:57.307571\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.233748\n",
            "accuracy: 0.916250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.239721\n",
            "accuracy: 0.920000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.225414\n",
            "accuracy: 0.915000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.179935\n",
            "accuracy: 0.931250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.218617\n",
            "accuracy: 0.931250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.256308\n",
            "accuracy: 0.922500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.181759\n",
            "accuracy: 0.930000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.244545\n",
            "accuracy: 0.918750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.230570\n",
            "accuracy: 0.921250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.232427\n",
            "accuracy: 0.911250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.218587\n",
            "accuracy: 0.927500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.211962\n",
            "accuracy: 0.936250\n",
            "2018-10-30 20:25:41.624232\n",
            "---- EPOCH 069 EVALUATION ----\n",
            "eval mean loss: 0.352067\n",
            "eval accuracy: 0.897893\n",
            "eval avg class acc: 0.867099\n",
            "**** EPOCH 070 ****\n",
            "2018-10-30 20:25:53.966922\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.195086\n",
            "accuracy: 0.928750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.212537\n",
            "accuracy: 0.927500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.220082\n",
            "accuracy: 0.917500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.197316\n",
            "accuracy: 0.938750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.210239\n",
            "accuracy: 0.923750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.182409\n",
            "accuracy: 0.937500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.225877\n",
            "accuracy: 0.928750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.224534\n",
            "accuracy: 0.920000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.189332\n",
            "accuracy: 0.927500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.236904\n",
            "accuracy: 0.911250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.243381\n",
            "accuracy: 0.920000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.217962\n",
            "accuracy: 0.931250\n",
            "2018-10-30 20:28:38.394558\n",
            "---- EPOCH 070 EVALUATION ----\n",
            "eval mean loss: 0.356074\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.863099\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 071 ****\n",
            "2018-10-30 20:28:51.186499\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.188066\n",
            "accuracy: 0.926250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.227076\n",
            "accuracy: 0.921250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.209221\n",
            "accuracy: 0.923750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.184644\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.219237\n",
            "accuracy: 0.932500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.225783\n",
            "accuracy: 0.917500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.217509\n",
            "accuracy: 0.932500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.186846\n",
            "accuracy: 0.935000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.241977\n",
            "accuracy: 0.918750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.225974\n",
            "accuracy: 0.920000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.194535\n",
            "accuracy: 0.932500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.244440\n",
            "accuracy: 0.918750\n",
            "2018-10-30 20:31:35.400569\n",
            "---- EPOCH 071 EVALUATION ----\n",
            "eval mean loss: 0.364574\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.868570\n",
            "**** EPOCH 072 ****\n",
            "2018-10-30 20:31:47.774098\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.228517\n",
            "accuracy: 0.926250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.175811\n",
            "accuracy: 0.936250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.221995\n",
            "accuracy: 0.921250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.257032\n",
            "accuracy: 0.912500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.221620\n",
            "accuracy: 0.925000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.191929\n",
            "accuracy: 0.938750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.160125\n",
            "accuracy: 0.946250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.175542\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.205549\n",
            "accuracy: 0.922500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.217150\n",
            "accuracy: 0.920000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.209542\n",
            "accuracy: 0.922500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.179729\n",
            "accuracy: 0.933750\n",
            "2018-10-30 20:34:32.010031\n",
            "---- EPOCH 072 EVALUATION ----\n",
            "eval mean loss: 0.386746\n",
            "eval accuracy: 0.887763\n",
            "eval avg class acc: 0.859343\n",
            "**** EPOCH 073 ****\n",
            "2018-10-30 20:34:44.363057\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.181009\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.191752\n",
            "accuracy: 0.936250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.183037\n",
            "accuracy: 0.931250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.201219\n",
            "accuracy: 0.918750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.213276\n",
            "accuracy: 0.930000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.228101\n",
            "accuracy: 0.925000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.207590\n",
            "accuracy: 0.927500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.236471\n",
            "accuracy: 0.921250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.183353\n",
            "accuracy: 0.933750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.196878\n",
            "accuracy: 0.928750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.177234\n",
            "accuracy: 0.945000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.236727\n",
            "accuracy: 0.918750\n",
            "2018-10-30 20:37:28.514318\n",
            "---- EPOCH 073 EVALUATION ----\n",
            "eval mean loss: 0.388451\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.861267\n",
            "**** EPOCH 074 ****\n",
            "2018-10-30 20:37:40.821956\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.215483\n",
            "accuracy: 0.925000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.192682\n",
            "accuracy: 0.930000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.217350\n",
            "accuracy: 0.927500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.198044\n",
            "accuracy: 0.928750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.183894\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.226572\n",
            "accuracy: 0.918750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.203862\n",
            "accuracy: 0.933750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.205881\n",
            "accuracy: 0.930000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.213508\n",
            "accuracy: 0.920000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.222564\n",
            "accuracy: 0.917500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.239511\n",
            "accuracy: 0.908750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.176350\n",
            "accuracy: 0.930000\n",
            "2018-10-30 20:40:24.990334\n",
            "---- EPOCH 074 EVALUATION ----\n",
            "eval mean loss: 0.377731\n",
            "eval accuracy: 0.898298\n",
            "eval avg class acc: 0.867186\n",
            "**** EPOCH 075 ****\n",
            "2018-10-30 20:40:37.321091\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.190361\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.165004\n",
            "accuracy: 0.940000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.290903\n",
            "accuracy: 0.906250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.165761\n",
            "accuracy: 0.936250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.155815\n",
            "accuracy: 0.943750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.178010\n",
            "accuracy: 0.943750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.191504\n",
            "accuracy: 0.938750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.215031\n",
            "accuracy: 0.918750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.212819\n",
            "accuracy: 0.921250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.175302\n",
            "accuracy: 0.932500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.203419\n",
            "accuracy: 0.937500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.227815\n",
            "accuracy: 0.913750\n",
            "2018-10-30 20:43:21.132330\n",
            "---- EPOCH 075 EVALUATION ----\n",
            "eval mean loss: 0.387415\n",
            "eval accuracy: 0.888574\n",
            "eval avg class acc: 0.867895\n",
            "**** EPOCH 076 ****\n",
            "2018-10-30 20:43:33.425714\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.182524\n",
            "accuracy: 0.938750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.213670\n",
            "accuracy: 0.916250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.239661\n",
            "accuracy: 0.912500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.209909\n",
            "accuracy: 0.930000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.238319\n",
            "accuracy: 0.913750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.250544\n",
            "accuracy: 0.915000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.196273\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.189561\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.175247\n",
            "accuracy: 0.937500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.218363\n",
            "accuracy: 0.931250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.180447\n",
            "accuracy: 0.932500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.196540\n",
            "accuracy: 0.932500\n",
            "2018-10-30 20:46:17.447226\n",
            "---- EPOCH 076 EVALUATION ----\n",
            "eval mean loss: 0.384138\n",
            "eval accuracy: 0.891410\n",
            "eval avg class acc: 0.863814\n",
            "**** EPOCH 077 ****\n",
            "2018-10-30 20:46:29.752454\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.185641\n",
            "accuracy: 0.935000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.168904\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.293226\n",
            "accuracy: 0.920000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.178347\n",
            "accuracy: 0.928750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.192034\n",
            "accuracy: 0.928750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.225086\n",
            "accuracy: 0.930000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.190503\n",
            "accuracy: 0.940000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.243593\n",
            "accuracy: 0.925000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.224807\n",
            "accuracy: 0.925000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.197430\n",
            "accuracy: 0.925000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.225106\n",
            "accuracy: 0.920000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.187578\n",
            "accuracy: 0.948750\n",
            "2018-10-30 20:49:13.880280\n",
            "---- EPOCH 077 EVALUATION ----\n",
            "eval mean loss: 0.383169\n",
            "eval accuracy: 0.889384\n",
            "eval avg class acc: 0.868977\n",
            "**** EPOCH 078 ****\n",
            "2018-10-30 20:49:26.177988\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.160952\n",
            "accuracy: 0.935000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.215420\n",
            "accuracy: 0.931250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.195452\n",
            "accuracy: 0.931250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.203249\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.172054\n",
            "accuracy: 0.931250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.196927\n",
            "accuracy: 0.930000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.203317\n",
            "accuracy: 0.926250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.187132\n",
            "accuracy: 0.928750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.186240\n",
            "accuracy: 0.942500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.171534\n",
            "accuracy: 0.937500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.204064\n",
            "accuracy: 0.932500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.189984\n",
            "accuracy: 0.930000\n",
            "2018-10-30 20:52:10.041730\n",
            "---- EPOCH 078 EVALUATION ----\n",
            "eval mean loss: 0.372225\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873686\n",
            "**** EPOCH 079 ****\n",
            "2018-10-30 20:52:22.372742\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.202972\n",
            "accuracy: 0.935000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.167354\n",
            "accuracy: 0.942500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.173919\n",
            "accuracy: 0.933750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.171902\n",
            "accuracy: 0.941250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.192683\n",
            "accuracy: 0.937500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.183181\n",
            "accuracy: 0.936250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.183803\n",
            "accuracy: 0.933750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.185443\n",
            "accuracy: 0.932500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.213646\n",
            "accuracy: 0.926250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.222480\n",
            "accuracy: 0.913750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.164689\n",
            "accuracy: 0.941250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.249089\n",
            "accuracy: 0.912500\n",
            "2018-10-30 20:55:06.547569\n",
            "---- EPOCH 079 EVALUATION ----\n",
            "eval mean loss: 0.375299\n",
            "eval accuracy: 0.883306\n",
            "eval avg class acc: 0.858698\n",
            "**** EPOCH 080 ****\n",
            "2018-10-30 20:55:18.902700\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.183647\n",
            "accuracy: 0.923750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.170803\n",
            "accuracy: 0.941250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.222980\n",
            "accuracy: 0.931250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.169702\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.190099\n",
            "accuracy: 0.927500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.214228\n",
            "accuracy: 0.925000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.234465\n",
            "accuracy: 0.925000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.201283\n",
            "accuracy: 0.925000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.230907\n",
            "accuracy: 0.927500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.184591\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.174394\n",
            "accuracy: 0.933750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.208515\n",
            "accuracy: 0.930000\n",
            "2018-10-30 20:58:02.992321\n",
            "---- EPOCH 080 EVALUATION ----\n",
            "eval mean loss: 0.364111\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.867401\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 081 ****\n",
            "2018-10-30 20:58:15.725910\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.172892\n",
            "accuracy: 0.942500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.176028\n",
            "accuracy: 0.942500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.204902\n",
            "accuracy: 0.933750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.173739\n",
            "accuracy: 0.933750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.195397\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.175855\n",
            "accuracy: 0.938750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.214881\n",
            "accuracy: 0.927500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.189351\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.220175\n",
            "accuracy: 0.930000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.167830\n",
            "accuracy: 0.941250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.218780\n",
            "accuracy: 0.927500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.162047\n",
            "accuracy: 0.933750\n",
            "2018-10-30 21:00:59.623900\n",
            "---- EPOCH 081 EVALUATION ----\n",
            "eval mean loss: 0.367367\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.867052\n",
            "**** EPOCH 082 ****\n",
            "2018-10-30 21:01:11.958718\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.188770\n",
            "accuracy: 0.936250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.218983\n",
            "accuracy: 0.920000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.140869\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.187779\n",
            "accuracy: 0.928750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.174033\n",
            "accuracy: 0.937500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.195912\n",
            "accuracy: 0.935000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.184577\n",
            "accuracy: 0.942500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.179847\n",
            "accuracy: 0.946250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.173026\n",
            "accuracy: 0.931250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.192107\n",
            "accuracy: 0.938750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.144807\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.208300\n",
            "accuracy: 0.925000\n",
            "2018-10-30 21:03:55.940942\n",
            "---- EPOCH 082 EVALUATION ----\n",
            "eval mean loss: 0.372268\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.862262\n",
            "**** EPOCH 083 ****\n",
            "2018-10-30 21:04:08.248461\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.209200\n",
            "accuracy: 0.930000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.166744\n",
            "accuracy: 0.936250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.214522\n",
            "accuracy: 0.920000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.176994\n",
            "accuracy: 0.942500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.218645\n",
            "accuracy: 0.923750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.167229\n",
            "accuracy: 0.946250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.197919\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.162440\n",
            "accuracy: 0.938750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.164930\n",
            "accuracy: 0.943750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.176086\n",
            "accuracy: 0.932500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.167668\n",
            "accuracy: 0.941250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.167978\n",
            "accuracy: 0.938750\n",
            "2018-10-30 21:06:52.370461\n",
            "---- EPOCH 083 EVALUATION ----\n",
            "eval mean loss: 0.383132\n",
            "eval accuracy: 0.884522\n",
            "eval avg class acc: 0.862453\n",
            "**** EPOCH 084 ****\n",
            "2018-10-30 21:07:04.675640\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.176656\n",
            "accuracy: 0.930000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.142409\n",
            "accuracy: 0.948750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.139008\n",
            "accuracy: 0.951250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.193878\n",
            "accuracy: 0.937500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.167345\n",
            "accuracy: 0.937500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.167885\n",
            "accuracy: 0.937500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.171984\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.154163\n",
            "accuracy: 0.942500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.172963\n",
            "accuracy: 0.937500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.177785\n",
            "accuracy: 0.935000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.172779\n",
            "accuracy: 0.952500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.191246\n",
            "accuracy: 0.936250\n",
            "2018-10-30 21:09:48.628902\n",
            "---- EPOCH 084 EVALUATION ----\n",
            "eval mean loss: 0.367873\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.862936\n",
            "**** EPOCH 085 ****\n",
            "2018-10-30 21:10:00.987640\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.172692\n",
            "accuracy: 0.942500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.145897\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.146570\n",
            "accuracy: 0.940000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.183990\n",
            "accuracy: 0.928750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.177655\n",
            "accuracy: 0.938750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.176766\n",
            "accuracy: 0.936250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.181797\n",
            "accuracy: 0.935000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.182189\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.130118\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.206865\n",
            "accuracy: 0.925000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.214337\n",
            "accuracy: 0.928750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.169538\n",
            "accuracy: 0.937500\n",
            "2018-10-30 21:12:45.313675\n",
            "---- EPOCH 085 EVALUATION ----\n",
            "eval mean loss: 0.372524\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.867320\n",
            "**** EPOCH 086 ****\n",
            "2018-10-30 21:12:57.664377\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.141385\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.186838\n",
            "accuracy: 0.921250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.207730\n",
            "accuracy: 0.936250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.159579\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.177387\n",
            "accuracy: 0.935000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.173074\n",
            "accuracy: 0.948750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.176040\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.141700\n",
            "accuracy: 0.947500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.166087\n",
            "accuracy: 0.936250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.194404\n",
            "accuracy: 0.931250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.212249\n",
            "accuracy: 0.918750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.175001\n",
            "accuracy: 0.941250\n",
            "2018-10-30 21:15:41.867463\n",
            "---- EPOCH 086 EVALUATION ----\n",
            "eval mean loss: 0.379046\n",
            "eval accuracy: 0.891410\n",
            "eval avg class acc: 0.865192\n",
            "**** EPOCH 087 ****\n",
            "2018-10-30 21:15:54.195686\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.179900\n",
            "accuracy: 0.938750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.177135\n",
            "accuracy: 0.933750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.135028\n",
            "accuracy: 0.940000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.186885\n",
            "accuracy: 0.926250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.147337\n",
            "accuracy: 0.948750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.174750\n",
            "accuracy: 0.932500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.168744\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.176598\n",
            "accuracy: 0.935000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.185806\n",
            "accuracy: 0.938750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.194841\n",
            "accuracy: 0.927500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.209399\n",
            "accuracy: 0.931250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.152127\n",
            "accuracy: 0.945000\n",
            "2018-10-30 21:18:38.467639\n",
            "---- EPOCH 087 EVALUATION ----\n",
            "eval mean loss: 0.373072\n",
            "eval accuracy: 0.891005\n",
            "eval avg class acc: 0.866023\n",
            "**** EPOCH 088 ****\n",
            "2018-10-30 21:18:50.836936\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.135897\n",
            "accuracy: 0.953750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.136936\n",
            "accuracy: 0.947500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.157689\n",
            "accuracy: 0.942500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.188503\n",
            "accuracy: 0.927500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.146245\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.167547\n",
            "accuracy: 0.937500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.177283\n",
            "accuracy: 0.941250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.150637\n",
            "accuracy: 0.948750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.165230\n",
            "accuracy: 0.942500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.170769\n",
            "accuracy: 0.950000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.157421\n",
            "accuracy: 0.947500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.224561\n",
            "accuracy: 0.933750\n",
            "2018-10-30 21:21:34.971122\n",
            "---- EPOCH 088 EVALUATION ----\n",
            "eval mean loss: 0.379082\n",
            "eval accuracy: 0.887763\n",
            "eval avg class acc: 0.868227\n",
            "**** EPOCH 089 ****\n",
            "2018-10-30 21:21:47.261400\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.165835\n",
            "accuracy: 0.943750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.165598\n",
            "accuracy: 0.941250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.154147\n",
            "accuracy: 0.945000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.120105\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.169258\n",
            "accuracy: 0.938750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.203356\n",
            "accuracy: 0.931250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.186224\n",
            "accuracy: 0.938750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.158261\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.181748\n",
            "accuracy: 0.930000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.180296\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.164814\n",
            "accuracy: 0.937500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.174248\n",
            "accuracy: 0.940000\n",
            "2018-10-30 21:24:31.271584\n",
            "---- EPOCH 089 EVALUATION ----\n",
            "eval mean loss: 0.402887\n",
            "eval accuracy: 0.890600\n",
            "eval avg class acc: 0.866855\n",
            "**** EPOCH 090 ****\n",
            "2018-10-30 21:24:43.647321\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.156208\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.138687\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.168211\n",
            "accuracy: 0.948750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.185250\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.186274\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.199766\n",
            "accuracy: 0.932500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.186995\n",
            "accuracy: 0.926250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.189027\n",
            "accuracy: 0.931250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.157889\n",
            "accuracy: 0.948750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.148401\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.185871\n",
            "accuracy: 0.928750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.166453\n",
            "accuracy: 0.933750\n",
            "2018-10-30 21:27:27.685658\n",
            "---- EPOCH 090 EVALUATION ----\n",
            "eval mean loss: 0.379869\n",
            "eval accuracy: 0.893031\n",
            "eval avg class acc: 0.867355\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 091 ****\n",
            "2018-10-30 21:27:40.523953\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.174320\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.170077\n",
            "accuracy: 0.941250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.148659\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.137067\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.187060\n",
            "accuracy: 0.931250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.179927\n",
            "accuracy: 0.927500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.156095\n",
            "accuracy: 0.941250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.190531\n",
            "accuracy: 0.932500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.174313\n",
            "accuracy: 0.935000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.176357\n",
            "accuracy: 0.935000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.134400\n",
            "accuracy: 0.946250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.162488\n",
            "accuracy: 0.938750\n",
            "2018-10-30 21:30:24.555724\n",
            "---- EPOCH 091 EVALUATION ----\n",
            "eval mean loss: 0.370946\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.873267\n",
            "**** EPOCH 092 ****\n",
            "2018-10-30 21:30:36.867812\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.163581\n",
            "accuracy: 0.940000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.189051\n",
            "accuracy: 0.946250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.182100\n",
            "accuracy: 0.936250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.170267\n",
            "accuracy: 0.935000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.174057\n",
            "accuracy: 0.943750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.155627\n",
            "accuracy: 0.945000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.168869\n",
            "accuracy: 0.940000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.128953\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.193640\n",
            "accuracy: 0.932500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.178363\n",
            "accuracy: 0.937500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.200300\n",
            "accuracy: 0.925000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.142979\n",
            "accuracy: 0.951250\n",
            "2018-10-30 21:33:21.170305\n",
            "---- EPOCH 092 EVALUATION ----\n",
            "eval mean loss: 0.368494\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.862512\n",
            "**** EPOCH 093 ****\n",
            "2018-10-30 21:33:33.508510\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.155550\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.140443\n",
            "accuracy: 0.950000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.173091\n",
            "accuracy: 0.941250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.150671\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.131985\n",
            "accuracy: 0.953750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.157386\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.170644\n",
            "accuracy: 0.940000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.158417\n",
            "accuracy: 0.937500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.168637\n",
            "accuracy: 0.946250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.156857\n",
            "accuracy: 0.948750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.146349\n",
            "accuracy: 0.947500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.188532\n",
            "accuracy: 0.935000\n",
            "2018-10-30 21:36:17.629755\n",
            "---- EPOCH 093 EVALUATION ----\n",
            "eval mean loss: 0.380375\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.868692\n",
            "**** EPOCH 094 ****\n",
            "2018-10-30 21:36:29.969504\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.164581\n",
            "accuracy: 0.943750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.143883\n",
            "accuracy: 0.946250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.157667\n",
            "accuracy: 0.946250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.178274\n",
            "accuracy: 0.942500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.156572\n",
            "accuracy: 0.933750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.147433\n",
            "accuracy: 0.946250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.163352\n",
            "accuracy: 0.938750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.133258\n",
            "accuracy: 0.951250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.157848\n",
            "accuracy: 0.942500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.169954\n",
            "accuracy: 0.936250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.179525\n",
            "accuracy: 0.936250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.160207\n",
            "accuracy: 0.942500\n",
            "2018-10-30 21:39:14.289808\n",
            "---- EPOCH 094 EVALUATION ----\n",
            "eval mean loss: 0.365380\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.875320\n",
            "**** EPOCH 095 ****\n",
            "2018-10-30 21:39:26.686271\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.148468\n",
            "accuracy: 0.947500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.119647\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.145341\n",
            "accuracy: 0.948750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.184412\n",
            "accuracy: 0.940000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.167001\n",
            "accuracy: 0.938750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.164860\n",
            "accuracy: 0.937500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.135057\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.141097\n",
            "accuracy: 0.946250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.125752\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.207615\n",
            "accuracy: 0.932500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.159301\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.160510\n",
            "accuracy: 0.950000\n",
            "2018-10-30 21:42:10.845873\n",
            "---- EPOCH 095 EVALUATION ----\n",
            "eval mean loss: 0.377171\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.871227\n",
            "**** EPOCH 096 ****\n",
            "2018-10-30 21:42:23.165783\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.166756\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.151069\n",
            "accuracy: 0.938750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.168933\n",
            "accuracy: 0.945000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.143264\n",
            "accuracy: 0.945000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.160587\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.158302\n",
            "accuracy: 0.942500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.171041\n",
            "accuracy: 0.935000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.129602\n",
            "accuracy: 0.956250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.163381\n",
            "accuracy: 0.943750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.174818\n",
            "accuracy: 0.937500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.142260\n",
            "accuracy: 0.947500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.160006\n",
            "accuracy: 0.943750\n",
            "2018-10-30 21:45:07.460165\n",
            "---- EPOCH 096 EVALUATION ----\n",
            "eval mean loss: 0.385758\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.866849\n",
            "**** EPOCH 097 ****\n",
            "2018-10-30 21:45:19.803522\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.158217\n",
            "accuracy: 0.938750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.149457\n",
            "accuracy: 0.950000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.169104\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.161472\n",
            "accuracy: 0.941250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.183325\n",
            "accuracy: 0.930000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.139526\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.169133\n",
            "accuracy: 0.943750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.152013\n",
            "accuracy: 0.945000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.172592\n",
            "accuracy: 0.941250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.139033\n",
            "accuracy: 0.952500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.177528\n",
            "accuracy: 0.941250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.158842\n",
            "accuracy: 0.941250\n",
            "2018-10-30 21:48:04.523738\n",
            "---- EPOCH 097 EVALUATION ----\n",
            "eval mean loss: 0.374756\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.872552\n",
            "**** EPOCH 098 ****\n",
            "2018-10-30 21:48:16.869444\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.168827\n",
            "accuracy: 0.942500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.162437\n",
            "accuracy: 0.937500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.131976\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.146682\n",
            "accuracy: 0.946250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.167444\n",
            "accuracy: 0.941250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.165195\n",
            "accuracy: 0.938750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.165011\n",
            "accuracy: 0.937500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.140191\n",
            "accuracy: 0.951250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.172602\n",
            "accuracy: 0.941250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.159517\n",
            "accuracy: 0.943750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.180672\n",
            "accuracy: 0.932500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.141842\n",
            "accuracy: 0.947500\n",
            "2018-10-30 21:51:01.472612\n",
            "---- EPOCH 098 EVALUATION ----\n",
            "eval mean loss: 0.376888\n",
            "eval accuracy: 0.899109\n",
            "eval avg class acc: 0.873227\n",
            "**** EPOCH 099 ****\n",
            "2018-10-30 21:51:13.858323\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.095057\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.178183\n",
            "accuracy: 0.943750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.173503\n",
            "accuracy: 0.937500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.138573\n",
            "accuracy: 0.946250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.139038\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.178734\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.156011\n",
            "accuracy: 0.948750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.127610\n",
            "accuracy: 0.956250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.140116\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.167836\n",
            "accuracy: 0.935000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.156118\n",
            "accuracy: 0.948750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.158703\n",
            "accuracy: 0.956250\n",
            "2018-10-30 21:53:58.397771\n",
            "---- EPOCH 099 EVALUATION ----\n",
            "eval mean loss: 0.405026\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.864436\n",
            "**** EPOCH 100 ****\n",
            "2018-10-30 21:54:10.795788\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.151820\n",
            "accuracy: 0.932500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.185356\n",
            "accuracy: 0.936250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.155471\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.149210\n",
            "accuracy: 0.945000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.155699\n",
            "accuracy: 0.946250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.113232\n",
            "accuracy: 0.956250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.181733\n",
            "accuracy: 0.938750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.161390\n",
            "accuracy: 0.936250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.162139\n",
            "accuracy: 0.935000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.136015\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.179216\n",
            "accuracy: 0.938750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.163476\n",
            "accuracy: 0.940000\n",
            "2018-10-30 21:56:55.518210\n",
            "---- EPOCH 100 EVALUATION ----\n",
            "eval mean loss: 0.386498\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.872308\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 101 ****\n",
            "2018-10-30 21:57:08.339240\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.111640\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.152242\n",
            "accuracy: 0.938750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.165368\n",
            "accuracy: 0.936250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.165830\n",
            "accuracy: 0.940000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.156906\n",
            "accuracy: 0.946250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.137777\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.127585\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.168183\n",
            "accuracy: 0.936250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.142801\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.125614\n",
            "accuracy: 0.955000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.152655\n",
            "accuracy: 0.942500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.156569\n",
            "accuracy: 0.950000\n",
            "2018-10-30 21:59:52.883264\n",
            "---- EPOCH 101 EVALUATION ----\n",
            "eval mean loss: 0.385640\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.870965\n",
            "**** EPOCH 102 ****\n",
            "2018-10-30 22:00:05.233790\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.132399\n",
            "accuracy: 0.951250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.156798\n",
            "accuracy: 0.937500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.175699\n",
            "accuracy: 0.946250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.179953\n",
            "accuracy: 0.946250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.136233\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.147558\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.147291\n",
            "accuracy: 0.952500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.149472\n",
            "accuracy: 0.948750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.161096\n",
            "accuracy: 0.947500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.155067\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.153600\n",
            "accuracy: 0.941250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.155058\n",
            "accuracy: 0.948750\n",
            "2018-10-30 22:02:49.329516\n",
            "---- EPOCH 102 EVALUATION ----\n",
            "eval mean loss: 0.401253\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.873715\n",
            "**** EPOCH 103 ****\n",
            "2018-10-30 22:03:01.627577\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.157540\n",
            "accuracy: 0.945000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.140289\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.126963\n",
            "accuracy: 0.946250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.131544\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.141025\n",
            "accuracy: 0.938750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.139615\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.167269\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.167220\n",
            "accuracy: 0.938750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.147287\n",
            "accuracy: 0.952500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.161197\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.120661\n",
            "accuracy: 0.955000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.154416\n",
            "accuracy: 0.943750\n",
            "2018-10-30 22:05:45.811126\n",
            "---- EPOCH 103 EVALUATION ----\n",
            "eval mean loss: 0.399767\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.877064\n",
            "**** EPOCH 104 ****\n",
            "2018-10-30 22:05:58.145031\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.125279\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.137390\n",
            "accuracy: 0.952500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.162800\n",
            "accuracy: 0.938750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.122049\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.178895\n",
            "accuracy: 0.936250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.166574\n",
            "accuracy: 0.942500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.121353\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.148307\n",
            "accuracy: 0.950000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.143423\n",
            "accuracy: 0.946250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.135869\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.140000\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.158359\n",
            "accuracy: 0.945000\n",
            "2018-10-30 22:08:42.416696\n",
            "---- EPOCH 104 EVALUATION ----\n",
            "eval mean loss: 0.397641\n",
            "eval accuracy: 0.888979\n",
            "eval avg class acc: 0.862733\n",
            "**** EPOCH 105 ****\n",
            "2018-10-30 22:08:54.734838\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.132162\n",
            "accuracy: 0.953750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.140712\n",
            "accuracy: 0.948750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.126312\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.132652\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.135868\n",
            "accuracy: 0.955000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.153348\n",
            "accuracy: 0.942500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.138935\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.176515\n",
            "accuracy: 0.935000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.112942\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.165671\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.131116\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.159086\n",
            "accuracy: 0.940000\n",
            "2018-10-30 22:11:39.080839\n",
            "---- EPOCH 105 EVALUATION ----\n",
            "eval mean loss: 0.399250\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.870552\n",
            "**** EPOCH 106 ****\n",
            "2018-10-30 22:11:51.399062\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.129128\n",
            "accuracy: 0.951250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.157097\n",
            "accuracy: 0.945000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.140120\n",
            "accuracy: 0.956250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.135402\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.144313\n",
            "accuracy: 0.948750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.196776\n",
            "accuracy: 0.930000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.157662\n",
            "accuracy: 0.945000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.148719\n",
            "accuracy: 0.942500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.131543\n",
            "accuracy: 0.948750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.131123\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.155638\n",
            "accuracy: 0.942500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.121274\n",
            "accuracy: 0.958750\n",
            "2018-10-30 22:14:35.610320\n",
            "---- EPOCH 106 EVALUATION ----\n",
            "eval mean loss: 0.411056\n",
            "eval accuracy: 0.886143\n",
            "eval avg class acc: 0.864023\n",
            "**** EPOCH 107 ****\n",
            "2018-10-30 22:14:47.912435\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.168652\n",
            "accuracy: 0.941250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.150116\n",
            "accuracy: 0.950000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.139911\n",
            "accuracy: 0.942500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.115740\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.143401\n",
            "accuracy: 0.957500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.124337\n",
            "accuracy: 0.952500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.166160\n",
            "accuracy: 0.941250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.146175\n",
            "accuracy: 0.940000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.144994\n",
            "accuracy: 0.952500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.140981\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.140177\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.130029\n",
            "accuracy: 0.956250\n",
            "2018-10-30 22:17:32.035023\n",
            "---- EPOCH 107 EVALUATION ----\n",
            "eval mean loss: 0.391421\n",
            "eval accuracy: 0.890600\n",
            "eval avg class acc: 0.867977\n",
            "**** EPOCH 108 ****\n",
            "2018-10-30 22:17:44.375530\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.112597\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113558\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.139493\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.126260\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.119964\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.124938\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.156638\n",
            "accuracy: 0.942500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.138536\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.132683\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.110849\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.133099\n",
            "accuracy: 0.957500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.119466\n",
            "accuracy: 0.953750\n",
            "2018-10-30 22:20:28.628857\n",
            "---- EPOCH 108 EVALUATION ----\n",
            "eval mean loss: 0.404656\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.870634\n",
            "**** EPOCH 109 ****\n",
            "2018-10-30 22:20:40.977345\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.118267\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.100585\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.163427\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.134372\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.133660\n",
            "accuracy: 0.943750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.170911\n",
            "accuracy: 0.943750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.118103\n",
            "accuracy: 0.956250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.146825\n",
            "accuracy: 0.946250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.137821\n",
            "accuracy: 0.938750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.135976\n",
            "accuracy: 0.952500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.144933\n",
            "accuracy: 0.938750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.125535\n",
            "accuracy: 0.953750\n",
            "2018-10-30 22:23:25.097624\n",
            "---- EPOCH 109 EVALUATION ----\n",
            "eval mean loss: 0.404904\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.865645\n",
            "**** EPOCH 110 ****\n",
            "2018-10-30 22:23:37.443306\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.149409\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.107340\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.152180\n",
            "accuracy: 0.946250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.149102\n",
            "accuracy: 0.946250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.152644\n",
            "accuracy: 0.946250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.138497\n",
            "accuracy: 0.946250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.150479\n",
            "accuracy: 0.953750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.152673\n",
            "accuracy: 0.945000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119115\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.170422\n",
            "accuracy: 0.943750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.134551\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.138955\n",
            "accuracy: 0.957500\n",
            "2018-10-30 22:26:21.577559\n",
            "---- EPOCH 110 EVALUATION ----\n",
            "eval mean loss: 0.403218\n",
            "eval accuracy: 0.891410\n",
            "eval avg class acc: 0.870436\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 111 ****\n",
            "2018-10-30 22:26:34.400898\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.133648\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.153631\n",
            "accuracy: 0.951250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.131888\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.148394\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.103208\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.132989\n",
            "accuracy: 0.952500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.149343\n",
            "accuracy: 0.945000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.158545\n",
            "accuracy: 0.936250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.154862\n",
            "accuracy: 0.945000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.130675\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.156421\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.143266\n",
            "accuracy: 0.951250\n",
            "2018-10-30 22:29:18.628197\n",
            "---- EPOCH 111 EVALUATION ----\n",
            "eval mean loss: 0.402546\n",
            "eval accuracy: 0.893031\n",
            "eval avg class acc: 0.862477\n",
            "**** EPOCH 112 ****\n",
            "2018-10-30 22:29:30.940456\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.140310\n",
            "accuracy: 0.948750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.160691\n",
            "accuracy: 0.947500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.130389\n",
            "accuracy: 0.956250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.125905\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.138948\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.145467\n",
            "accuracy: 0.953750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.143701\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.154822\n",
            "accuracy: 0.952500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.122292\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.173896\n",
            "accuracy: 0.940000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.100461\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.147859\n",
            "accuracy: 0.952500\n",
            "2018-10-30 22:32:15.022908\n",
            "---- EPOCH 112 EVALUATION ----\n",
            "eval mean loss: 0.414179\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.866523\n",
            "**** EPOCH 113 ****\n",
            "2018-10-30 22:32:27.356923\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.109595\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.144472\n",
            "accuracy: 0.947500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.143424\n",
            "accuracy: 0.945000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.164590\n",
            "accuracy: 0.937500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.089658\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.137826\n",
            "accuracy: 0.945000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.164406\n",
            "accuracy: 0.943750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.125638\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.116200\n",
            "accuracy: 0.952500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.160574\n",
            "accuracy: 0.931250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.125725\n",
            "accuracy: 0.951250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.159331\n",
            "accuracy: 0.937500\n",
            "2018-10-30 22:35:11.527172\n",
            "---- EPOCH 113 EVALUATION ----\n",
            "eval mean loss: 0.407277\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.877221\n",
            "**** EPOCH 114 ****\n",
            "2018-10-30 22:35:23.881951\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.123414\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.148578\n",
            "accuracy: 0.948750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.138254\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.137687\n",
            "accuracy: 0.945000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.139489\n",
            "accuracy: 0.948750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.111967\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.126007\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.117575\n",
            "accuracy: 0.948750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.146832\n",
            "accuracy: 0.948750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.139728\n",
            "accuracy: 0.947500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.152959\n",
            "accuracy: 0.948750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.131915\n",
            "accuracy: 0.958750\n",
            "2018-10-30 22:38:08.095085\n",
            "---- EPOCH 114 EVALUATION ----\n",
            "eval mean loss: 0.397818\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.876529\n",
            "**** EPOCH 115 ****\n",
            "2018-10-30 22:38:20.392629\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.133306\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.111355\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.151501\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.117058\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.152763\n",
            "accuracy: 0.940000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.143378\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.130791\n",
            "accuracy: 0.948750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.131176\n",
            "accuracy: 0.956250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.120539\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.142621\n",
            "accuracy: 0.950000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.135329\n",
            "accuracy: 0.947500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.110109\n",
            "accuracy: 0.958750\n",
            "2018-10-30 22:41:04.532207\n",
            "---- EPOCH 115 EVALUATION ----\n",
            "eval mean loss: 0.394252\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.872180\n",
            "**** EPOCH 116 ****\n",
            "2018-10-30 22:41:16.889627\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.149694\n",
            "accuracy: 0.951250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.194233\n",
            "accuracy: 0.943750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.094922\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.149113\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.131677\n",
            "accuracy: 0.951250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.147092\n",
            "accuracy: 0.943750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.141521\n",
            "accuracy: 0.956250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.128004\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.147899\n",
            "accuracy: 0.956250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.121109\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.126661\n",
            "accuracy: 0.957500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.150941\n",
            "accuracy: 0.948750\n",
            "2018-10-30 22:44:01.219740\n",
            "---- EPOCH 116 EVALUATION ----\n",
            "eval mean loss: 0.396053\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.876558\n",
            "**** EPOCH 117 ****\n",
            "2018-10-30 22:44:13.600562\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.146056\n",
            "accuracy: 0.937500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.122960\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.128566\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.131490\n",
            "accuracy: 0.952500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.154830\n",
            "accuracy: 0.950000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.111420\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.133473\n",
            "accuracy: 0.953750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.108223\n",
            "accuracy: 0.956250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.134868\n",
            "accuracy: 0.943750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.129464\n",
            "accuracy: 0.947500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.142776\n",
            "accuracy: 0.948750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.145591\n",
            "accuracy: 0.946250\n",
            "2018-10-30 22:46:57.871570\n",
            "---- EPOCH 117 EVALUATION ----\n",
            "eval mean loss: 0.410317\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.865180\n",
            "**** EPOCH 118 ****\n",
            "2018-10-30 22:47:10.181334\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.109431\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.137742\n",
            "accuracy: 0.943750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.113490\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104962\n",
            "accuracy: 0.962500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.155171\n",
            "accuracy: 0.942500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.142735\n",
            "accuracy: 0.953750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.107736\n",
            "accuracy: 0.962500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.118826\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119203\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.123525\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.166409\n",
            "accuracy: 0.946250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.110290\n",
            "accuracy: 0.962500\n",
            "2018-10-30 22:49:54.497319\n",
            "---- EPOCH 118 EVALUATION ----\n",
            "eval mean loss: 0.414652\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.866477\n",
            "**** EPOCH 119 ****\n",
            "2018-10-30 22:50:06.917070\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.121004\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.136804\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.127832\n",
            "accuracy: 0.951250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.136281\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.132901\n",
            "accuracy: 0.953750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.143025\n",
            "accuracy: 0.947500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.136067\n",
            "accuracy: 0.953750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.161470\n",
            "accuracy: 0.940000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.118312\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.126935\n",
            "accuracy: 0.947500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.135849\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.131963\n",
            "accuracy: 0.943750\n",
            "2018-10-30 22:52:51.189698\n",
            "---- EPOCH 119 EVALUATION ----\n",
            "eval mean loss: 0.410715\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.869012\n",
            "**** EPOCH 120 ****\n",
            "2018-10-30 22:53:03.546618\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.121288\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.125097\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.149115\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.120941\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.131311\n",
            "accuracy: 0.952500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.075354\n",
            "accuracy: 0.975000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.148651\n",
            "accuracy: 0.940000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.184825\n",
            "accuracy: 0.940000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119857\n",
            "accuracy: 0.953750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.158029\n",
            "accuracy: 0.942500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.120077\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.140223\n",
            "accuracy: 0.946250\n",
            "2018-10-30 22:55:47.842224\n",
            "---- EPOCH 120 EVALUATION ----\n",
            "eval mean loss: 0.396967\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.871599\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 121 ****\n",
            "2018-10-30 22:56:00.668164\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.119352\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.129328\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.132285\n",
            "accuracy: 0.948750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.138621\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.123625\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.168266\n",
            "accuracy: 0.945000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.121040\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.118586\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.156977\n",
            "accuracy: 0.950000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.116785\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.131422\n",
            "accuracy: 0.945000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.144517\n",
            "accuracy: 0.943750\n",
            "2018-10-30 22:58:44.889007\n",
            "---- EPOCH 121 EVALUATION ----\n",
            "eval mean loss: 0.402392\n",
            "eval accuracy: 0.899514\n",
            "eval avg class acc: 0.871052\n",
            "**** EPOCH 122 ****\n",
            "2018-10-30 22:58:57.219107\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.127030\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.122406\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.115818\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.142621\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.137360\n",
            "accuracy: 0.955000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.124694\n",
            "accuracy: 0.950000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.107395\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.128283\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.139376\n",
            "accuracy: 0.943750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.115089\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.114271\n",
            "accuracy: 0.955000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.130891\n",
            "accuracy: 0.952500\n",
            "2018-10-30 23:01:41.583955\n",
            "---- EPOCH 122 EVALUATION ----\n",
            "eval mean loss: 0.399609\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.878517\n",
            "**** EPOCH 123 ****\n",
            "2018-10-30 23:01:53.910277\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.122799\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113257\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.123733\n",
            "accuracy: 0.957500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.133092\n",
            "accuracy: 0.943750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.131850\n",
            "accuracy: 0.955000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.128402\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.098438\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.100756\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.132715\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108821\n",
            "accuracy: 0.957500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.116391\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.103535\n",
            "accuracy: 0.962500\n",
            "2018-10-30 23:04:38.143305\n",
            "---- EPOCH 123 EVALUATION ----\n",
            "eval mean loss: 0.399761\n",
            "eval accuracy: 0.902755\n",
            "eval avg class acc: 0.877884\n",
            "**** EPOCH 124 ****\n",
            "2018-10-30 23:04:50.490479\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.146115\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.147975\n",
            "accuracy: 0.950000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.121551\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.135525\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.134529\n",
            "accuracy: 0.952500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.135353\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.135188\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.127156\n",
            "accuracy: 0.948750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.139130\n",
            "accuracy: 0.953750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108702\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.129428\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.115784\n",
            "accuracy: 0.952500\n",
            "2018-10-30 23:07:34.765274\n",
            "---- EPOCH 124 EVALUATION ----\n",
            "eval mean loss: 0.404082\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.873599\n",
            "**** EPOCH 125 ****\n",
            "2018-10-30 23:07:47.116911\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.109543\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.107554\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.112916\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.121762\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.121385\n",
            "accuracy: 0.946250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.108752\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.142853\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.117848\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.117026\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.102868\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.139738\n",
            "accuracy: 0.943750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.133366\n",
            "accuracy: 0.950000\n",
            "2018-10-30 23:10:31.326192\n",
            "---- EPOCH 125 EVALUATION ----\n",
            "eval mean loss: 0.406207\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.871465\n",
            "**** EPOCH 126 ****\n",
            "2018-10-30 23:10:43.663527\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.103889\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.108012\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.148374\n",
            "accuracy: 0.947500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082908\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.122181\n",
            "accuracy: 0.952500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.108079\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.137146\n",
            "accuracy: 0.951250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.125603\n",
            "accuracy: 0.951250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.129697\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108773\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095301\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.149071\n",
            "accuracy: 0.952500\n",
            "2018-10-30 23:13:27.734402\n",
            "---- EPOCH 126 EVALUATION ----\n",
            "eval mean loss: 0.402150\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873767\n",
            "**** EPOCH 127 ****\n",
            "2018-10-30 23:13:40.081282\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.123548\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.111904\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.111651\n",
            "accuracy: 0.960000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.121129\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.128728\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.140718\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.137787\n",
            "accuracy: 0.956250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.120478\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.113057\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.113603\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.147842\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.131717\n",
            "accuracy: 0.950000\n",
            "2018-10-30 23:16:24.306127\n",
            "---- EPOCH 127 EVALUATION ----\n",
            "eval mean loss: 0.403301\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.871017\n",
            "**** EPOCH 128 ****\n",
            "2018-10-30 23:16:36.654567\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.125172\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.126329\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.107967\n",
            "accuracy: 0.953750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.117296\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.130255\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.108676\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.090441\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.134080\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.094887\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.140831\n",
            "accuracy: 0.948750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.148585\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.105321\n",
            "accuracy: 0.958750\n",
            "2018-10-30 23:19:20.834873\n",
            "---- EPOCH 128 EVALUATION ----\n",
            "eval mean loss: 0.391853\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.872895\n",
            "**** EPOCH 129 ****\n",
            "2018-10-30 23:19:33.171620\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.118939\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.114057\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.129202\n",
            "accuracy: 0.956250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.118248\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.147555\n",
            "accuracy: 0.945000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.098301\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.108239\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.138794\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.123854\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.110863\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.130757\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.136067\n",
            "accuracy: 0.963750\n",
            "2018-10-30 23:22:17.324699\n",
            "---- EPOCH 129 EVALUATION ----\n",
            "eval mean loss: 0.403601\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.871017\n",
            "**** EPOCH 130 ****\n",
            "2018-10-30 23:22:29.614559\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099871\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.146308\n",
            "accuracy: 0.945000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.127417\n",
            "accuracy: 0.952500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.092234\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.126109\n",
            "accuracy: 0.943750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.176249\n",
            "accuracy: 0.935000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.094236\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.137706\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.113195\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.122223\n",
            "accuracy: 0.957500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.132587\n",
            "accuracy: 0.955000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.091817\n",
            "accuracy: 0.965000\n",
            "2018-10-30 23:25:13.615738\n",
            "---- EPOCH 130 EVALUATION ----\n",
            "eval mean loss: 0.395293\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.865442\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 131 ****\n",
            "2018-10-30 23:25:26.381232\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.123994\n",
            "accuracy: 0.955000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.107520\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.109848\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099531\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.122507\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.103993\n",
            "accuracy: 0.957500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.114345\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.115059\n",
            "accuracy: 0.952500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.125373\n",
            "accuracy: 0.956250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.116636\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.101648\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098061\n",
            "accuracy: 0.963750\n",
            "2018-10-30 23:28:10.602940\n",
            "---- EPOCH 131 EVALUATION ----\n",
            "eval mean loss: 0.398116\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.872971\n",
            "**** EPOCH 132 ****\n",
            "2018-10-30 23:28:22.910610\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.135634\n",
            "accuracy: 0.942500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.109585\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.118188\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.089664\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.102685\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.109609\n",
            "accuracy: 0.953750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.108917\n",
            "accuracy: 0.962500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.108765\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.110186\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.082911\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091580\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.138732\n",
            "accuracy: 0.953750\n",
            "2018-10-30 23:31:07.229561\n",
            "---- EPOCH 132 EVALUATION ----\n",
            "eval mean loss: 0.405193\n",
            "eval accuracy: 0.889789\n",
            "eval avg class acc: 0.864988\n",
            "**** EPOCH 133 ****\n",
            "2018-10-30 23:31:19.548865\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099094\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.091826\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.129811\n",
            "accuracy: 0.948750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.135770\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.122397\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.109292\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.136267\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.122663\n",
            "accuracy: 0.952500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.151363\n",
            "accuracy: 0.950000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.107756\n",
            "accuracy: 0.952500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.109723\n",
            "accuracy: 0.957500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.114974\n",
            "accuracy: 0.957500\n",
            "2018-10-30 23:34:03.796805\n",
            "---- EPOCH 133 EVALUATION ----\n",
            "eval mean loss: 0.403229\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.869930\n",
            "**** EPOCH 134 ****\n",
            "2018-10-30 23:34:16.139005\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.131241\n",
            "accuracy: 0.945000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113663\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.098471\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.108212\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.103307\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.087094\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.144341\n",
            "accuracy: 0.946250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.131247\n",
            "accuracy: 0.950000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.108769\n",
            "accuracy: 0.953750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.113633\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.107938\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.126004\n",
            "accuracy: 0.955000\n",
            "2018-10-30 23:37:00.464503\n",
            "---- EPOCH 134 EVALUATION ----\n",
            "eval mean loss: 0.406595\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.873930\n",
            "**** EPOCH 135 ****\n",
            "2018-10-30 23:37:12.802813\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.108827\n",
            "accuracy: 0.951250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.127627\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.105636\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.109367\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.130734\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.112105\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.092759\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.103269\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119110\n",
            "accuracy: 0.958750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.124235\n",
            "accuracy: 0.947500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.110786\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.118859\n",
            "accuracy: 0.951250\n",
            "2018-10-30 23:39:56.888564\n",
            "---- EPOCH 135 EVALUATION ----\n",
            "eval mean loss: 0.427546\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.867058\n",
            "**** EPOCH 136 ****\n",
            "2018-10-30 23:40:09.226812\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.106488\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.112471\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.154560\n",
            "accuracy: 0.943750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.109185\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.090161\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.151944\n",
            "accuracy: 0.943750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.122558\n",
            "accuracy: 0.946250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.122352\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.142185\n",
            "accuracy: 0.945000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.098843\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.129732\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100754\n",
            "accuracy: 0.968750\n",
            "2018-10-30 23:42:53.530224\n",
            "---- EPOCH 136 EVALUATION ----\n",
            "eval mean loss: 0.414079\n",
            "eval accuracy: 0.899109\n",
            "eval avg class acc: 0.875430\n",
            "**** EPOCH 137 ****\n",
            "2018-10-30 23:43:05.900187\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.117394\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.106639\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.084842\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.161679\n",
            "accuracy: 0.938750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.169834\n",
            "accuracy: 0.942500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.131258\n",
            "accuracy: 0.955000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.126089\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.108326\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.131048\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.104052\n",
            "accuracy: 0.955000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.101458\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.125313\n",
            "accuracy: 0.957500\n",
            "2018-10-30 23:45:50.176413\n",
            "---- EPOCH 137 EVALUATION ----\n",
            "eval mean loss: 0.420643\n",
            "eval accuracy: 0.892220\n",
            "eval avg class acc: 0.865180\n",
            "**** EPOCH 138 ****\n",
            "2018-10-30 23:46:02.511294\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.097595\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.116711\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.119093\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.097500\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.114840\n",
            "accuracy: 0.957500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.110316\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.133573\n",
            "accuracy: 0.956250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.115264\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.134264\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.135478\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.113755\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.091003\n",
            "accuracy: 0.963750\n",
            "2018-10-30 23:48:46.537449\n",
            "---- EPOCH 138 EVALUATION ----\n",
            "eval mean loss: 0.407793\n",
            "eval accuracy: 0.901945\n",
            "eval avg class acc: 0.877802\n",
            "**** EPOCH 139 ****\n",
            "2018-10-30 23:48:58.842523\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.093115\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.120508\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.119058\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.117656\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.169324\n",
            "accuracy: 0.945000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093906\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091003\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.124308\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.139908\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.147522\n",
            "accuracy: 0.946250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.125485\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100314\n",
            "accuracy: 0.960000\n",
            "2018-10-30 23:51:42.751984\n",
            "---- EPOCH 139 EVALUATION ----\n",
            "eval mean loss: 0.416199\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.874599\n",
            "**** EPOCH 140 ****\n",
            "2018-10-30 23:51:55.120080\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.108772\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.102923\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095134\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.119169\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.111143\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.098634\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.124894\n",
            "accuracy: 0.962500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.110771\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.127848\n",
            "accuracy: 0.947500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108809\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.132540\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.109216\n",
            "accuracy: 0.960000\n",
            "2018-10-30 23:54:39.202728\n",
            "---- EPOCH 140 EVALUATION ----\n",
            "eval mean loss: 0.412410\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.876930\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 141 ****\n",
            "2018-10-30 23:54:51.958274\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.105615\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.097932\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.108494\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.110647\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.104746\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.088023\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.127610\n",
            "accuracy: 0.948750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.113957\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.115437\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108041\n",
            "accuracy: 0.948750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097680\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.096006\n",
            "accuracy: 0.968750\n",
            "2018-10-30 23:57:36.096799\n",
            "---- EPOCH 141 EVALUATION ----\n",
            "eval mean loss: 0.414434\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.875145\n",
            "**** EPOCH 142 ****\n",
            "2018-10-30 23:57:48.482828\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.096575\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.105817\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.105836\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.087700\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.092477\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099731\n",
            "accuracy: 0.966250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.082326\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.100168\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.115276\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.086821\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.099733\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.136903\n",
            "accuracy: 0.950000\n",
            "2018-10-31 00:00:32.676181\n",
            "---- EPOCH 142 EVALUATION ----\n",
            "eval mean loss: 0.423264\n",
            "eval accuracy: 0.897893\n",
            "eval avg class acc: 0.869924\n",
            "**** EPOCH 143 ****\n",
            "2018-10-31 00:00:44.995396\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.117841\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.116640\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.089338\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.076499\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.114578\n",
            "accuracy: 0.958750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.118505\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.106495\n",
            "accuracy: 0.962500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.119080\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.079752\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.108923\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.133559\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.107309\n",
            "accuracy: 0.957500\n",
            "2018-10-31 00:03:29.153764\n",
            "---- EPOCH 143 EVALUATION ----\n",
            "eval mean loss: 0.431660\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.876890\n",
            "**** EPOCH 144 ****\n",
            "2018-10-31 00:03:41.475545\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.112032\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.099740\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102235\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.115731\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.119784\n",
            "accuracy: 0.957500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.124324\n",
            "accuracy: 0.956250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.089811\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.116886\n",
            "accuracy: 0.958750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.121642\n",
            "accuracy: 0.956250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.077993\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.132484\n",
            "accuracy: 0.940000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.092660\n",
            "accuracy: 0.971250\n",
            "2018-10-31 00:06:25.481840\n",
            "---- EPOCH 144 EVALUATION ----\n",
            "eval mean loss: 0.417635\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.872605\n",
            "**** EPOCH 145 ****\n",
            "2018-10-31 00:06:37.847702\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.111743\n",
            "accuracy: 0.956250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113034\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.119944\n",
            "accuracy: 0.957500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082646\n",
            "accuracy: 0.980000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.105020\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.130640\n",
            "accuracy: 0.950000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.107385\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.101936\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.117479\n",
            "accuracy: 0.951250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.090968\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.117225\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.116038\n",
            "accuracy: 0.946250\n",
            "2018-10-31 00:09:21.605406\n",
            "---- EPOCH 145 EVALUATION ----\n",
            "eval mean loss: 0.416996\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.880430\n",
            "**** EPOCH 146 ****\n",
            "2018-10-31 00:09:33.851250\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.084986\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074346\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.111363\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.127601\n",
            "accuracy: 0.953750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.081403\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.101147\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.123422\n",
            "accuracy: 0.950000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.113854\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.100375\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.115177\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.130585\n",
            "accuracy: 0.952500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.111528\n",
            "accuracy: 0.960000\n",
            "2018-10-31 00:12:17.576821\n",
            "---- EPOCH 146 EVALUATION ----\n",
            "eval mean loss: 0.414349\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.875890\n",
            "**** EPOCH 147 ****\n",
            "2018-10-31 00:12:29.858984\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.107370\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.117074\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.090003\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.124769\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.096164\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.120691\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.102038\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.066317\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.096240\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.088944\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.115348\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.105020\n",
            "accuracy: 0.961250\n",
            "2018-10-31 00:15:13.464875\n",
            "---- EPOCH 147 EVALUATION ----\n",
            "eval mean loss: 0.426392\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.870599\n",
            "**** EPOCH 148 ****\n",
            "2018-10-31 00:15:25.815235\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.115327\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.085520\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092062\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.121165\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.091692\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099057\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091230\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.080460\n",
            "accuracy: 0.973750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.114804\n",
            "accuracy: 0.956250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084287\n",
            "accuracy: 0.975000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.114719\n",
            "accuracy: 0.953750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.099621\n",
            "accuracy: 0.958750\n",
            "2018-10-31 00:18:09.365036\n",
            "---- EPOCH 148 EVALUATION ----\n",
            "eval mean loss: 0.421092\n",
            "eval accuracy: 0.893031\n",
            "eval avg class acc: 0.867267\n",
            "**** EPOCH 149 ****\n",
            "2018-10-31 00:18:21.659147\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.089981\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.117128\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.116192\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099699\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.109198\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.122964\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.102302\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.094520\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.088425\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.126549\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.111095\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.096561\n",
            "accuracy: 0.967500\n",
            "2018-10-31 00:21:05.348172\n",
            "---- EPOCH 149 EVALUATION ----\n",
            "eval mean loss: 0.408371\n",
            "eval accuracy: 0.898298\n",
            "eval avg class acc: 0.874099\n",
            "**** EPOCH 150 ****\n",
            "2018-10-31 00:21:17.674863\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.107874\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.109261\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099209\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086705\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.104200\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.108122\n",
            "accuracy: 0.955000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.113606\n",
            "accuracy: 0.955000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.126964\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.065155\n",
            "accuracy: 0.977500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.106530\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.119750\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.114905\n",
            "accuracy: 0.958750\n",
            "2018-10-31 00:24:01.698674\n",
            "---- EPOCH 150 EVALUATION ----\n",
            "eval mean loss: 0.419187\n",
            "eval accuracy: 0.898298\n",
            "eval avg class acc: 0.870221\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 151 ****\n",
            "2018-10-31 00:24:14.509540\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099991\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.113005\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.082377\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.115842\n",
            "accuracy: 0.956250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.103592\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.105538\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083240\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.096084\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.090149\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.130088\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097482\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.123032\n",
            "accuracy: 0.957500\n",
            "2018-10-31 00:26:58.630028\n",
            "---- EPOCH 151 EVALUATION ----\n",
            "eval mean loss: 0.418951\n",
            "eval accuracy: 0.897488\n",
            "eval avg class acc: 0.873517\n",
            "**** EPOCH 152 ****\n",
            "2018-10-31 00:27:10.937915\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.146905\n",
            "accuracy: 0.952500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.096304\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.078729\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.093789\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.102149\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.094937\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.069743\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.115582\n",
            "accuracy: 0.953750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.091505\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.082989\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.078427\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.086710\n",
            "accuracy: 0.966250\n",
            "2018-10-31 00:29:55.120293\n",
            "---- EPOCH 152 EVALUATION ----\n",
            "eval mean loss: 0.434241\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 153 ****\n",
            "2018-10-31 00:30:07.452757\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.108472\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.111982\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.096603\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.095333\n",
            "accuracy: 0.962500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.093049\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.125518\n",
            "accuracy: 0.955000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.110893\n",
            "accuracy: 0.951250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.113934\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.077399\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084438\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.102551\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098566\n",
            "accuracy: 0.970000\n",
            "2018-10-31 00:32:51.656761\n",
            "---- EPOCH 153 EVALUATION ----\n",
            "eval mean loss: 0.433903\n",
            "eval accuracy: 0.893031\n",
            "eval avg class acc: 0.870012\n",
            "**** EPOCH 154 ****\n",
            "2018-10-31 00:33:03.995936\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.115389\n",
            "accuracy: 0.955000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.109532\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.111756\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.117795\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.100919\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.085291\n",
            "accuracy: 0.973750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.104164\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.087295\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.120521\n",
            "accuracy: 0.952500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.087315\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.126157\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.106676\n",
            "accuracy: 0.960000\n",
            "2018-10-31 00:35:48.010327\n",
            "---- EPOCH 154 EVALUATION ----\n",
            "eval mean loss: 0.431420\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.870145\n",
            "**** EPOCH 155 ****\n",
            "2018-10-31 00:36:00.304215\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.112497\n",
            "accuracy: 0.946250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.098432\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.086027\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.109349\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.111780\n",
            "accuracy: 0.958750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.092308\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083783\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.110697\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.089873\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.090342\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.104559\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.076513\n",
            "accuracy: 0.973750\n",
            "2018-10-31 00:38:44.452449\n",
            "---- EPOCH 155 EVALUATION ----\n",
            "eval mean loss: 0.437313\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.866727\n",
            "**** EPOCH 156 ****\n",
            "2018-10-31 00:38:56.762497\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.111925\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.072323\n",
            "accuracy: 0.977500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102048\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.089228\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.104679\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.103625\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.090582\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.076227\n",
            "accuracy: 0.973750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.087161\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.122924\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.106346\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.085878\n",
            "accuracy: 0.971250\n",
            "2018-10-31 00:41:40.932783\n",
            "---- EPOCH 156 EVALUATION ----\n",
            "eval mean loss: 0.439637\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.864808\n",
            "**** EPOCH 157 ****\n",
            "2018-10-31 00:41:53.276293\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.078652\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.108494\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.104098\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.071330\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.118778\n",
            "accuracy: 0.947500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078135\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083017\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.105301\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.139908\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.090655\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097076\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.134928\n",
            "accuracy: 0.961250\n",
            "2018-10-31 00:44:37.791927\n",
            "---- EPOCH 157 EVALUATION ----\n",
            "eval mean loss: 0.444792\n",
            "eval accuracy: 0.888979\n",
            "eval avg class acc: 0.865145\n",
            "**** EPOCH 158 ****\n",
            "2018-10-31 00:44:50.097398\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.086309\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.110059\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.100086\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.127547\n",
            "accuracy: 0.948750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.086464\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093432\n",
            "accuracy: 0.962500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.132132\n",
            "accuracy: 0.948750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.095671\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119773\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.095715\n",
            "accuracy: 0.971250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.079901\n",
            "accuracy: 0.973750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.106341\n",
            "accuracy: 0.963750\n",
            "2018-10-31 00:47:34.278668\n",
            "---- EPOCH 158 EVALUATION ----\n",
            "eval mean loss: 0.434566\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.873145\n",
            "**** EPOCH 159 ****\n",
            "2018-10-31 00:47:46.661770\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.112124\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.096748\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095116\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.091200\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.112551\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.087627\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.132544\n",
            "accuracy: 0.951250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.102362\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.112234\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.075707\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.089143\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.090895\n",
            "accuracy: 0.976250\n",
            "2018-10-31 00:50:30.898923\n",
            "---- EPOCH 159 EVALUATION ----\n",
            "eval mean loss: 0.431335\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.875267\n",
            "**** EPOCH 160 ****\n",
            "2018-10-31 00:50:43.286200\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.103523\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.107382\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.108324\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.095503\n",
            "accuracy: 0.956250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.121601\n",
            "accuracy: 0.952500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.101939\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.105740\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.104421\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.133174\n",
            "accuracy: 0.958750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.141983\n",
            "accuracy: 0.958750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091260\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100698\n",
            "accuracy: 0.966250\n",
            "2018-10-31 00:53:27.731928\n",
            "---- EPOCH 160 EVALUATION ----\n",
            "eval mean loss: 0.433343\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.870308\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 161 ****\n",
            "2018-10-31 00:53:40.549981\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.103943\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.071431\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095661\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.106623\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.118519\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.084874\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.112132\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.117904\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086010\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.091104\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.122266\n",
            "accuracy: 0.956250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.111209\n",
            "accuracy: 0.955000\n",
            "2018-10-31 00:56:24.870395\n",
            "---- EPOCH 161 EVALUATION ----\n",
            "eval mean loss: 0.438775\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.868599\n",
            "**** EPOCH 162 ****\n",
            "2018-10-31 00:56:37.190593\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.113076\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.091552\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.127835\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.081837\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.103100\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.127471\n",
            "accuracy: 0.957500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088523\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.105747\n",
            "accuracy: 0.955000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.110617\n",
            "accuracy: 0.962500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.110129\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091003\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.127030\n",
            "accuracy: 0.962500\n",
            "2018-10-31 00:59:21.568574\n",
            "---- EPOCH 162 EVALUATION ----\n",
            "eval mean loss: 0.435265\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.873721\n",
            "**** EPOCH 163 ****\n",
            "2018-10-31 00:59:33.869601\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.100647\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.081087\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.119312\n",
            "accuracy: 0.955000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.123464\n",
            "accuracy: 0.952500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.100729\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.121494\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.114553\n",
            "accuracy: 0.951250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.102690\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.082424\n",
            "accuracy: 0.976250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.119669\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095101\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100215\n",
            "accuracy: 0.960000\n",
            "2018-10-31 01:02:18.263629\n",
            "---- EPOCH 163 EVALUATION ----\n",
            "eval mean loss: 0.429595\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 164 ****\n",
            "2018-10-31 01:02:30.608745\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.081034\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.094012\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092721\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.085313\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.109065\n",
            "accuracy: 0.956250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099902\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086494\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.091860\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.093969\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.111459\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.080535\n",
            "accuracy: 0.976250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.101146\n",
            "accuracy: 0.963750\n",
            "2018-10-31 01:05:15.158192\n",
            "---- EPOCH 164 EVALUATION ----\n",
            "eval mean loss: 0.434266\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.870105\n",
            "**** EPOCH 165 ****\n",
            "2018-10-31 01:05:27.470977\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.092617\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074804\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.106537\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.098098\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.098804\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.120716\n",
            "accuracy: 0.950000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.094004\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.077040\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.098757\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.122896\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.086332\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.090569\n",
            "accuracy: 0.970000\n",
            "2018-10-31 01:08:11.750334\n",
            "---- EPOCH 165 EVALUATION ----\n",
            "eval mean loss: 0.426799\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.874395\n",
            "**** EPOCH 166 ****\n",
            "2018-10-31 01:08:24.104744\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.096842\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.087166\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099082\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.101109\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.085071\n",
            "accuracy: 0.977500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.094363\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.106858\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.076816\n",
            "accuracy: 0.971250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.098676\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.091803\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.092039\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.104333\n",
            "accuracy: 0.957500\n",
            "2018-10-31 01:11:08.543594\n",
            "---- EPOCH 166 EVALUATION ----\n",
            "eval mean loss: 0.426170\n",
            "eval accuracy: 0.891815\n",
            "eval avg class acc: 0.866936\n",
            "**** EPOCH 167 ****\n",
            "2018-10-31 01:11:20.904748\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.097745\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.077733\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092138\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.111097\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.142853\n",
            "accuracy: 0.947500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.092051\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.113152\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.066641\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.076593\n",
            "accuracy: 0.977500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.066687\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.080782\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.085567\n",
            "accuracy: 0.970000\n",
            "2018-10-31 01:14:05.465394\n",
            "---- EPOCH 167 EVALUATION ----\n",
            "eval mean loss: 0.432835\n",
            "eval accuracy: 0.892626\n",
            "eval avg class acc: 0.868936\n",
            "**** EPOCH 168 ****\n",
            "2018-10-31 01:14:17.814811\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087155\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.094206\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.077680\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.095315\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.094181\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.074083\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.101381\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.106262\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.085268\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.092233\n",
            "accuracy: 0.971250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.105794\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.073590\n",
            "accuracy: 0.971250\n",
            "2018-10-31 01:17:02.339728\n",
            "---- EPOCH 168 EVALUATION ----\n",
            "eval mean loss: 0.430982\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 169 ****\n",
            "2018-10-31 01:17:14.660794\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.084684\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.105270\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.091938\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086294\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.101994\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.104570\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.084142\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.095839\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.089889\n",
            "accuracy: 0.962500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.101889\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.131906\n",
            "accuracy: 0.951250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.087414\n",
            "accuracy: 0.970000\n",
            "2018-10-31 01:19:59.256219\n",
            "---- EPOCH 169 EVALUATION ----\n",
            "eval mean loss: 0.424673\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.875099\n",
            "**** EPOCH 170 ****\n",
            "2018-10-31 01:20:11.621085\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.082675\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.108514\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.089408\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.093332\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.115587\n",
            "accuracy: 0.953750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078626\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.106665\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.098872\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.089929\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.097492\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095862\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.113990\n",
            "accuracy: 0.962500\n",
            "2018-10-31 01:22:55.898840\n",
            "---- EPOCH 170 EVALUATION ----\n",
            "eval mean loss: 0.422949\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.868186\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 171 ****\n",
            "2018-10-31 01:23:08.708282\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.062984\n",
            "accuracy: 0.973750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.115229\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.100960\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082322\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.113589\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.094483\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.105693\n",
            "accuracy: 0.955000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.105114\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.106301\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.121051\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097227\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098986\n",
            "accuracy: 0.971250\n",
            "2018-10-31 01:25:53.272133\n",
            "---- EPOCH 171 EVALUATION ----\n",
            "eval mean loss: 0.427946\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873936\n",
            "**** EPOCH 172 ****\n",
            "2018-10-31 01:26:05.653500\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.072672\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.123563\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092108\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.118920\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.080867\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.088324\n",
            "accuracy: 0.973750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.095009\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.094551\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.084207\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.069294\n",
            "accuracy: 0.981250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095734\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.103318\n",
            "accuracy: 0.975000\n",
            "2018-10-31 01:28:49.862181\n",
            "---- EPOCH 172 EVALUATION ----\n",
            "eval mean loss: 0.428314\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.872517\n",
            "**** EPOCH 173 ****\n",
            "2018-10-31 01:29:02.189140\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.098588\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.098841\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.114529\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.106696\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.087062\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.089350\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088788\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.117112\n",
            "accuracy: 0.958750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.071389\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.098535\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.079102\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.099231\n",
            "accuracy: 0.967500\n",
            "2018-10-31 01:31:46.759430\n",
            "---- EPOCH 173 EVALUATION ----\n",
            "eval mean loss: 0.433414\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873977\n",
            "**** EPOCH 174 ****\n",
            "2018-10-31 01:31:59.140154\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.088659\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.069416\n",
            "accuracy: 0.977500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.087090\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104276\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.123326\n",
            "accuracy: 0.951250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093496\n",
            "accuracy: 0.962500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.092765\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.106358\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.075658\n",
            "accuracy: 0.981250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.101921\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.097129\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.102925\n",
            "accuracy: 0.962500\n",
            "2018-10-31 01:34:43.813810\n",
            "---- EPOCH 174 EVALUATION ----\n",
            "eval mean loss: 0.438267\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.877186\n",
            "**** EPOCH 175 ****\n",
            "2018-10-31 01:34:56.147143\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.088952\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.065507\n",
            "accuracy: 0.978750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.103486\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.083548\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.092522\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.062300\n",
            "accuracy: 0.982500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.098671\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.089204\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.094053\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.080512\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.105504\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.089871\n",
            "accuracy: 0.967500\n",
            "2018-10-31 01:37:41.023599\n",
            "---- EPOCH 175 EVALUATION ----\n",
            "eval mean loss: 0.419688\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.875267\n",
            "**** EPOCH 176 ****\n",
            "2018-10-31 01:37:53.386207\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.107508\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.064274\n",
            "accuracy: 0.981250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.090471\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104381\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.083599\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.101426\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.101972\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.107061\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.073089\n",
            "accuracy: 0.982500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.099462\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.083982\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.096575\n",
            "accuracy: 0.968750\n",
            "2018-10-31 01:40:37.999418\n",
            "---- EPOCH 176 EVALUATION ----\n",
            "eval mean loss: 0.437767\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.872930\n",
            "**** EPOCH 177 ****\n",
            "2018-10-31 01:40:50.351415\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.114530\n",
            "accuracy: 0.955000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.094619\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.082996\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.081650\n",
            "accuracy: 0.978750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.086670\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.129031\n",
            "accuracy: 0.951250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086302\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.109710\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.106199\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.111861\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.076885\n",
            "accuracy: 0.976250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.092578\n",
            "accuracy: 0.968750\n",
            "2018-10-31 01:43:34.845055\n",
            "---- EPOCH 177 EVALUATION ----\n",
            "eval mean loss: 0.428815\n",
            "eval accuracy: 0.899514\n",
            "eval avg class acc: 0.875849\n",
            "**** EPOCH 178 ****\n",
            "2018-10-31 01:43:47.229644\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099288\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.095788\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.101018\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.101994\n",
            "accuracy: 0.962500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.108954\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.086507\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086664\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.107738\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.103436\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.093003\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.103993\n",
            "accuracy: 0.963750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.108247\n",
            "accuracy: 0.962500\n",
            "2018-10-31 01:46:31.765185\n",
            "---- EPOCH 178 EVALUATION ----\n",
            "eval mean loss: 0.429968\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.874936\n",
            "**** EPOCH 179 ****\n",
            "2018-10-31 01:46:44.104090\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085688\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.098152\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.087307\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.080787\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.077586\n",
            "accuracy: 0.973750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.073975\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.121318\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.064240\n",
            "accuracy: 0.980000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.078933\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.076655\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.085866\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100943\n",
            "accuracy: 0.963750\n",
            "2018-10-31 01:49:28.510589\n",
            "---- EPOCH 179 EVALUATION ----\n",
            "eval mean loss: 0.427026\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.870105\n",
            "**** EPOCH 180 ****\n",
            "2018-10-31 01:49:40.928693\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.105597\n",
            "accuracy: 0.958750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.121522\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.105528\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.112548\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.109008\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.092789\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.085579\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.098788\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.083285\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.074230\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082568\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.111462\n",
            "accuracy: 0.957500\n",
            "2018-10-31 01:52:25.399945\n",
            "---- EPOCH 180 EVALUATION ----\n",
            "eval mean loss: 0.432520\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.874180\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 181 ****\n",
            "2018-10-31 01:52:38.209297\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.100119\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.105821\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.078868\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.064305\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071549\n",
            "accuracy: 0.975000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.089688\n",
            "accuracy: 0.966250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.081967\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.104370\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.102157\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.127774\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.081087\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.117216\n",
            "accuracy: 0.955000\n",
            "2018-10-31 01:55:22.685377\n",
            "---- EPOCH 181 EVALUATION ----\n",
            "eval mean loss: 0.425533\n",
            "eval accuracy: 0.899514\n",
            "eval avg class acc: 0.877849\n",
            "**** EPOCH 182 ****\n",
            "2018-10-31 01:55:35.013595\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.116869\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.080408\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092055\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099677\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.083001\n",
            "accuracy: 0.973750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.082296\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.072916\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.109482\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.112543\n",
            "accuracy: 0.961250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.103841\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.086897\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.120534\n",
            "accuracy: 0.961250\n",
            "2018-10-31 01:58:19.414292\n",
            "---- EPOCH 182 EVALUATION ----\n",
            "eval mean loss: 0.441174\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.874227\n",
            "**** EPOCH 183 ****\n",
            "2018-10-31 01:58:31.746465\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.117785\n",
            "accuracy: 0.953750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.072416\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.075218\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.098923\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.101662\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.095816\n",
            "accuracy: 0.966250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.079588\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.096307\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.097586\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.102743\n",
            "accuracy: 0.955000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.108325\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.095085\n",
            "accuracy: 0.963750\n",
            "2018-10-31 02:01:16.245176\n",
            "---- EPOCH 183 EVALUATION ----\n",
            "eval mean loss: 0.434145\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.870977\n",
            "**** EPOCH 184 ****\n",
            "2018-10-31 02:01:28.606723\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.117919\n",
            "accuracy: 0.953750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.090453\n",
            "accuracy: 0.975000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.074192\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.121310\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.067717\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.091193\n",
            "accuracy: 0.961250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.065909\n",
            "accuracy: 0.976250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.092485\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.096208\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084429\n",
            "accuracy: 0.971250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.089987\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.079820\n",
            "accuracy: 0.972500\n",
            "2018-10-31 02:04:13.261063\n",
            "---- EPOCH 184 EVALUATION ----\n",
            "eval mean loss: 0.441469\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.871762\n",
            "**** EPOCH 185 ****\n",
            "2018-10-31 02:04:25.618977\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.079613\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.112983\n",
            "accuracy: 0.956250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.054352\n",
            "accuracy: 0.980000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.085928\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.093490\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.098501\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.075756\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.089209\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.094301\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.113721\n",
            "accuracy: 0.956250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.125678\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.093353\n",
            "accuracy: 0.962500\n",
            "2018-10-31 02:07:10.301402\n",
            "---- EPOCH 185 EVALUATION ----\n",
            "eval mean loss: 0.435458\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.876099\n",
            "**** EPOCH 186 ****\n",
            "2018-10-31 02:07:22.680499\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.106079\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.080278\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.074113\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.108960\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.090036\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.071610\n",
            "accuracy: 0.975000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086681\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.093069\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080981\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.104762\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082778\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098670\n",
            "accuracy: 0.967500\n",
            "2018-10-31 02:10:07.047406\n",
            "---- EPOCH 186 EVALUATION ----\n",
            "eval mean loss: 0.438643\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.875349\n",
            "**** EPOCH 187 ****\n",
            "2018-10-31 02:10:19.454456\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.077420\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.089944\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.094467\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.088597\n",
            "accuracy: 0.975000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.099938\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.085073\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088495\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.075656\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.104335\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.095247\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.087269\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.095630\n",
            "accuracy: 0.966250\n",
            "2018-10-31 02:13:04.145656\n",
            "---- EPOCH 187 EVALUATION ----\n",
            "eval mean loss: 0.434064\n",
            "eval accuracy: 0.898298\n",
            "eval avg class acc: 0.876849\n",
            "**** EPOCH 188 ****\n",
            "2018-10-31 02:13:16.525769\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.076094\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.108512\n",
            "accuracy: 0.958750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.101752\n",
            "accuracy: 0.953750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.084486\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.096970\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.090570\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088029\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.084537\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.082865\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.097519\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.086388\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.099521\n",
            "accuracy: 0.970000\n",
            "2018-10-31 02:16:00.954808\n",
            "---- EPOCH 188 EVALUATION ----\n",
            "eval mean loss: 0.440091\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.876849\n",
            "**** EPOCH 189 ****\n",
            "2018-10-31 02:16:13.286919\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087437\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.069679\n",
            "accuracy: 0.975000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.114000\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.097956\n",
            "accuracy: 0.958750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.112918\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.090333\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.094799\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.076574\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.092378\n",
            "accuracy: 0.962500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.065022\n",
            "accuracy: 0.975000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.079824\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.107079\n",
            "accuracy: 0.961250\n",
            "2018-10-31 02:18:57.828375\n",
            "---- EPOCH 189 EVALUATION ----\n",
            "eval mean loss: 0.446502\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.876308\n",
            "**** EPOCH 190 ****\n",
            "2018-10-31 02:19:10.135116\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.068255\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.085351\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102880\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.087955\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.114321\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.087088\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.115194\n",
            "accuracy: 0.957500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.083426\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.078561\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.086607\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.092381\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.080960\n",
            "accuracy: 0.976250\n",
            "2018-10-31 02:21:54.628439\n",
            "---- EPOCH 190 EVALUATION ----\n",
            "eval mean loss: 0.446390\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.870727\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 191 ****\n",
            "2018-10-31 02:22:07.454525\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.106452\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.092183\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.094612\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099189\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.079093\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.102991\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.060334\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.080010\n",
            "accuracy: 0.977500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.088151\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.076540\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.073250\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098667\n",
            "accuracy: 0.965000\n",
            "2018-10-31 02:24:51.762830\n",
            "---- EPOCH 191 EVALUATION ----\n",
            "eval mean loss: 0.437545\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.875308\n",
            "**** EPOCH 192 ****\n",
            "2018-10-31 02:25:04.131946\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085588\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.075170\n",
            "accuracy: 0.978750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.071053\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.072968\n",
            "accuracy: 0.978750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.081577\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.118033\n",
            "accuracy: 0.957500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.063982\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.067807\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.074158\n",
            "accuracy: 0.975000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.119289\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.090953\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.083422\n",
            "accuracy: 0.977500\n",
            "2018-10-31 02:27:48.814351\n",
            "---- EPOCH 192 EVALUATION ----\n",
            "eval mean loss: 0.434827\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.871477\n",
            "**** EPOCH 193 ****\n",
            "2018-10-31 02:28:01.213117\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.108628\n",
            "accuracy: 0.960000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.090062\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.066194\n",
            "accuracy: 0.976250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.093983\n",
            "accuracy: 0.971250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.102190\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.076411\n",
            "accuracy: 0.971250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.096275\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.064896\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.104427\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.069962\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.087357\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.072657\n",
            "accuracy: 0.963750\n",
            "2018-10-31 02:30:45.969914\n",
            "---- EPOCH 193 EVALUATION ----\n",
            "eval mean loss: 0.439955\n",
            "eval accuracy: 0.898703\n",
            "eval avg class acc: 0.874390\n",
            "**** EPOCH 194 ****\n",
            "2018-10-31 02:30:58.296806\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087620\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.071654\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102913\n",
            "accuracy: 0.950000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.069732\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071458\n",
            "accuracy: 0.975000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.058469\n",
            "accuracy: 0.982500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091203\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.112161\n",
            "accuracy: 0.957500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086562\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.106185\n",
            "accuracy: 0.953750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.081551\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.083668\n",
            "accuracy: 0.968750\n",
            "2018-10-31 02:33:42.755824\n",
            "---- EPOCH 194 EVALUATION ----\n",
            "eval mean loss: 0.449069\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.876477\n",
            "**** EPOCH 195 ****\n",
            "2018-10-31 02:33:55.086981\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.088677\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.094341\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.064886\n",
            "accuracy: 0.975000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.090750\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.073750\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.066302\n",
            "accuracy: 0.981250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.084235\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.096319\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.108931\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.080238\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.072828\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.075104\n",
            "accuracy: 0.973750\n",
            "2018-10-31 02:36:39.291995\n",
            "---- EPOCH 195 EVALUATION ----\n",
            "eval mean loss: 0.441817\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873936\n",
            "**** EPOCH 196 ****\n",
            "2018-10-31 02:36:51.599470\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.086134\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.102068\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095885\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.092578\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.088371\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.060439\n",
            "accuracy: 0.973750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.098282\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.066217\n",
            "accuracy: 0.977500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.075211\n",
            "accuracy: 0.976250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.085643\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095296\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.114622\n",
            "accuracy: 0.955000\n",
            "2018-10-31 02:39:36.130044\n",
            "---- EPOCH 196 EVALUATION ----\n",
            "eval mean loss: 0.446995\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.876099\n",
            "**** EPOCH 197 ****\n",
            "2018-10-31 02:39:48.384026\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.083034\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.072132\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.079119\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.075524\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.066793\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.085359\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.066053\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.084066\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.093553\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.118063\n",
            "accuracy: 0.951250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.077149\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.087282\n",
            "accuracy: 0.965000\n",
            "2018-10-31 02:42:32.778443\n",
            "---- EPOCH 197 EVALUATION ----\n",
            "eval mean loss: 0.444879\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.872186\n",
            "**** EPOCH 198 ****\n",
            "2018-10-31 02:42:45.038443\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.083067\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.082762\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102775\n",
            "accuracy: 0.960000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086706\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.081916\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078294\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083581\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.085009\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.090415\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.092479\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.088611\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.098911\n",
            "accuracy: 0.965000\n",
            "2018-10-31 02:45:29.585633\n",
            "---- EPOCH 198 EVALUATION ----\n",
            "eval mean loss: 0.444215\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.872890\n",
            "**** EPOCH 199 ****\n",
            "2018-10-31 02:45:41.793371\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.093351\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.102771\n",
            "accuracy: 0.952500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.071366\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.087117\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.091307\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.072735\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.089474\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.073618\n",
            "accuracy: 0.977500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.100121\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.071542\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091748\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.101579\n",
            "accuracy: 0.961250\n",
            "2018-10-31 02:48:25.958987\n",
            "---- EPOCH 199 EVALUATION ----\n",
            "eval mean loss: 0.449449\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.873186\n",
            "**** EPOCH 200 ****\n",
            "2018-10-31 02:48:38.161533\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.091433\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.083940\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.101697\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082929\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.110864\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.072382\n",
            "accuracy: 0.975000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.095418\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.086216\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.063426\n",
            "accuracy: 0.975000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084110\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.088137\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.076845\n",
            "accuracy: 0.972500\n",
            "2018-10-31 02:51:21.952730\n",
            "---- EPOCH 200 EVALUATION ----\n",
            "eval mean loss: 0.439064\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.875395\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 201 ****\n",
            "2018-10-31 02:51:34.604003\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.075665\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.081560\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.073031\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.071350\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.101178\n",
            "accuracy: 0.963750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078245\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.077617\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.080913\n",
            "accuracy: 0.971250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.093860\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.078705\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.094025\n",
            "accuracy: 0.958750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.069860\n",
            "accuracy: 0.977500\n",
            "2018-10-31 02:54:18.237448\n",
            "---- EPOCH 201 EVALUATION ----\n",
            "eval mean loss: 0.437833\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.872558\n",
            "**** EPOCH 202 ****\n",
            "2018-10-31 02:54:30.473452\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.093091\n",
            "accuracy: 0.962500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.084575\n",
            "accuracy: 0.962500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099189\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.108153\n",
            "accuracy: 0.952500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071934\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093455\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.065821\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.098982\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.109511\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.090448\n",
            "accuracy: 0.963750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.079551\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.088845\n",
            "accuracy: 0.972500\n",
            "2018-10-31 02:57:14.868362\n",
            "---- EPOCH 202 EVALUATION ----\n",
            "eval mean loss: 0.436191\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.873977\n",
            "**** EPOCH 203 ****\n",
            "2018-10-31 02:57:27.131625\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.065768\n",
            "accuracy: 0.978750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.088599\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.086217\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086240\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.084958\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.080041\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091515\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.090420\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.108499\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.097391\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.073788\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.079772\n",
            "accuracy: 0.968750\n",
            "2018-10-31 03:00:11.726356\n",
            "---- EPOCH 203 EVALUATION ----\n",
            "eval mean loss: 0.441062\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.871355\n",
            "**** EPOCH 204 ****\n",
            "2018-10-31 03:00:23.966124\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087509\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.089722\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.103987\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.069896\n",
            "accuracy: 0.975000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.090081\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.067809\n",
            "accuracy: 0.980000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086293\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.063901\n",
            "accuracy: 0.980000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.094631\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.069272\n",
            "accuracy: 0.978750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.066426\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.080314\n",
            "accuracy: 0.971250\n",
            "2018-10-31 03:03:07.927520\n",
            "---- EPOCH 204 EVALUATION ----\n",
            "eval mean loss: 0.442351\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.874349\n",
            "**** EPOCH 205 ****\n",
            "2018-10-31 03:03:20.198160\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.074793\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.119220\n",
            "accuracy: 0.953750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.077865\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.080838\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071871\n",
            "accuracy: 0.977500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.094350\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.075229\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.088128\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.088008\n",
            "accuracy: 0.962500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.080580\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.085147\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.071173\n",
            "accuracy: 0.977500\n",
            "2018-10-31 03:06:04.161612\n",
            "---- EPOCH 205 EVALUATION ----\n",
            "eval mean loss: 0.443121\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.873767\n",
            "**** EPOCH 206 ****\n",
            "2018-10-31 03:06:16.443605\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.072811\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.075629\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.092725\n",
            "accuracy: 0.962500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.102604\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.084808\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.089747\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.076409\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.079838\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086475\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.076268\n",
            "accuracy: 0.972500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.094503\n",
            "accuracy: 0.965000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.083880\n",
            "accuracy: 0.970000\n",
            "2018-10-31 03:09:00.612240\n",
            "---- EPOCH 206 EVALUATION ----\n",
            "eval mean loss: 0.445300\n",
            "eval accuracy: 0.897893\n",
            "eval avg class acc: 0.873390\n",
            "**** EPOCH 207 ****\n",
            "2018-10-31 03:09:12.885009\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.091501\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.068961\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.070198\n",
            "accuracy: 0.977500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.060518\n",
            "accuracy: 0.985000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.112822\n",
            "accuracy: 0.958750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.065620\n",
            "accuracy: 0.975000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086056\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.092617\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.068244\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.082447\n",
            "accuracy: 0.965000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082905\n",
            "accuracy: 0.967500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.077451\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:11:57.021432\n",
            "---- EPOCH 207 EVALUATION ----\n",
            "eval mean loss: 0.452326\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.871017\n",
            "**** EPOCH 208 ****\n",
            "2018-10-31 03:12:09.275086\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085752\n",
            "accuracy: 0.976250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.095952\n",
            "accuracy: 0.960000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.095608\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.080765\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.070606\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.079344\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.104072\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.093104\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080900\n",
            "accuracy: 0.975000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.058616\n",
            "accuracy: 0.986250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.114316\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.080448\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:14:53.792460\n",
            "---- EPOCH 208 EVALUATION ----\n",
            "eval mean loss: 0.445989\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.873767\n",
            "**** EPOCH 209 ****\n",
            "2018-10-31 03:15:06.059344\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.090860\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.088569\n",
            "accuracy: 0.963750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.074260\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.088090\n",
            "accuracy: 0.957500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.100723\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.071506\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.079043\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.082560\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080643\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.074733\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.099685\n",
            "accuracy: 0.965000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.052427\n",
            "accuracy: 0.982500\n",
            "2018-10-31 03:17:50.441593\n",
            "---- EPOCH 209 EVALUATION ----\n",
            "eval mean loss: 0.445703\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.873640\n",
            "**** EPOCH 210 ****\n",
            "2018-10-31 03:18:02.716061\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.076923\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.104846\n",
            "accuracy: 0.957500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.082676\n",
            "accuracy: 0.970000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.088423\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.094764\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.088219\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.075784\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.082730\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080520\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.106309\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.084445\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.085819\n",
            "accuracy: 0.966250\n",
            "2018-10-31 03:20:46.985117\n",
            "---- EPOCH 210 EVALUATION ----\n",
            "eval mean loss: 0.444480\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.872267\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 211 ****\n",
            "2018-10-31 03:20:59.712708\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.072686\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.082279\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.081033\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.088917\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.078475\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.076926\n",
            "accuracy: 0.966250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.097363\n",
            "accuracy: 0.967500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.041761\n",
            "accuracy: 0.987500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.095425\n",
            "accuracy: 0.963750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.109128\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.089737\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.077772\n",
            "accuracy: 0.963750\n",
            "2018-10-31 03:23:43.828509\n",
            "---- EPOCH 211 EVALUATION ----\n",
            "eval mean loss: 0.441283\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.870977\n",
            "**** EPOCH 212 ****\n",
            "2018-10-31 03:23:56.098537\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.070531\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.071248\n",
            "accuracy: 0.975000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.098282\n",
            "accuracy: 0.963750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104793\n",
            "accuracy: 0.951250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.086097\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099310\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.064826\n",
            "accuracy: 0.977500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.069236\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.099129\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.099973\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.085592\n",
            "accuracy: 0.965000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.073756\n",
            "accuracy: 0.970000\n",
            "2018-10-31 03:26:40.335841\n",
            "---- EPOCH 212 EVALUATION ----\n",
            "eval mean loss: 0.446269\n",
            "eval accuracy: 0.897083\n",
            "eval avg class acc: 0.876017\n",
            "**** EPOCH 213 ****\n",
            "2018-10-31 03:26:52.588209\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.074662\n",
            "accuracy: 0.972500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.096004\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.079042\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.112697\n",
            "accuracy: 0.962500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.088293\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.092115\n",
            "accuracy: 0.962500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.093586\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.091709\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.076607\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.083005\n",
            "accuracy: 0.960000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.078974\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.067386\n",
            "accuracy: 0.985000\n",
            "2018-10-31 03:29:36.996737\n",
            "---- EPOCH 213 EVALUATION ----\n",
            "eval mean loss: 0.441204\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.872977\n",
            "**** EPOCH 214 ****\n",
            "2018-10-31 03:29:49.303853\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.080530\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.070970\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.106031\n",
            "accuracy: 0.958750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.079732\n",
            "accuracy: 0.975000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.074635\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.078171\n",
            "accuracy: 0.977500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.103650\n",
            "accuracy: 0.963750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.100532\n",
            "accuracy: 0.960000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.093526\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.084891\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.068375\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.073135\n",
            "accuracy: 0.973750\n",
            "2018-10-31 03:32:33.493732\n",
            "---- EPOCH 214 EVALUATION ----\n",
            "eval mean loss: 0.452773\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.874058\n",
            "**** EPOCH 215 ****\n",
            "2018-10-31 03:32:45.746323\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.081224\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.079044\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.067199\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.070478\n",
            "accuracy: 0.976250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.100367\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.099163\n",
            "accuracy: 0.960000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.098205\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.067501\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.096584\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.092641\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.055202\n",
            "accuracy: 0.983750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.068303\n",
            "accuracy: 0.976250\n",
            "2018-10-31 03:35:30.204508\n",
            "---- EPOCH 215 EVALUATION ----\n",
            "eval mean loss: 0.450171\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.874186\n",
            "**** EPOCH 216 ****\n",
            "2018-10-31 03:35:42.487466\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.096610\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.075962\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.085758\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.100940\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.082275\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.103496\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.058851\n",
            "accuracy: 0.977500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.087230\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.069349\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.096936\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.086829\n",
            "accuracy: 0.960000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.071028\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:38:26.748863\n",
            "---- EPOCH 216 EVALUATION ----\n",
            "eval mean loss: 0.450242\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.874895\n",
            "**** EPOCH 217 ****\n",
            "2018-10-31 03:38:39.040136\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.087237\n",
            "accuracy: 0.966250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.068709\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.078439\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.093703\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.078598\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.077184\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.090798\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.093837\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.060582\n",
            "accuracy: 0.980000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.085101\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.096870\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.077385\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:41:23.433540\n",
            "---- EPOCH 217 EVALUATION ----\n",
            "eval mean loss: 0.450011\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.873017\n",
            "**** EPOCH 218 ****\n",
            "2018-10-31 03:41:35.653932\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.074585\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.083539\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.078869\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082563\n",
            "accuracy: 0.971250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.076639\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.056357\n",
            "accuracy: 0.985000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.086652\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.073050\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.075516\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.092039\n",
            "accuracy: 0.966250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.062490\n",
            "accuracy: 0.976250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.081723\n",
            "accuracy: 0.968750\n",
            "2018-10-31 03:44:20.102155\n",
            "---- EPOCH 218 EVALUATION ----\n",
            "eval mean loss: 0.450296\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873971\n",
            "**** EPOCH 219 ****\n",
            "2018-10-31 03:44:32.435910\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.095888\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.070649\n",
            "accuracy: 0.977500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099099\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.091800\n",
            "accuracy: 0.960000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.060967\n",
            "accuracy: 0.981250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083447\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.075408\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.075532\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.065327\n",
            "accuracy: 0.977500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.071295\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.110741\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.079820\n",
            "accuracy: 0.970000\n",
            "2018-10-31 03:47:16.832705\n",
            "---- EPOCH 219 EVALUATION ----\n",
            "eval mean loss: 0.452495\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 220 ****\n",
            "2018-10-31 03:47:29.136134\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.088357\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.067814\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.086460\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.084949\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.076523\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083648\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.069949\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.081633\n",
            "accuracy: 0.968750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.085812\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.088292\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.077497\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.071969\n",
            "accuracy: 0.972500\n",
            "2018-10-31 03:50:13.650986\n",
            "---- EPOCH 220 EVALUATION ----\n",
            "eval mean loss: 0.447455\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.871890\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 221 ****\n",
            "2018-10-31 03:50:26.338710\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.098965\n",
            "accuracy: 0.957500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.078427\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.069013\n",
            "accuracy: 0.976250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.078202\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.109772\n",
            "accuracy: 0.961250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.082898\n",
            "accuracy: 0.967500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.074822\n",
            "accuracy: 0.976250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.086743\n",
            "accuracy: 0.971250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.076357\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.102039\n",
            "accuracy: 0.962500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.095112\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.069550\n",
            "accuracy: 0.971250\n",
            "2018-10-31 03:53:10.688150\n",
            "---- EPOCH 221 EVALUATION ----\n",
            "eval mean loss: 0.449804\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.872599\n",
            "**** EPOCH 222 ****\n",
            "2018-10-31 03:53:22.994244\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.080036\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.086313\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.087808\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.072158\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.097335\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.063600\n",
            "accuracy: 0.980000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.096493\n",
            "accuracy: 0.958750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.077750\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.081558\n",
            "accuracy: 0.968750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.071790\n",
            "accuracy: 0.975000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.065088\n",
            "accuracy: 0.976250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.100504\n",
            "accuracy: 0.961250\n",
            "2018-10-31 03:56:07.213903\n",
            "---- EPOCH 222 EVALUATION ----\n",
            "eval mean loss: 0.453552\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.871599\n",
            "**** EPOCH 223 ****\n",
            "2018-10-31 03:56:19.430753\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.095885\n",
            "accuracy: 0.968750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.106913\n",
            "accuracy: 0.965000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.074237\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.075007\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.083901\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.089147\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.061527\n",
            "accuracy: 0.973750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.099294\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.085982\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.063376\n",
            "accuracy: 0.981250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.063058\n",
            "accuracy: 0.978750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.085360\n",
            "accuracy: 0.968750\n",
            "2018-10-31 03:59:03.411025\n",
            "---- EPOCH 223 EVALUATION ----\n",
            "eval mean loss: 0.453607\n",
            "eval accuracy: 0.893841\n",
            "eval avg class acc: 0.870808\n",
            "**** EPOCH 224 ****\n",
            "2018-10-31 03:59:15.665420\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085907\n",
            "accuracy: 0.961250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074361\n",
            "accuracy: 0.966250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.084242\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.066572\n",
            "accuracy: 0.976250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.072506\n",
            "accuracy: 0.973750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.070659\n",
            "accuracy: 0.977500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.069556\n",
            "accuracy: 0.975000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.061693\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.068294\n",
            "accuracy: 0.976250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.085548\n",
            "accuracy: 0.972500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.129021\n",
            "accuracy: 0.950000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.092472\n",
            "accuracy: 0.962500\n",
            "2018-10-31 04:01:59.548530\n",
            "---- EPOCH 224 EVALUATION ----\n",
            "eval mean loss: 0.457231\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.870767\n",
            "**** EPOCH 225 ****\n",
            "2018-10-31 04:02:11.805730\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.051223\n",
            "accuracy: 0.985000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.088971\n",
            "accuracy: 0.970000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.073481\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.086533\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.082884\n",
            "accuracy: 0.967500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.085434\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.084824\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.087012\n",
            "accuracy: 0.963750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086423\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.077431\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.087443\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.070984\n",
            "accuracy: 0.975000\n",
            "2018-10-31 04:04:55.818834\n",
            "---- EPOCH 225 EVALUATION ----\n",
            "eval mean loss: 0.449469\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.874686\n",
            "**** EPOCH 226 ****\n",
            "2018-10-31 04:05:08.132886\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.082128\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.080122\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.083384\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.094711\n",
            "accuracy: 0.966250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.084965\n",
            "accuracy: 0.968750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.090735\n",
            "accuracy: 0.958750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.047750\n",
            "accuracy: 0.983750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.092653\n",
            "accuracy: 0.961250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.067354\n",
            "accuracy: 0.981250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.081756\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.099435\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.074385\n",
            "accuracy: 0.970000\n",
            "2018-10-31 04:07:52.247433\n",
            "---- EPOCH 226 EVALUATION ----\n",
            "eval mean loss: 0.459187\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.874849\n",
            "**** EPOCH 227 ****\n",
            "2018-10-31 04:08:04.567738\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.069234\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.071506\n",
            "accuracy: 0.971250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.088179\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.067022\n",
            "accuracy: 0.978750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.063652\n",
            "accuracy: 0.982500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.102622\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.088335\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.073912\n",
            "accuracy: 0.971250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086930\n",
            "accuracy: 0.967500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.077391\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.081122\n",
            "accuracy: 0.977500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.067733\n",
            "accuracy: 0.977500\n",
            "2018-10-31 04:10:48.965162\n",
            "---- EPOCH 227 EVALUATION ----\n",
            "eval mean loss: 0.458740\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.871599\n",
            "**** EPOCH 228 ****\n",
            "2018-10-31 04:11:01.247881\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.064076\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.092031\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.049209\n",
            "accuracy: 0.985000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.081457\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.088161\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.076232\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.091696\n",
            "accuracy: 0.961250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.084166\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.078327\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.063225\n",
            "accuracy: 0.977500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.065940\n",
            "accuracy: 0.978750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.081027\n",
            "accuracy: 0.966250\n",
            "2018-10-31 04:13:45.556016\n",
            "---- EPOCH 228 EVALUATION ----\n",
            "eval mean loss: 0.458728\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.874599\n",
            "**** EPOCH 229 ****\n",
            "2018-10-31 04:13:57.869469\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.082583\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.095081\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.073893\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.061230\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.077027\n",
            "accuracy: 0.971250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.070484\n",
            "accuracy: 0.976250\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.083097\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.089607\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.082124\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.077592\n",
            "accuracy: 0.973750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.084330\n",
            "accuracy: 0.966250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.081683\n",
            "accuracy: 0.972500\n",
            "2018-10-31 04:16:42.287814\n",
            "---- EPOCH 229 EVALUATION ----\n",
            "eval mean loss: 0.456634\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.873349\n",
            "**** EPOCH 230 ****\n",
            "2018-10-31 04:16:54.552830\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.099465\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.063523\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.081458\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.090576\n",
            "accuracy: 0.965000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.087283\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.081616\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.059801\n",
            "accuracy: 0.981250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.062261\n",
            "accuracy: 0.975000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.086670\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.079683\n",
            "accuracy: 0.968750\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.074521\n",
            "accuracy: 0.975000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.082265\n",
            "accuracy: 0.967500\n",
            "2018-10-31 04:19:38.763116\n",
            "---- EPOCH 230 EVALUATION ----\n",
            "eval mean loss: 0.460449\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.873686\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 231 ****\n",
            "2018-10-31 04:19:51.463999\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.064665\n",
            "accuracy: 0.980000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.085319\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.069738\n",
            "accuracy: 0.977500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.073740\n",
            "accuracy: 0.972500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.071968\n",
            "accuracy: 0.972500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.066708\n",
            "accuracy: 0.982500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.062518\n",
            "accuracy: 0.976250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.075314\n",
            "accuracy: 0.973750\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.095009\n",
            "accuracy: 0.965000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.087020\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.084587\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.077521\n",
            "accuracy: 0.972500\n",
            "2018-10-31 04:22:35.733058\n",
            "---- EPOCH 231 EVALUATION ----\n",
            "eval mean loss: 0.457827\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.872517\n",
            "**** EPOCH 232 ****\n",
            "2018-10-31 04:22:48.045134\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.080297\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.083973\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.069373\n",
            "accuracy: 0.971250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.079034\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.092807\n",
            "accuracy: 0.962500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.093664\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.074934\n",
            "accuracy: 0.972500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.087138\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.101910\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.063563\n",
            "accuracy: 0.971250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.056466\n",
            "accuracy: 0.978750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.067593\n",
            "accuracy: 0.978750\n",
            "2018-10-31 04:25:32.167039\n",
            "---- EPOCH 232 EVALUATION ----\n",
            "eval mean loss: 0.459460\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.872599\n",
            "**** EPOCH 233 ****\n",
            "2018-10-31 04:25:44.446886\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.070586\n",
            "accuracy: 0.978750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.089490\n",
            "accuracy: 0.967500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.102004\n",
            "accuracy: 0.961250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.071965\n",
            "accuracy: 0.967500\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.066600\n",
            "accuracy: 0.980000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083160\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.082054\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.078657\n",
            "accuracy: 0.972500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.080570\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.110972\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.080413\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.066506\n",
            "accuracy: 0.972500\n",
            "2018-10-31 04:28:28.526577\n",
            "---- EPOCH 233 EVALUATION ----\n",
            "eval mean loss: 0.459460\n",
            "eval accuracy: 0.895867\n",
            "eval avg class acc: 0.874390\n",
            "**** EPOCH 234 ****\n",
            "2018-10-31 04:28:40.753711\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.074571\n",
            "accuracy: 0.975000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.066192\n",
            "accuracy: 0.977500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.090692\n",
            "accuracy: 0.965000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.082221\n",
            "accuracy: 0.976250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.062770\n",
            "accuracy: 0.977500\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083896\n",
            "accuracy: 0.963750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.073806\n",
            "accuracy: 0.968750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.106349\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.091958\n",
            "accuracy: 0.972500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.056816\n",
            "accuracy: 0.981250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082882\n",
            "accuracy: 0.972500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.078044\n",
            "accuracy: 0.973750\n",
            "2018-10-31 04:31:24.613038\n",
            "---- EPOCH 234 EVALUATION ----\n",
            "eval mean loss: 0.462001\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.872017\n",
            "**** EPOCH 235 ****\n",
            "2018-10-31 04:31:36.867836\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.066924\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.063900\n",
            "accuracy: 0.975000\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.064533\n",
            "accuracy: 0.980000\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104111\n",
            "accuracy: 0.961250\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.059952\n",
            "accuracy: 0.978750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083551\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.080856\n",
            "accuracy: 0.966250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.078525\n",
            "accuracy: 0.970000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.119828\n",
            "accuracy: 0.955000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.070481\n",
            "accuracy: 0.967500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091685\n",
            "accuracy: 0.962500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.057651\n",
            "accuracy: 0.983750\n",
            "2018-10-31 04:34:20.750616\n",
            "---- EPOCH 235 EVALUATION ----\n",
            "eval mean loss: 0.459839\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.871849\n",
            "**** EPOCH 236 ****\n",
            "2018-10-31 04:34:33.026893\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.062489\n",
            "accuracy: 0.978750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.103968\n",
            "accuracy: 0.961250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.089128\n",
            "accuracy: 0.966250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.113063\n",
            "accuracy: 0.963750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.087108\n",
            "accuracy: 0.973750\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.073292\n",
            "accuracy: 0.972500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.070295\n",
            "accuracy: 0.978750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.074644\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.081719\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.085601\n",
            "accuracy: 0.972500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.123467\n",
            "accuracy: 0.952500\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.076031\n",
            "accuracy: 0.971250\n",
            "2018-10-31 04:37:16.968242\n",
            "---- EPOCH 236 EVALUATION ----\n",
            "eval mean loss: 0.456045\n",
            "eval accuracy: 0.893436\n",
            "eval avg class acc: 0.870099\n",
            "**** EPOCH 237 ****\n",
            "2018-10-31 04:37:29.227383\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.085941\n",
            "accuracy: 0.970000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074742\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.079486\n",
            "accuracy: 0.973750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.111791\n",
            "accuracy: 0.955000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.093560\n",
            "accuracy: 0.965000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.083420\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.082794\n",
            "accuracy: 0.973750\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.091284\n",
            "accuracy: 0.966250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.069516\n",
            "accuracy: 0.971250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.088770\n",
            "accuracy: 0.961250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.085690\n",
            "accuracy: 0.968750\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.093515\n",
            "accuracy: 0.973750\n",
            "2018-10-31 04:40:13.181497\n",
            "---- EPOCH 237 EVALUATION ----\n",
            "eval mean loss: 0.458868\n",
            "eval accuracy: 0.896272\n",
            "eval avg class acc: 0.872517\n",
            "**** EPOCH 238 ****\n",
            "2018-10-31 04:40:25.438118\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.104178\n",
            "accuracy: 0.965000\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.086701\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.086929\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.099344\n",
            "accuracy: 0.968750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.074585\n",
            "accuracy: 0.976250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.069713\n",
            "accuracy: 0.977500\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.101977\n",
            "accuracy: 0.960000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.085861\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.097172\n",
            "accuracy: 0.957500\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.068111\n",
            "accuracy: 0.976250\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.076050\n",
            "accuracy: 0.971250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.063953\n",
            "accuracy: 0.978750\n",
            "2018-10-31 04:43:09.457875\n",
            "---- EPOCH 238 EVALUATION ----\n",
            "eval mean loss: 0.457023\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.873895\n",
            "**** EPOCH 239 ****\n",
            "2018-10-31 04:43:21.691549\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.086875\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074125\n",
            "accuracy: 0.968750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.059988\n",
            "accuracy: 0.981250\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.080240\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.098691\n",
            "accuracy: 0.966250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.082925\n",
            "accuracy: 0.968750\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.089326\n",
            "accuracy: 0.970000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.097029\n",
            "accuracy: 0.965000\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.074543\n",
            "accuracy: 0.973750\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.086999\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.094962\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.080993\n",
            "accuracy: 0.972500\n",
            "2018-10-31 04:46:05.803373\n",
            "---- EPOCH 239 EVALUATION ----\n",
            "eval mean loss: 0.455870\n",
            "eval accuracy: 0.894246\n",
            "eval avg class acc: 0.871477\n",
            "**** EPOCH 240 ****\n",
            "2018-10-31 04:46:18.109725\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.095423\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.064290\n",
            "accuracy: 0.972500\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.077783\n",
            "accuracy: 0.968750\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.068221\n",
            "accuracy: 0.973750\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.086395\n",
            "accuracy: 0.970000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.087110\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.071809\n",
            "accuracy: 0.971250\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.088583\n",
            "accuracy: 0.962500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.089497\n",
            "accuracy: 0.970000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.073027\n",
            "accuracy: 0.975000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.091244\n",
            "accuracy: 0.965000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.062077\n",
            "accuracy: 0.977500\n",
            "2018-10-31 04:49:02.136417\n",
            "---- EPOCH 240 EVALUATION ----\n",
            "eval mean loss: 0.455987\n",
            "eval accuracy: 0.896677\n",
            "eval avg class acc: 0.874180\n",
            "Model saved in file: log/model.ckpt\n",
            "**** EPOCH 241 ****\n",
            "2018-10-31 04:49:14.840176\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.094367\n",
            "accuracy: 0.971250\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.083171\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.072158\n",
            "accuracy: 0.972500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.104299\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.088306\n",
            "accuracy: 0.960000\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.096555\n",
            "accuracy: 0.965000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.058574\n",
            "accuracy: 0.977500\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.065689\n",
            "accuracy: 0.976250\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.113263\n",
            "accuracy: 0.960000\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.098238\n",
            "accuracy: 0.970000\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.096177\n",
            "accuracy: 0.961250\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.092472\n",
            "accuracy: 0.967500\n",
            "2018-10-31 04:51:58.934473\n",
            "---- EPOCH 241 EVALUATION ----\n",
            "eval mean loss: 0.453782\n",
            "eval accuracy: 0.894652\n",
            "eval avg class acc: 0.872727\n",
            "**** EPOCH 242 ****\n",
            "2018-10-31 04:52:11.194851\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.081320\n",
            "accuracy: 0.967500\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.070351\n",
            "accuracy: 0.973750\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.099291\n",
            "accuracy: 0.967500\n",
            " ---- batch: 200 ----\n",
            "mean loss: 0.077789\n",
            "accuracy: 0.970000\n",
            " ---- batch: 250 ----\n",
            "mean loss: 0.066425\n",
            "accuracy: 0.976250\n",
            " ---- batch: 300 ----\n",
            "mean loss: 0.077059\n",
            "accuracy: 0.970000\n",
            " ---- batch: 350 ----\n",
            "mean loss: 0.100234\n",
            "accuracy: 0.965000\n",
            " ---- batch: 400 ----\n",
            "mean loss: 0.080291\n",
            "accuracy: 0.967500\n",
            " ---- batch: 450 ----\n",
            "mean loss: 0.085905\n",
            "accuracy: 0.966250\n",
            " ---- batch: 500 ----\n",
            "mean loss: 0.064297\n",
            "accuracy: 0.977500\n",
            " ---- batch: 550 ----\n",
            "mean loss: 0.082535\n",
            "accuracy: 0.970000\n",
            " ---- batch: 600 ----\n",
            "mean loss: 0.066129\n",
            "accuracy: 0.976250\n",
            "2018-10-31 04:54:55.301138\n",
            "---- EPOCH 242 EVALUATION ----\n",
            "eval mean loss: 0.451082\n",
            "eval accuracy: 0.895057\n",
            "eval avg class acc: 0.871895\n",
            "**** EPOCH 243 ****\n",
            "2018-10-31 04:55:07.566193\n",
            " ---- batch: 050 ----\n",
            "mean loss: 0.096314\n",
            "accuracy: 0.963750\n",
            " ---- batch: 100 ----\n",
            "mean loss: 0.074050\n",
            "accuracy: 0.976250\n",
            " ---- batch: 150 ----\n",
            "mean loss: 0.061694\n",
            "accuracy: 0.975000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hrIjBOTwmMby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3768
        },
        "outputId": "c07081e6-c17f-4c4f-9188-56892b48ebc9"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2')\n",
        "\n",
        "!python evaluate.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2/utils/pointnet_util.py:127: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "2018-10-31 05:29:54.430223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-31 05:29:54.430683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-10-31 05:29:54.430722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-10-31 05:29:55.383116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-31 05:29:55.383176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-10-31 05:29:55.383207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-10-31 05:29:55.383603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Model restored.\n",
            "Batch: 000, batch size: 16\n",
            "Batch: 001, batch size: 16\n",
            "Batch: 002, batch size: 16\n",
            "Batch: 003, batch size: 16\n",
            "Batch: 004, batch size: 16\n",
            "Batch: 005, batch size: 16\n",
            "Batch: 006, batch size: 16\n",
            "Batch: 007, batch size: 16\n",
            "Batch: 008, batch size: 16\n",
            "Batch: 009, batch size: 16\n",
            "Batch: 010, batch size: 16\n",
            "Batch: 011, batch size: 16\n",
            "Batch: 012, batch size: 16\n",
            "Batch: 013, batch size: 16\n",
            "Batch: 014, batch size: 16\n",
            "Batch: 015, batch size: 16\n",
            "Batch: 016, batch size: 16\n",
            "Batch: 017, batch size: 16\n",
            "Batch: 018, batch size: 16\n",
            "Batch: 019, batch size: 16\n",
            "Batch: 020, batch size: 16\n",
            "Batch: 021, batch size: 16\n",
            "Batch: 022, batch size: 16\n",
            "Batch: 023, batch size: 16\n",
            "Batch: 024, batch size: 16\n",
            "Batch: 025, batch size: 16\n",
            "Batch: 026, batch size: 16\n",
            "Batch: 027, batch size: 16\n",
            "Batch: 028, batch size: 16\n",
            "Batch: 029, batch size: 16\n",
            "Batch: 030, batch size: 16\n",
            "Batch: 031, batch size: 16\n",
            "Batch: 032, batch size: 16\n",
            "Batch: 033, batch size: 16\n",
            "Batch: 034, batch size: 16\n",
            "Batch: 035, batch size: 16\n",
            "Batch: 036, batch size: 16\n",
            "Batch: 037, batch size: 16\n",
            "Batch: 038, batch size: 16\n",
            "Batch: 039, batch size: 16\n",
            "Batch: 040, batch size: 16\n",
            "Batch: 041, batch size: 16\n",
            "Batch: 042, batch size: 16\n",
            "Batch: 043, batch size: 16\n",
            "Batch: 044, batch size: 16\n",
            "Batch: 045, batch size: 16\n",
            "Batch: 046, batch size: 16\n",
            "Batch: 047, batch size: 16\n",
            "Batch: 048, batch size: 16\n",
            "Batch: 049, batch size: 16\n",
            "Batch: 050, batch size: 16\n",
            "Batch: 051, batch size: 16\n",
            "Batch: 052, batch size: 16\n",
            "Batch: 053, batch size: 16\n",
            "Batch: 054, batch size: 16\n",
            "Batch: 055, batch size: 16\n",
            "Batch: 056, batch size: 16\n",
            "Batch: 057, batch size: 16\n",
            "Batch: 058, batch size: 16\n",
            "Batch: 059, batch size: 16\n",
            "Batch: 060, batch size: 16\n",
            "Batch: 061, batch size: 16\n",
            "Batch: 062, batch size: 16\n",
            "Batch: 063, batch size: 16\n",
            "Batch: 064, batch size: 16\n",
            "Batch: 065, batch size: 16\n",
            "Batch: 066, batch size: 16\n",
            "Batch: 067, batch size: 16\n",
            "Batch: 068, batch size: 16\n",
            "Batch: 069, batch size: 16\n",
            "Batch: 070, batch size: 16\n",
            "Batch: 071, batch size: 16\n",
            "Batch: 072, batch size: 16\n",
            "Batch: 073, batch size: 16\n",
            "Batch: 074, batch size: 16\n",
            "Batch: 075, batch size: 16\n",
            "Batch: 076, batch size: 16\n",
            "Batch: 077, batch size: 16\n",
            "Batch: 078, batch size: 16\n",
            "Batch: 079, batch size: 16\n",
            "Batch: 080, batch size: 16\n",
            "Batch: 081, batch size: 16\n",
            "Batch: 082, batch size: 16\n",
            "Batch: 083, batch size: 16\n",
            "Batch: 084, batch size: 16\n",
            "Batch: 085, batch size: 16\n",
            "Batch: 086, batch size: 16\n",
            "Batch: 087, batch size: 16\n",
            "Batch: 088, batch size: 16\n",
            "Batch: 089, batch size: 16\n",
            "Batch: 090, batch size: 16\n",
            "Batch: 091, batch size: 16\n",
            "Batch: 092, batch size: 16\n",
            "Batch: 093, batch size: 16\n",
            "Batch: 094, batch size: 16\n",
            "Batch: 095, batch size: 16\n",
            "Batch: 096, batch size: 16\n",
            "Batch: 097, batch size: 16\n",
            "Batch: 098, batch size: 16\n",
            "Batch: 099, batch size: 16\n",
            "Batch: 100, batch size: 16\n",
            "Batch: 101, batch size: 16\n",
            "Batch: 102, batch size: 16\n",
            "Batch: 103, batch size: 16\n",
            "Batch: 104, batch size: 16\n",
            "Batch: 105, batch size: 16\n",
            "Batch: 106, batch size: 16\n",
            "Batch: 107, batch size: 16\n",
            "Batch: 108, batch size: 16\n",
            "Batch: 109, batch size: 16\n",
            "Batch: 110, batch size: 16\n",
            "Batch: 111, batch size: 16\n",
            "Batch: 112, batch size: 16\n",
            "Batch: 113, batch size: 16\n",
            "Batch: 114, batch size: 16\n",
            "Batch: 115, batch size: 16\n",
            "Batch: 116, batch size: 16\n",
            "Batch: 117, batch size: 16\n",
            "Batch: 118, batch size: 16\n",
            "Batch: 119, batch size: 16\n",
            "Batch: 120, batch size: 16\n",
            "Batch: 121, batch size: 16\n",
            "Batch: 122, batch size: 16\n",
            "Batch: 123, batch size: 16\n",
            "Batch: 124, batch size: 16\n",
            "Batch: 125, batch size: 16\n",
            "Batch: 126, batch size: 16\n",
            "Batch: 127, batch size: 16\n",
            "Batch: 128, batch size: 16\n",
            "Batch: 129, batch size: 16\n",
            "Batch: 130, batch size: 16\n",
            "Batch: 131, batch size: 16\n",
            "Batch: 132, batch size: 16\n",
            "Batch: 133, batch size: 16\n",
            "Batch: 134, batch size: 16\n",
            "Batch: 135, batch size: 16\n",
            "Batch: 136, batch size: 16\n",
            "Batch: 137, batch size: 16\n",
            "Batch: 138, batch size: 16\n",
            "Batch: 139, batch size: 16\n",
            "Batch: 140, batch size: 16\n",
            "Batch: 141, batch size: 16\n",
            "Batch: 142, batch size: 16\n",
            "Batch: 143, batch size: 16\n",
            "Batch: 144, batch size: 16\n",
            "Batch: 145, batch size: 16\n",
            "Batch: 146, batch size: 16\n",
            "Batch: 147, batch size: 16\n",
            "Batch: 148, batch size: 16\n",
            "Batch: 149, batch size: 16\n",
            "Batch: 150, batch size: 16\n",
            "Batch: 151, batch size: 16\n",
            "Batch: 152, batch size: 16\n",
            "Batch: 153, batch size: 16\n",
            "Batch: 154, batch size: 4\n",
            "eval mean loss: 0.453525\n",
            "eval accuracy: 0.895462\n",
            "eval avg class acc: 0.873308\n",
            "  airplane:\t1.000\n",
            "   bathtub:\t0.940\n",
            "       bed:\t0.970\n",
            "     bench:\t0.800\n",
            " bookshelf:\t0.950\n",
            "    bottle:\t0.940\n",
            "      bowl:\t0.950\n",
            "       car:\t0.970\n",
            "     chair:\t0.970\n",
            "      cone:\t0.950\n",
            "       cup:\t0.800\n",
            "   curtain:\t0.850\n",
            "      desk:\t0.860\n",
            "      door:\t0.950\n",
            "   dresser:\t0.663\n",
            "flower_pot:\t0.200\n",
            " glass_box:\t0.940\n",
            "    guitar:\t1.000\n",
            "  keyboard:\t1.000\n",
            "      lamp:\t0.850\n",
            "    laptop:\t1.000\n",
            "    mantel:\t0.970\n",
            "   monitor:\t0.980\n",
            "night_stand:\t0.779\n",
            "    person:\t0.850\n",
            "     piano:\t0.960\n",
            "     plant:\t0.750\n",
            "     radio:\t0.800\n",
            "range_hood:\t0.930\n",
            "      sink:\t0.850\n",
            "      sofa:\t0.930\n",
            "    stairs:\t0.950\n",
            "     stool:\t0.750\n",
            "     table:\t0.790\n",
            "      tent:\t0.950\n",
            "    toilet:\t0.990\n",
            "  tv_stand:\t0.860\n",
            "      vase:\t0.740\n",
            "  wardrobe:\t0.850\n",
            "      xbox:\t0.700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HrqElhJv4U6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urpBMxFMwZp0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running tensorboard with the pointnet 2 result\n",
        "https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/"
      ]
    },
    {
      "metadata": {
        "id": "IQr6PJmEyDoA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "7fbfba6c-044b-43dd-803d-37aad0b03e1b"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-31 07:30:54--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.199.255.1, 34.196.237.103, 52.204.188.97, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.199.255.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  6.36MB/s    in 0.8s    \n",
            "\n",
            "2018-10-31 07:30:56 (6.36 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4zqMn0V3yHfl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/pointnet2/pointnet2')\n",
        "os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet2/pointnet2')\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7Et00urGZpi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6007 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSEyxJBXFwKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2eecc9c6-0580-4f28-dd16-d7f4f8b44084"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://c0859e76.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v-_9M7rBJWlj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jQsVx4w1JYHY"
      },
      "cell_type": "markdown",
      "source": [
        "## Running 3DmFV-Net\n",
        "\n",
        "Mount the google drive and point to the folder containing the train.py and run the code from there with a slight modification.\n"
      ]
    },
    {
      "metadata": {
        "id": "VdXudP48JjqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72287
        },
        "outputId": "2b62ed42-2801-46b9-e163-8c7fa57df509"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KE5208_Sense_Making/Code/3DmFV-Net-master')\n",
        "#os.chdir('/content/gdrive/My Drive/GitHub/PointnetEnhanced/pointnet/')\n",
        "\n",
        "\n",
        "!python train_cls.py --gpu=0 --batch_size=128"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Modelnet40\n",
            "Log dir already exists! creating a new one..............\n",
            "New log dir:log/modelnet40/3dmfv_net_cls/grid5_log_trial/8\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/KE5208_Sense_Making/Code/3DmFV-Net-master/utils/tf_util.py:606: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:224: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:201: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/KE5208_Sense_Making/Code/3DmFV-Net-master/utils/tf_util.py:637: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "2018-10-31 16:37:04.518141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-31 16:37:04.518618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-10-31 16:37:04.518660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-10-31 16:37:04.935543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-31 16:37:04.935624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-10-31 16:37:04.935647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-10-31 16:37:04.935958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "**** EPOCH 000 ****\n",
            "----0-----\n",
            "mean loss: 3.015806\n",
            "accuracy: 0.263184\n",
            "----1-----\n",
            "mean loss: 2.334979\n",
            "accuracy: 0.414714\n",
            "----2-----\n",
            "mean loss: 2.086715\n",
            "accuracy: 0.472168\n",
            "----3-----\n",
            "mean loss: 1.930782\n",
            "accuracy: 0.503906\n",
            "----4-----\n",
            "mean loss: 1.737059\n",
            "accuracy: 0.546387\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 1.448044\n",
            "eval accuracy: 0.594984\n",
            "eval avg class acc: 0.444060\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 001 ****\n",
            "----0-----\n",
            "mean loss: 1.577246\n",
            "accuracy: 0.574870\n",
            "----1-----\n",
            "mean loss: 1.514309\n",
            "accuracy: 0.596680\n",
            "----2-----\n",
            "mean loss: 1.426890\n",
            "accuracy: 0.610840\n",
            "----3-----\n",
            "mean loss: 1.350677\n",
            "accuracy: 0.630371\n",
            "----4-----\n",
            "mean loss: 1.271170\n",
            "accuracy: 0.646973\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.903551\n",
            "eval accuracy: 0.743010\n",
            "eval avg class acc: 0.612291\n",
            "**** EPOCH 002 ****\n",
            "----0-----\n",
            "mean loss: 1.206195\n",
            "accuracy: 0.658691\n",
            "----1-----\n",
            "mean loss: 1.188432\n",
            "accuracy: 0.661621\n",
            "----2-----\n",
            "mean loss: 1.054731\n",
            "accuracy: 0.699219\n",
            "----3-----\n",
            "mean loss: 1.091334\n",
            "accuracy: 0.691406\n",
            "----4-----\n",
            "mean loss: 1.059733\n",
            "accuracy: 0.693359\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.886331\n",
            "eval accuracy: 0.727796\n",
            "eval avg class acc: 0.638523\n",
            "**** EPOCH 003 ****\n",
            "----0-----\n",
            "mean loss: 1.043284\n",
            "accuracy: 0.692871\n",
            "----1-----\n",
            "mean loss: 0.990548\n",
            "accuracy: 0.709635\n",
            "----2-----\n",
            "mean loss: 0.977778\n",
            "accuracy: 0.707520\n",
            "----3-----\n",
            "mean loss: 0.978291\n",
            "accuracy: 0.710938\n",
            "----4-----\n",
            "mean loss: 0.954568\n",
            "accuracy: 0.727051\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.727344\n",
            "eval accuracy: 0.780016\n",
            "eval avg class acc: 0.682413\n",
            "**** EPOCH 004 ****\n",
            "----0-----\n",
            "mean loss: 0.904872\n",
            "accuracy: 0.742676\n",
            "----1-----\n",
            "mean loss: 0.895120\n",
            "accuracy: 0.726562\n",
            "----2-----\n",
            "mean loss: 0.861368\n",
            "accuracy: 0.740885\n",
            "----3-----\n",
            "mean loss: 0.868856\n",
            "accuracy: 0.746582\n",
            "----4-----\n",
            "mean loss: 0.855125\n",
            "accuracy: 0.745605\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.708034\n",
            "eval accuracy: 0.782895\n",
            "eval avg class acc: 0.702493\n",
            "**** EPOCH 005 ****\n",
            "----0-----\n",
            "mean loss: 0.854279\n",
            "accuracy: 0.737305\n",
            "----1-----\n",
            "mean loss: 0.803775\n",
            "accuracy: 0.757161\n",
            "----2-----\n",
            "mean loss: 0.835447\n",
            "accuracy: 0.759277\n",
            "----3-----\n",
            "mean loss: 0.810655\n",
            "accuracy: 0.760742\n",
            "----4-----\n",
            "mean loss: 0.828899\n",
            "accuracy: 0.755371\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.667562\n",
            "eval accuracy: 0.791118\n",
            "eval avg class acc: 0.702182\n",
            "**** EPOCH 006 ****\n",
            "----0-----\n",
            "mean loss: 0.764849\n",
            "accuracy: 0.777832\n",
            "----1-----\n",
            "mean loss: 0.799528\n",
            "accuracy: 0.756836\n",
            "----2-----\n",
            "mean loss: 0.770865\n",
            "accuracy: 0.771484\n",
            "----3-----\n",
            "mean loss: 0.751557\n",
            "accuracy: 0.769531\n",
            "----4-----\n",
            "mean loss: 0.768611\n",
            "accuracy: 0.757812\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.563377\n",
            "eval accuracy: 0.822780\n",
            "eval avg class acc: 0.735729\n",
            "**** EPOCH 007 ****\n",
            "----0-----\n",
            "mean loss: 0.717432\n",
            "accuracy: 0.776042\n",
            "----1-----\n",
            "mean loss: 0.708965\n",
            "accuracy: 0.785156\n",
            "----2-----\n",
            "mean loss: 0.751494\n",
            "accuracy: 0.783691\n",
            "----3-----\n",
            "mean loss: 0.755734\n",
            "accuracy: 0.772461\n",
            "----4-----\n",
            "mean loss: 0.733539\n",
            "accuracy: 0.775391\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.573454\n",
            "eval accuracy: 0.818257\n",
            "eval avg class acc: 0.727700\n",
            "**** EPOCH 008 ****\n",
            "----0-----\n",
            "mean loss: 0.686330\n",
            "accuracy: 0.785807\n",
            "----1-----\n",
            "mean loss: 0.755055\n",
            "accuracy: 0.775879\n",
            "----2-----\n",
            "mean loss: 0.708005\n",
            "accuracy: 0.791016\n",
            "----3-----\n",
            "mean loss: 0.713604\n",
            "accuracy: 0.777832\n",
            "----4-----\n",
            "mean loss: 0.693517\n",
            "accuracy: 0.787109\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.547525\n",
            "eval accuracy: 0.835938\n",
            "eval avg class acc: 0.741157\n",
            "**** EPOCH 009 ****\n",
            "----0-----\n",
            "mean loss: 0.653157\n",
            "accuracy: 0.794271\n",
            "----1-----\n",
            "mean loss: 0.658886\n",
            "accuracy: 0.794434\n",
            "----2-----\n",
            "mean loss: 0.662482\n",
            "accuracy: 0.786621\n",
            "----3-----\n",
            "mean loss: 0.676997\n",
            "accuracy: 0.788574\n",
            "----4-----\n",
            "mean loss: 0.687488\n",
            "accuracy: 0.812012\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.536288\n",
            "eval accuracy: 0.838816\n",
            "eval avg class acc: 0.757041\n",
            "**** EPOCH 010 ****\n",
            "----0-----\n",
            "mean loss: 0.616915\n",
            "accuracy: 0.804036\n",
            "----1-----\n",
            "mean loss: 0.612684\n",
            "accuracy: 0.804199\n",
            "----2-----\n",
            "mean loss: 0.620925\n",
            "accuracy: 0.803711\n",
            "----3-----\n",
            "mean loss: 0.604470\n",
            "accuracy: 0.810547\n",
            "----4-----\n",
            "mean loss: 0.642445\n",
            "accuracy: 0.803223\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.470703\n",
            "eval accuracy: 0.854441\n",
            "eval avg class acc: 0.764991\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 011 ****\n",
            "----0-----\n",
            "mean loss: 0.609238\n",
            "accuracy: 0.818848\n",
            "----1-----\n",
            "mean loss: 0.597208\n",
            "accuracy: 0.820801\n",
            "----2-----\n",
            "mean loss: 0.622389\n",
            "accuracy: 0.799805\n",
            "----3-----\n",
            "mean loss: 0.612486\n",
            "accuracy: 0.804036\n",
            "----4-----\n",
            "mean loss: 0.623171\n",
            "accuracy: 0.812012\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.511994\n",
            "eval accuracy: 0.837993\n",
            "eval avg class acc: 0.760859\n",
            "**** EPOCH 012 ****\n",
            "----0-----\n",
            "mean loss: 0.554524\n",
            "accuracy: 0.820312\n",
            "----1-----\n",
            "mean loss: 0.591376\n",
            "accuracy: 0.814453\n",
            "----2-----\n",
            "mean loss: 0.574650\n",
            "accuracy: 0.829102\n",
            "----3-----\n",
            "mean loss: 0.598364\n",
            "accuracy: 0.817871\n",
            "----4-----\n",
            "mean loss: 0.601361\n",
            "accuracy: 0.819824\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.500634\n",
            "eval accuracy: 0.848273\n",
            "eval avg class acc: 0.777751\n",
            "**** EPOCH 013 ****\n",
            "----0-----\n",
            "mean loss: 0.582864\n",
            "accuracy: 0.830566\n",
            "----1-----\n",
            "mean loss: 0.550795\n",
            "accuracy: 0.831055\n",
            "----2-----\n",
            "mean loss: 0.582556\n",
            "accuracy: 0.822917\n",
            "----3-----\n",
            "mean loss: 0.563937\n",
            "accuracy: 0.818848\n",
            "----4-----\n",
            "mean loss: 0.585157\n",
            "accuracy: 0.817871\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.446748\n",
            "eval accuracy: 0.868010\n",
            "eval avg class acc: 0.805339\n",
            "**** EPOCH 014 ****\n",
            "----0-----\n",
            "mean loss: 0.546765\n",
            "accuracy: 0.823242\n",
            "----1-----\n",
            "mean loss: 0.564215\n",
            "accuracy: 0.823730\n",
            "----2-----\n",
            "mean loss: 0.569518\n",
            "accuracy: 0.827148\n",
            "----3-----\n",
            "mean loss: 0.560375\n",
            "accuracy: 0.816895\n",
            "----4-----\n",
            "mean loss: 0.522564\n",
            "accuracy: 0.827474\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.458446\n",
            "eval accuracy: 0.863898\n",
            "eval avg class acc: 0.809327\n",
            "**** EPOCH 015 ****\n",
            "----0-----\n",
            "mean loss: 0.435881\n",
            "accuracy: 0.861979\n",
            "----1-----\n",
            "mean loss: 0.489323\n",
            "accuracy: 0.847168\n",
            "----2-----\n",
            "mean loss: 0.532302\n",
            "accuracy: 0.832031\n",
            "----3-----\n",
            "mean loss: 0.537976\n",
            "accuracy: 0.828613\n",
            "----4-----\n",
            "mean loss: 0.560051\n",
            "accuracy: 0.823242\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.480601\n",
            "eval accuracy: 0.851974\n",
            "eval avg class acc: 0.787733\n",
            "**** EPOCH 016 ****\n",
            "----0-----\n",
            "mean loss: 0.532287\n",
            "accuracy: 0.833984\n",
            "----1-----\n",
            "mean loss: 0.503567\n",
            "accuracy: 0.845215\n",
            "----2-----\n",
            "mean loss: 0.543015\n",
            "accuracy: 0.831055\n",
            "----3-----\n",
            "mean loss: 0.504344\n",
            "accuracy: 0.838542\n",
            "----4-----\n",
            "mean loss: 0.521924\n",
            "accuracy: 0.841309\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.470363\n",
            "eval accuracy: 0.849918\n",
            "eval avg class acc: 0.776932\n",
            "**** EPOCH 017 ****\n",
            "----0-----\n",
            "mean loss: 0.474481\n",
            "accuracy: 0.854167\n",
            "----1-----\n",
            "mean loss: 0.507947\n",
            "accuracy: 0.840332\n",
            "----2-----\n",
            "mean loss: 0.498416\n",
            "accuracy: 0.845703\n",
            "----3-----\n",
            "mean loss: 0.516921\n",
            "accuracy: 0.836914\n",
            "----4-----\n",
            "mean loss: 0.515951\n",
            "accuracy: 0.839844\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.489433\n",
            "eval accuracy: 0.852385\n",
            "eval avg class acc: 0.800069\n",
            "**** EPOCH 018 ****\n",
            "----0-----\n",
            "mean loss: 0.457074\n",
            "accuracy: 0.846354\n",
            "----1-----\n",
            "mean loss: 0.479835\n",
            "accuracy: 0.851562\n",
            "----2-----\n",
            "mean loss: 0.499279\n",
            "accuracy: 0.843262\n",
            "----3-----\n",
            "mean loss: 0.513726\n",
            "accuracy: 0.834961\n",
            "----4-----\n",
            "mean loss: 0.508190\n",
            "accuracy: 0.845703\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.477934\n",
            "eval accuracy: 0.861020\n",
            "eval avg class acc: 0.799524\n",
            "**** EPOCH 019 ****\n",
            "----0-----\n",
            "mean loss: 0.512376\n",
            "accuracy: 0.835449\n",
            "----1-----\n",
            "mean loss: 0.493031\n",
            "accuracy: 0.854492\n",
            "----2-----\n",
            "mean loss: 0.502822\n",
            "accuracy: 0.847656\n",
            "----3-----\n",
            "mean loss: 0.441730\n",
            "accuracy: 0.863932\n",
            "----4-----\n",
            "mean loss: 0.500696\n",
            "accuracy: 0.840332\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.455747\n",
            "eval accuracy: 0.865954\n",
            "eval avg class acc: 0.806826\n",
            "**** EPOCH 020 ****\n",
            "----0-----\n",
            "mean loss: 0.491340\n",
            "accuracy: 0.854980\n",
            "----1-----\n",
            "mean loss: 0.465489\n",
            "accuracy: 0.850098\n",
            "----2-----\n",
            "mean loss: 0.442593\n",
            "accuracy: 0.852865\n",
            "----3-----\n",
            "mean loss: 0.465073\n",
            "accuracy: 0.857422\n",
            "----4-----\n",
            "mean loss: 0.474694\n",
            "accuracy: 0.851074\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.451650\n",
            "eval accuracy: 0.868010\n",
            "eval avg class acc: 0.815360\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 021 ****\n",
            "----0-----\n",
            "mean loss: 0.425443\n",
            "accuracy: 0.863770\n",
            "----1-----\n",
            "mean loss: 0.390848\n",
            "accuracy: 0.877604\n",
            "----2-----\n",
            "mean loss: 0.432259\n",
            "accuracy: 0.861816\n",
            "----3-----\n",
            "mean loss: 0.434794\n",
            "accuracy: 0.872070\n",
            "----4-----\n",
            "mean loss: 0.454323\n",
            "accuracy: 0.855469\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.412705\n",
            "eval accuracy: 0.881168\n",
            "eval avg class acc: 0.830241\n",
            "**** EPOCH 022 ****\n",
            "----0-----\n",
            "mean loss: 0.418040\n",
            "accuracy: 0.869629\n",
            "----1-----\n",
            "mean loss: 0.387299\n",
            "accuracy: 0.874349\n",
            "----2-----\n",
            "mean loss: 0.387864\n",
            "accuracy: 0.878418\n",
            "----3-----\n",
            "mean loss: 0.434144\n",
            "accuracy: 0.853516\n",
            "----4-----\n",
            "mean loss: 0.429931\n",
            "accuracy: 0.862793\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.448440\n",
            "eval accuracy: 0.858964\n",
            "eval avg class acc: 0.812246\n",
            "**** EPOCH 023 ****\n",
            "----0-----\n",
            "mean loss: 0.376980\n",
            "accuracy: 0.875977\n",
            "----1-----\n",
            "mean loss: 0.445959\n",
            "accuracy: 0.856934\n",
            "----2-----\n",
            "mean loss: 0.418351\n",
            "accuracy: 0.856934\n",
            "----3-----\n",
            "mean loss: 0.401729\n",
            "accuracy: 0.881348\n",
            "----4-----\n",
            "mean loss: 0.395630\n",
            "accuracy: 0.870443\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.418267\n",
            "eval accuracy: 0.876234\n",
            "eval avg class acc: 0.833604\n",
            "**** EPOCH 024 ****\n",
            "----0-----\n",
            "mean loss: 0.415060\n",
            "accuracy: 0.866699\n",
            "----1-----\n",
            "mean loss: 0.377650\n",
            "accuracy: 0.870443\n",
            "----2-----\n",
            "mean loss: 0.385923\n",
            "accuracy: 0.881836\n",
            "----3-----\n",
            "mean loss: 0.391681\n",
            "accuracy: 0.868652\n",
            "----4-----\n",
            "mean loss: 0.415192\n",
            "accuracy: 0.856934\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.403114\n",
            "eval accuracy: 0.876645\n",
            "eval avg class acc: 0.830326\n",
            "**** EPOCH 025 ****\n",
            "----0-----\n",
            "mean loss: 0.396213\n",
            "accuracy: 0.875488\n",
            "----1-----\n",
            "mean loss: 0.390006\n",
            "accuracy: 0.872070\n",
            "----2-----\n",
            "mean loss: 0.375496\n",
            "accuracy: 0.883464\n",
            "----3-----\n",
            "mean loss: 0.390453\n",
            "accuracy: 0.868652\n",
            "----4-----\n",
            "mean loss: 0.384542\n",
            "accuracy: 0.872070\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.397639\n",
            "eval accuracy: 0.881990\n",
            "eval avg class acc: 0.827261\n",
            "**** EPOCH 026 ****\n",
            "----0-----\n",
            "mean loss: 0.391416\n",
            "accuracy: 0.872559\n",
            "----1-----\n",
            "mean loss: 0.380828\n",
            "accuracy: 0.882324\n",
            "----2-----\n",
            "mean loss: 0.368854\n",
            "accuracy: 0.881836\n",
            "----3-----\n",
            "mean loss: 0.375165\n",
            "accuracy: 0.877930\n",
            "----4-----\n",
            "mean loss: 0.391340\n",
            "accuracy: 0.876953\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.418918\n",
            "eval accuracy: 0.872122\n",
            "eval avg class acc: 0.817373\n",
            "**** EPOCH 027 ****\n",
            "----0-----\n",
            "mean loss: 0.377955\n",
            "accuracy: 0.881836\n",
            "----1-----\n",
            "mean loss: 0.388065\n",
            "accuracy: 0.869141\n",
            "----2-----\n",
            "mean loss: 0.428308\n",
            "accuracy: 0.853516\n",
            "----3-----\n",
            "mean loss: 0.367299\n",
            "accuracy: 0.874512\n",
            "----4-----\n",
            "mean loss: 0.374194\n",
            "accuracy: 0.874023\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.428188\n",
            "eval accuracy: 0.864309\n",
            "eval avg class acc: 0.822617\n",
            "**** EPOCH 028 ****\n",
            "----0-----\n",
            "mean loss: 0.374720\n",
            "accuracy: 0.878906\n",
            "----1-----\n",
            "mean loss: 0.353775\n",
            "accuracy: 0.883301\n",
            "----2-----\n",
            "mean loss: 0.395868\n",
            "accuracy: 0.882324\n",
            "----3-----\n",
            "mean loss: 0.397636\n",
            "accuracy: 0.878255\n",
            "----4-----\n",
            "mean loss: 0.369536\n",
            "accuracy: 0.883301\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.406968\n",
            "eval accuracy: 0.871299\n",
            "eval avg class acc: 0.818780\n",
            "**** EPOCH 029 ****\n",
            "----0-----\n",
            "mean loss: 0.363558\n",
            "accuracy: 0.883301\n",
            "----1-----\n",
            "mean loss: 0.368059\n",
            "accuracy: 0.878906\n",
            "----2-----\n",
            "mean loss: 0.366791\n",
            "accuracy: 0.876953\n",
            "----3-----\n",
            "mean loss: 0.379182\n",
            "accuracy: 0.872070\n",
            "----4-----\n",
            "mean loss: 0.371147\n",
            "accuracy: 0.878418\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.414005\n",
            "eval accuracy: 0.877878\n",
            "eval avg class acc: 0.831381\n",
            "**** EPOCH 030 ****\n",
            "----0-----\n",
            "mean loss: 0.359298\n",
            "accuracy: 0.881348\n",
            "----1-----\n",
            "mean loss: 0.341224\n",
            "accuracy: 0.886719\n",
            "----2-----\n",
            "mean loss: 0.355759\n",
            "accuracy: 0.890625\n",
            "----3-----\n",
            "mean loss: 0.395014\n",
            "accuracy: 0.874512\n",
            "----4-----\n",
            "mean loss: 0.361202\n",
            "accuracy: 0.882812\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.412799\n",
            "eval accuracy: 0.868832\n",
            "eval avg class acc: 0.833952\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 031 ****\n",
            "----0-----\n",
            "mean loss: 0.343538\n",
            "accuracy: 0.885417\n",
            "----1-----\n",
            "mean loss: 0.385753\n",
            "accuracy: 0.874023\n",
            "----2-----\n",
            "mean loss: 0.359785\n",
            "accuracy: 0.883789\n",
            "----3-----\n",
            "mean loss: 0.377979\n",
            "accuracy: 0.886230\n",
            "----4-----\n",
            "mean loss: 0.377531\n",
            "accuracy: 0.879883\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.404755\n",
            "eval accuracy: 0.873766\n",
            "eval avg class acc: 0.822122\n",
            "**** EPOCH 032 ****\n",
            "----0-----\n",
            "mean loss: 0.350236\n",
            "accuracy: 0.887207\n",
            "----1-----\n",
            "mean loss: 0.342546\n",
            "accuracy: 0.886230\n",
            "----2-----\n",
            "mean loss: 0.345796\n",
            "accuracy: 0.882161\n",
            "----3-----\n",
            "mean loss: 0.378812\n",
            "accuracy: 0.869629\n",
            "----4-----\n",
            "mean loss: 0.369105\n",
            "accuracy: 0.880371\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.448882\n",
            "eval accuracy: 0.867599\n",
            "eval avg class acc: 0.823443\n",
            "**** EPOCH 033 ****\n",
            "----0-----\n",
            "mean loss: 0.332401\n",
            "accuracy: 0.894531\n",
            "----1-----\n",
            "mean loss: 0.349816\n",
            "accuracy: 0.880371\n",
            "----2-----\n",
            "mean loss: 0.352101\n",
            "accuracy: 0.883301\n",
            "----3-----\n",
            "mean loss: 0.345179\n",
            "accuracy: 0.889323\n",
            "----4-----\n",
            "mean loss: 0.341388\n",
            "accuracy: 0.898438\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.416871\n",
            "eval accuracy: 0.870066\n",
            "eval avg class acc: 0.814869\n",
            "**** EPOCH 034 ****\n",
            "----0-----\n",
            "mean loss: 0.349257\n",
            "accuracy: 0.882324\n",
            "----1-----\n",
            "mean loss: 0.352295\n",
            "accuracy: 0.883301\n",
            "----2-----\n",
            "mean loss: 0.363610\n",
            "accuracy: 0.877441\n",
            "----3-----\n",
            "mean loss: 0.356095\n",
            "accuracy: 0.886230\n",
            "----4-----\n",
            "mean loss: 0.337105\n",
            "accuracy: 0.884115\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.417319\n",
            "eval accuracy: 0.877878\n",
            "eval avg class acc: 0.830601\n",
            "**** EPOCH 035 ****\n",
            "----0-----\n",
            "mean loss: 0.302418\n",
            "accuracy: 0.904297\n",
            "----1-----\n",
            "mean loss: 0.337409\n",
            "accuracy: 0.887207\n",
            "----2-----\n",
            "mean loss: 0.360710\n",
            "accuracy: 0.876953\n",
            "----3-----\n",
            "mean loss: 0.364637\n",
            "accuracy: 0.880371\n",
            "----4-----\n",
            "mean loss: 0.381842\n",
            "accuracy: 0.874512\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.404288\n",
            "eval accuracy: 0.874178\n",
            "eval avg class acc: 0.827002\n",
            "**** EPOCH 036 ****\n",
            "----0-----\n",
            "mean loss: 0.348154\n",
            "accuracy: 0.881348\n",
            "----1-----\n",
            "mean loss: 0.333553\n",
            "accuracy: 0.888184\n",
            "----2-----\n",
            "mean loss: 0.362371\n",
            "accuracy: 0.876953\n",
            "----3-----\n",
            "mean loss: 0.343766\n",
            "accuracy: 0.888672\n",
            "----4-----\n",
            "mean loss: 0.340501\n",
            "accuracy: 0.888672\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.411204\n",
            "eval accuracy: 0.878701\n",
            "eval avg class acc: 0.832333\n",
            "**** EPOCH 037 ****\n",
            "----0-----\n",
            "mean loss: 0.310990\n",
            "accuracy: 0.891276\n",
            "----1-----\n",
            "mean loss: 0.335683\n",
            "accuracy: 0.890625\n",
            "----2-----\n",
            "mean loss: 0.314522\n",
            "accuracy: 0.898926\n",
            "----3-----\n",
            "mean loss: 0.318522\n",
            "accuracy: 0.897949\n",
            "----4-----\n",
            "mean loss: 0.351386\n",
            "accuracy: 0.889648\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.404033\n",
            "eval accuracy: 0.884868\n",
            "eval avg class acc: 0.843606\n",
            "**** EPOCH 038 ****\n",
            "----0-----\n",
            "mean loss: 0.342625\n",
            "accuracy: 0.887207\n",
            "----1-----\n",
            "mean loss: 0.322830\n",
            "accuracy: 0.899414\n",
            "----2-----\n",
            "mean loss: 0.327042\n",
            "accuracy: 0.892090\n",
            "----3-----\n",
            "mean loss: 0.323937\n",
            "accuracy: 0.903320\n",
            "----4-----\n",
            "mean loss: 0.312181\n",
            "accuracy: 0.895182\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.420549\n",
            "eval accuracy: 0.883635\n",
            "eval avg class acc: 0.839736\n",
            "**** EPOCH 039 ****\n",
            "----0-----\n",
            "mean loss: 0.339094\n",
            "accuracy: 0.890137\n",
            "----1-----\n",
            "mean loss: 0.338224\n",
            "accuracy: 0.892578\n",
            "----2-----\n",
            "mean loss: 0.304861\n",
            "accuracy: 0.897135\n",
            "----3-----\n",
            "mean loss: 0.338868\n",
            "accuracy: 0.889648\n",
            "----4-----\n",
            "mean loss: 0.333465\n",
            "accuracy: 0.884277\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.406895\n",
            "eval accuracy: 0.877878\n",
            "eval avg class acc: 0.834173\n",
            "**** EPOCH 040 ****\n",
            "----0-----\n",
            "mean loss: 0.317981\n",
            "accuracy: 0.904297\n",
            "----1-----\n",
            "mean loss: 0.323554\n",
            "accuracy: 0.892578\n",
            "----2-----\n",
            "mean loss: 0.329529\n",
            "accuracy: 0.892090\n",
            "----3-----\n",
            "mean loss: 0.317551\n",
            "accuracy: 0.890625\n",
            "----4-----\n",
            "mean loss: 0.316775\n",
            "accuracy: 0.894043\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.395317\n",
            "eval accuracy: 0.885691\n",
            "eval avg class acc: 0.844310\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 041 ****\n",
            "----0-----\n",
            "mean loss: 0.317698\n",
            "accuracy: 0.898438\n",
            "----1-----\n",
            "mean loss: 0.312868\n",
            "accuracy: 0.896484\n",
            "----2-----\n",
            "mean loss: 0.291593\n",
            "accuracy: 0.897949\n",
            "----3-----\n",
            "mean loss: 0.290335\n",
            "accuracy: 0.906738\n",
            "----4-----\n",
            "mean loss: 0.308851\n",
            "accuracy: 0.894043\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.386261\n",
            "eval accuracy: 0.878289\n",
            "eval avg class acc: 0.841140\n",
            "**** EPOCH 042 ****\n",
            "----0-----\n",
            "mean loss: 0.278551\n",
            "accuracy: 0.904785\n",
            "----1-----\n",
            "mean loss: 0.282981\n",
            "accuracy: 0.901855\n",
            "----2-----\n",
            "mean loss: 0.295082\n",
            "accuracy: 0.903320\n",
            "----3-----\n",
            "mean loss: 0.288153\n",
            "accuracy: 0.906250\n",
            "----4-----\n",
            "mean loss: 0.283779\n",
            "accuracy: 0.904297\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.368972\n",
            "eval accuracy: 0.891859\n",
            "eval avg class acc: 0.854087\n",
            "**** EPOCH 043 ****\n",
            "----0-----\n",
            "mean loss: 0.242834\n",
            "accuracy: 0.918945\n",
            "----1-----\n",
            "mean loss: 0.253720\n",
            "accuracy: 0.915039\n",
            "----2-----\n",
            "mean loss: 0.272244\n",
            "accuracy: 0.911621\n",
            "----3-----\n",
            "mean loss: 0.270362\n",
            "accuracy: 0.897461\n",
            "----4-----\n",
            "mean loss: 0.273689\n",
            "accuracy: 0.909505\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.416150\n",
            "eval accuracy: 0.874589\n",
            "eval avg class acc: 0.834566\n",
            "**** EPOCH 044 ****\n",
            "----0-----\n",
            "mean loss: 0.298188\n",
            "accuracy: 0.893066\n",
            "----1-----\n",
            "mean loss: 0.274714\n",
            "accuracy: 0.910645\n",
            "----2-----\n",
            "mean loss: 0.271130\n",
            "accuracy: 0.899089\n",
            "----3-----\n",
            "mean loss: 0.294813\n",
            "accuracy: 0.905762\n",
            "----4-----\n",
            "mean loss: 0.275684\n",
            "accuracy: 0.904785\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.387040\n",
            "eval accuracy: 0.881579\n",
            "eval avg class acc: 0.841325\n",
            "**** EPOCH 045 ****\n",
            "----0-----\n",
            "mean loss: 0.254187\n",
            "accuracy: 0.910645\n",
            "----1-----\n",
            "mean loss: 0.252842\n",
            "accuracy: 0.916992\n",
            "----2-----\n",
            "mean loss: 0.296877\n",
            "accuracy: 0.903320\n",
            "----3-----\n",
            "mean loss: 0.260758\n",
            "accuracy: 0.914714\n",
            "----4-----\n",
            "mean loss: 0.289074\n",
            "accuracy: 0.902832\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.390933\n",
            "eval accuracy: 0.887336\n",
            "eval avg class acc: 0.852955\n",
            "**** EPOCH 046 ****\n",
            "----0-----\n",
            "mean loss: 0.243564\n",
            "accuracy: 0.921387\n",
            "----1-----\n",
            "mean loss: 0.258342\n",
            "accuracy: 0.913574\n",
            "----2-----\n",
            "mean loss: 0.294258\n",
            "accuracy: 0.902344\n",
            "----3-----\n",
            "mean loss: 0.296213\n",
            "accuracy: 0.908691\n",
            "----4-----\n",
            "mean loss: 0.286031\n",
            "accuracy: 0.898438\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.401923\n",
            "eval accuracy: 0.883635\n",
            "eval avg class acc: 0.848637\n",
            "**** EPOCH 047 ****\n",
            "----0-----\n",
            "mean loss: 0.259613\n",
            "accuracy: 0.910156\n",
            "----1-----\n",
            "mean loss: 0.284155\n",
            "accuracy: 0.906738\n",
            "----2-----\n",
            "mean loss: 0.295409\n",
            "accuracy: 0.898438\n",
            "----3-----\n",
            "mean loss: 0.258570\n",
            "accuracy: 0.910807\n",
            "----4-----\n",
            "mean loss: 0.282830\n",
            "accuracy: 0.907715\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.393638\n",
            "eval accuracy: 0.885280\n",
            "eval avg class acc: 0.847441\n",
            "**** EPOCH 048 ****\n",
            "----0-----\n",
            "mean loss: 0.257833\n",
            "accuracy: 0.915039\n",
            "----1-----\n",
            "mean loss: 0.261534\n",
            "accuracy: 0.916667\n",
            "----2-----\n",
            "mean loss: 0.276088\n",
            "accuracy: 0.908203\n",
            "----3-----\n",
            "mean loss: 0.260466\n",
            "accuracy: 0.913086\n",
            "----4-----\n",
            "mean loss: 0.273490\n",
            "accuracy: 0.904785\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.407229\n",
            "eval accuracy: 0.889391\n",
            "eval avg class acc: 0.849275\n",
            "**** EPOCH 049 ****\n",
            "----0-----\n",
            "mean loss: 0.261417\n",
            "accuracy: 0.913086\n",
            "----1-----\n",
            "mean loss: 0.243990\n",
            "accuracy: 0.918945\n",
            "----2-----\n",
            "mean loss: 0.265238\n",
            "accuracy: 0.919434\n",
            "----3-----\n",
            "mean loss: 0.245595\n",
            "accuracy: 0.912109\n",
            "----4-----\n",
            "mean loss: 0.263427\n",
            "accuracy: 0.905599\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.391159\n",
            "eval accuracy: 0.889391\n",
            "eval avg class acc: 0.855478\n",
            "**** EPOCH 050 ****\n",
            "----0-----\n",
            "mean loss: 0.266127\n",
            "accuracy: 0.906738\n",
            "----1-----\n",
            "mean loss: 0.268771\n",
            "accuracy: 0.916016\n",
            "----2-----\n",
            "mean loss: 0.270275\n",
            "accuracy: 0.912760\n",
            "----3-----\n",
            "mean loss: 0.247770\n",
            "accuracy: 0.921387\n",
            "----4-----\n",
            "mean loss: 0.251723\n",
            "accuracy: 0.913086\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.395520\n",
            "eval accuracy: 0.886924\n",
            "eval avg class acc: 0.837004\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 051 ****\n",
            "----0-----\n",
            "mean loss: 0.256609\n",
            "accuracy: 0.912109\n",
            "----1-----\n",
            "mean loss: 0.256972\n",
            "accuracy: 0.916016\n",
            "----2-----\n",
            "mean loss: 0.266266\n",
            "accuracy: 0.906738\n",
            "----3-----\n",
            "mean loss: 0.248000\n",
            "accuracy: 0.917318\n",
            "----4-----\n",
            "mean loss: 0.268092\n",
            "accuracy: 0.909180\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.401654\n",
            "eval accuracy: 0.884457\n",
            "eval avg class acc: 0.841304\n",
            "**** EPOCH 052 ****\n",
            "----0-----\n",
            "mean loss: 0.246942\n",
            "accuracy: 0.915527\n",
            "----1-----\n",
            "mean loss: 0.243694\n",
            "accuracy: 0.918620\n",
            "----2-----\n",
            "mean loss: 0.251897\n",
            "accuracy: 0.912598\n",
            "----3-----\n",
            "mean loss: 0.271797\n",
            "accuracy: 0.913086\n",
            "----4-----\n",
            "mean loss: 0.272077\n",
            "accuracy: 0.910645\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.401720\n",
            "eval accuracy: 0.886924\n",
            "eval avg class acc: 0.837664\n",
            "**** EPOCH 053 ****\n",
            "----0-----\n",
            "mean loss: 0.253554\n",
            "accuracy: 0.915527\n",
            "----1-----\n",
            "mean loss: 0.264937\n",
            "accuracy: 0.911621\n",
            "----2-----\n",
            "mean loss: 0.249156\n",
            "accuracy: 0.911621\n",
            "----3-----\n",
            "mean loss: 0.259985\n",
            "accuracy: 0.917969\n",
            "----4-----\n",
            "mean loss: 0.234281\n",
            "accuracy: 0.919922\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.373224\n",
            "eval accuracy: 0.887336\n",
            "eval avg class acc: 0.846721\n",
            "**** EPOCH 054 ****\n",
            "----0-----\n",
            "mean loss: 0.241670\n",
            "accuracy: 0.914062\n",
            "----1-----\n",
            "mean loss: 0.241010\n",
            "accuracy: 0.919922\n",
            "----2-----\n",
            "mean loss: 0.285933\n",
            "accuracy: 0.903809\n",
            "----3-----\n",
            "mean loss: 0.266500\n",
            "accuracy: 0.918945\n",
            "----4-----\n",
            "mean loss: 0.258838\n",
            "accuracy: 0.914551\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.392272\n",
            "eval accuracy: 0.888980\n",
            "eval avg class acc: 0.834784\n",
            "**** EPOCH 055 ****\n",
            "----0-----\n",
            "mean loss: 0.243021\n",
            "accuracy: 0.917969\n",
            "----1-----\n",
            "mean loss: 0.255576\n",
            "accuracy: 0.920410\n",
            "----2-----\n",
            "mean loss: 0.236802\n",
            "accuracy: 0.916016\n",
            "----3-----\n",
            "mean loss: 0.255391\n",
            "accuracy: 0.916504\n",
            "----4-----\n",
            "mean loss: 0.255461\n",
            "accuracy: 0.909668\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.395103\n",
            "eval accuracy: 0.891447\n",
            "eval avg class acc: 0.847015\n",
            "**** EPOCH 056 ****\n",
            "----0-----\n",
            "mean loss: 0.227962\n",
            "accuracy: 0.925781\n",
            "----1-----\n",
            "mean loss: 0.249573\n",
            "accuracy: 0.919434\n",
            "----2-----\n",
            "mean loss: 0.268247\n",
            "accuracy: 0.905762\n",
            "----3-----\n",
            "mean loss: 0.233017\n",
            "accuracy: 0.919922\n",
            "----4-----\n",
            "mean loss: 0.261858\n",
            "accuracy: 0.908691\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.392585\n",
            "eval accuracy: 0.881579\n",
            "eval avg class acc: 0.838067\n",
            "**** EPOCH 057 ****\n",
            "----0-----\n",
            "mean loss: 0.221090\n",
            "accuracy: 0.928223\n",
            "----1-----\n",
            "mean loss: 0.237265\n",
            "accuracy: 0.918457\n",
            "----2-----\n",
            "mean loss: 0.249319\n",
            "accuracy: 0.914062\n",
            "----3-----\n",
            "mean loss: 0.254926\n",
            "accuracy: 0.920410\n",
            "----4-----\n",
            "mean loss: 0.244164\n",
            "accuracy: 0.912760\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.401271\n",
            "eval accuracy: 0.888980\n",
            "eval avg class acc: 0.856343\n",
            "**** EPOCH 058 ****\n",
            "----0-----\n",
            "mean loss: 0.225672\n",
            "accuracy: 0.920410\n",
            "----1-----\n",
            "mean loss: 0.254534\n",
            "accuracy: 0.916504\n",
            "----2-----\n",
            "mean loss: 0.224587\n",
            "accuracy: 0.929688\n",
            "----3-----\n",
            "mean loss: 0.219853\n",
            "accuracy: 0.923828\n",
            "----4-----\n",
            "mean loss: 0.256839\n",
            "accuracy: 0.914551\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.393312\n",
            "eval accuracy: 0.885280\n",
            "eval avg class acc: 0.844825\n",
            "**** EPOCH 059 ****\n",
            "----0-----\n",
            "mean loss: 0.223403\n",
            "accuracy: 0.920898\n",
            "----1-----\n",
            "mean loss: 0.230998\n",
            "accuracy: 0.924805\n",
            "----2-----\n",
            "mean loss: 0.238419\n",
            "accuracy: 0.916016\n",
            "----3-----\n",
            "mean loss: 0.240195\n",
            "accuracy: 0.919922\n",
            "----4-----\n",
            "mean loss: 0.254433\n",
            "accuracy: 0.912109\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.394304\n",
            "eval accuracy: 0.887747\n",
            "eval avg class acc: 0.850947\n",
            "**** EPOCH 060 ****\n",
            "----0-----\n",
            "mean loss: 0.233555\n",
            "accuracy: 0.915527\n",
            "----1-----\n",
            "mean loss: 0.214560\n",
            "accuracy: 0.921875\n",
            "----2-----\n",
            "mean loss: 0.246785\n",
            "accuracy: 0.922852\n",
            "----3-----\n",
            "mean loss: 0.243626\n",
            "accuracy: 0.919434\n",
            "----4-----\n",
            "mean loss: 0.253433\n",
            "accuracy: 0.914551\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.363623\n",
            "eval accuracy: 0.888980\n",
            "eval avg class acc: 0.840789\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 061 ****\n",
            "----0-----\n",
            "mean loss: 0.225739\n",
            "accuracy: 0.925781\n",
            "----1-----\n",
            "mean loss: 0.237456\n",
            "accuracy: 0.920410\n",
            "----2-----\n",
            "mean loss: 0.249193\n",
            "accuracy: 0.917969\n",
            "----3-----\n",
            "mean loss: 0.242895\n",
            "accuracy: 0.911458\n",
            "----4-----\n",
            "mean loss: 0.218873\n",
            "accuracy: 0.926758\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.378170\n",
            "eval accuracy: 0.891036\n",
            "eval avg class acc: 0.851303\n",
            "**** EPOCH 062 ****\n",
            "----0-----\n",
            "mean loss: 0.218399\n",
            "accuracy: 0.928223\n",
            "----1-----\n",
            "mean loss: 0.217814\n",
            "accuracy: 0.929688\n",
            "----2-----\n",
            "mean loss: 0.207070\n",
            "accuracy: 0.929688\n",
            "----3-----\n",
            "mean loss: 0.239330\n",
            "accuracy: 0.918457\n",
            "----4-----\n",
            "mean loss: 0.199880\n",
            "accuracy: 0.930339\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.364430\n",
            "eval accuracy: 0.900082\n",
            "eval avg class acc: 0.857521\n",
            "**** EPOCH 063 ****\n",
            "----0-----\n",
            "mean loss: 0.213625\n",
            "accuracy: 0.925293\n",
            "----1-----\n",
            "mean loss: 0.198724\n",
            "accuracy: 0.934570\n",
            "----2-----\n",
            "mean loss: 0.209767\n",
            "accuracy: 0.920573\n",
            "----3-----\n",
            "mean loss: 0.204540\n",
            "accuracy: 0.927246\n",
            "----4-----\n",
            "mean loss: 0.213099\n",
            "accuracy: 0.921387\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.392696\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.851023\n",
            "**** EPOCH 064 ****\n",
            "----0-----\n",
            "mean loss: 0.218724\n",
            "accuracy: 0.926270\n",
            "----1-----\n",
            "mean loss: 0.216829\n",
            "accuracy: 0.924316\n",
            "----2-----\n",
            "mean loss: 0.212675\n",
            "accuracy: 0.929688\n",
            "----3-----\n",
            "mean loss: 0.208148\n",
            "accuracy: 0.930176\n",
            "----4-----\n",
            "mean loss: 0.238065\n",
            "accuracy: 0.927734\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.386327\n",
            "eval accuracy: 0.895148\n",
            "eval avg class acc: 0.851548\n",
            "**** EPOCH 065 ****\n",
            "----0-----\n",
            "mean loss: 0.198138\n",
            "accuracy: 0.939941\n",
            "----1-----\n",
            "mean loss: 0.206529\n",
            "accuracy: 0.933594\n",
            "----2-----\n",
            "mean loss: 0.222339\n",
            "accuracy: 0.924316\n",
            "----3-----\n",
            "mean loss: 0.219740\n",
            "accuracy: 0.923340\n",
            "----4-----\n",
            "mean loss: 0.212012\n",
            "accuracy: 0.930176\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.402005\n",
            "eval accuracy: 0.893914\n",
            "eval avg class acc: 0.850270\n",
            "**** EPOCH 066 ****\n",
            "----0-----\n",
            "mean loss: 0.198187\n",
            "accuracy: 0.927734\n",
            "----1-----\n",
            "mean loss: 0.206265\n",
            "accuracy: 0.928711\n",
            "----2-----\n",
            "mean loss: 0.211789\n",
            "accuracy: 0.928223\n",
            "----3-----\n",
            "mean loss: 0.201172\n",
            "accuracy: 0.933594\n",
            "----4-----\n",
            "mean loss: 0.209715\n",
            "accuracy: 0.927734\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.389516\n",
            "eval accuracy: 0.892681\n",
            "eval avg class acc: 0.850263\n",
            "**** EPOCH 067 ****\n",
            "----0-----\n",
            "mean loss: 0.199523\n",
            "accuracy: 0.933594\n",
            "----1-----\n",
            "mean loss: 0.213572\n",
            "accuracy: 0.933594\n",
            "----2-----\n",
            "mean loss: 0.207068\n",
            "accuracy: 0.930176\n",
            "----3-----\n",
            "mean loss: 0.191486\n",
            "accuracy: 0.934896\n",
            "----4-----\n",
            "mean loss: 0.205474\n",
            "accuracy: 0.924316\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.401838\n",
            "eval accuracy: 0.889803\n",
            "eval avg class acc: 0.844098\n",
            "**** EPOCH 068 ****\n",
            "----0-----\n",
            "mean loss: 0.184073\n",
            "accuracy: 0.932943\n",
            "----1-----\n",
            "mean loss: 0.183899\n",
            "accuracy: 0.938477\n",
            "----2-----\n",
            "mean loss: 0.185737\n",
            "accuracy: 0.935059\n",
            "----3-----\n",
            "mean loss: 0.207478\n",
            "accuracy: 0.928223\n",
            "----4-----\n",
            "mean loss: 0.220261\n",
            "accuracy: 0.923340\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.409058\n",
            "eval accuracy: 0.881990\n",
            "eval avg class acc: 0.848978\n",
            "**** EPOCH 069 ****\n",
            "----0-----\n",
            "mean loss: 0.207758\n",
            "accuracy: 0.933594\n",
            "----1-----\n",
            "mean loss: 0.184517\n",
            "accuracy: 0.937500\n",
            "----2-----\n",
            "mean loss: 0.189892\n",
            "accuracy: 0.929199\n",
            "----3-----\n",
            "mean loss: 0.210868\n",
            "accuracy: 0.927734\n",
            "----4-----\n",
            "mean loss: 0.225501\n",
            "accuracy: 0.928223\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.397768\n",
            "eval accuracy: 0.888980\n",
            "eval avg class acc: 0.848479\n",
            "**** EPOCH 070 ****\n",
            "----0-----\n",
            "mean loss: 0.207339\n",
            "accuracy: 0.929688\n",
            "----1-----\n",
            "mean loss: 0.219608\n",
            "accuracy: 0.929688\n",
            "----2-----\n",
            "mean loss: 0.202649\n",
            "accuracy: 0.928385\n",
            "----3-----\n",
            "mean loss: 0.213941\n",
            "accuracy: 0.931152\n",
            "----4-----\n",
            "mean loss: 0.203563\n",
            "accuracy: 0.931152\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.404313\n",
            "eval accuracy: 0.889391\n",
            "eval avg class acc: 0.852311\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 071 ****\n",
            "----0-----\n",
            "mean loss: 0.205561\n",
            "accuracy: 0.934082\n",
            "----1-----\n",
            "mean loss: 0.213787\n",
            "accuracy: 0.919434\n",
            "----2-----\n",
            "mean loss: 0.200425\n",
            "accuracy: 0.932617\n",
            "----3-----\n",
            "mean loss: 0.177507\n",
            "accuracy: 0.936849\n",
            "----4-----\n",
            "mean loss: 0.201471\n",
            "accuracy: 0.930176\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.397154\n",
            "eval accuracy: 0.892681\n",
            "eval avg class acc: 0.846661\n",
            "**** EPOCH 072 ****\n",
            "----0-----\n",
            "mean loss: 0.160335\n",
            "accuracy: 0.945312\n",
            "----1-----\n",
            "mean loss: 0.182782\n",
            "accuracy: 0.936198\n",
            "----2-----\n",
            "mean loss: 0.194952\n",
            "accuracy: 0.931152\n",
            "----3-----\n",
            "mean loss: 0.200383\n",
            "accuracy: 0.928223\n",
            "----4-----\n",
            "mean loss: 0.206379\n",
            "accuracy: 0.932617\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.422249\n",
            "eval accuracy: 0.885280\n",
            "eval avg class acc: 0.840070\n",
            "**** EPOCH 073 ****\n",
            "----0-----\n",
            "mean loss: 0.208095\n",
            "accuracy: 0.925293\n",
            "----1-----\n",
            "mean loss: 0.224935\n",
            "accuracy: 0.929036\n",
            "----2-----\n",
            "mean loss: 0.202662\n",
            "accuracy: 0.926270\n",
            "----3-----\n",
            "mean loss: 0.183892\n",
            "accuracy: 0.933594\n",
            "----4-----\n",
            "mean loss: 0.205112\n",
            "accuracy: 0.932129\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.395573\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.853559\n",
            "**** EPOCH 074 ****\n",
            "----0-----\n",
            "mean loss: 0.193750\n",
            "accuracy: 0.932617\n",
            "----1-----\n",
            "mean loss: 0.193943\n",
            "accuracy: 0.928385\n",
            "----2-----\n",
            "mean loss: 0.218683\n",
            "accuracy: 0.929688\n",
            "----3-----\n",
            "mean loss: 0.198434\n",
            "accuracy: 0.931641\n",
            "----4-----\n",
            "mean loss: 0.196928\n",
            "accuracy: 0.933594\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.412108\n",
            "eval accuracy: 0.887747\n",
            "eval avg class acc: 0.845133\n",
            "**** EPOCH 075 ****\n",
            "----0-----\n",
            "mean loss: 0.177976\n",
            "accuracy: 0.937500\n",
            "----1-----\n",
            "mean loss: 0.177406\n",
            "accuracy: 0.933105\n",
            "----2-----\n",
            "mean loss: 0.188978\n",
            "accuracy: 0.941406\n",
            "----3-----\n",
            "mean loss: 0.216940\n",
            "accuracy: 0.932129\n",
            "----4-----\n",
            "mean loss: 0.209519\n",
            "accuracy: 0.924805\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.398284\n",
            "eval accuracy: 0.895559\n",
            "eval avg class acc: 0.860630\n",
            "**** EPOCH 076 ****\n",
            "----0-----\n",
            "mean loss: 0.186093\n",
            "accuracy: 0.936035\n",
            "----1-----\n",
            "mean loss: 0.194820\n",
            "accuracy: 0.930176\n",
            "----2-----\n",
            "mean loss: 0.179895\n",
            "accuracy: 0.938965\n",
            "----3-----\n",
            "mean loss: 0.194335\n",
            "accuracy: 0.928385\n",
            "----4-----\n",
            "mean loss: 0.185202\n",
            "accuracy: 0.942871\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.410462\n",
            "eval accuracy: 0.885280\n",
            "eval avg class acc: 0.837679\n",
            "**** EPOCH 077 ****\n",
            "----0-----\n",
            "mean loss: 0.201869\n",
            "accuracy: 0.931641\n",
            "----1-----\n",
            "mean loss: 0.189879\n",
            "accuracy: 0.929688\n",
            "----2-----\n",
            "mean loss: 0.186479\n",
            "accuracy: 0.934570\n",
            "----3-----\n",
            "mean loss: 0.197461\n",
            "accuracy: 0.934082\n",
            "----4-----\n",
            "mean loss: 0.183284\n",
            "accuracy: 0.940918\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.400579\n",
            "eval accuracy: 0.886102\n",
            "eval avg class acc: 0.840621\n",
            "**** EPOCH 078 ****\n",
            "----0-----\n",
            "mean loss: 0.168303\n",
            "accuracy: 0.939941\n",
            "----1-----\n",
            "mean loss: 0.169374\n",
            "accuracy: 0.944824\n",
            "----2-----\n",
            "mean loss: 0.209067\n",
            "accuracy: 0.931641\n",
            "----3-----\n",
            "mean loss: 0.176037\n",
            "accuracy: 0.937500\n",
            "----4-----\n",
            "mean loss: 0.207133\n",
            "accuracy: 0.927734\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.386727\n",
            "eval accuracy: 0.892270\n",
            "eval avg class acc: 0.853715\n",
            "**** EPOCH 079 ****\n",
            "----0-----\n",
            "mean loss: 0.181354\n",
            "accuracy: 0.937988\n",
            "----1-----\n",
            "mean loss: 0.183126\n",
            "accuracy: 0.934082\n",
            "----2-----\n",
            "mean loss: 0.190123\n",
            "accuracy: 0.933594\n",
            "----3-----\n",
            "mean loss: 0.178608\n",
            "accuracy: 0.936523\n",
            "----4-----\n",
            "mean loss: 0.167387\n",
            "accuracy: 0.947917\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.404856\n",
            "eval accuracy: 0.891447\n",
            "eval avg class acc: 0.852879\n",
            "**** EPOCH 080 ****\n",
            "----0-----\n",
            "mean loss: 0.163653\n",
            "accuracy: 0.947266\n",
            "----1-----\n",
            "mean loss: 0.157088\n",
            "accuracy: 0.944661\n",
            "----2-----\n",
            "mean loss: 0.177176\n",
            "accuracy: 0.936523\n",
            "----3-----\n",
            "mean loss: 0.184258\n",
            "accuracy: 0.934570\n",
            "----4-----\n",
            "mean loss: 0.190468\n",
            "accuracy: 0.938965\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.397738\n",
            "eval accuracy: 0.893092\n",
            "eval avg class acc: 0.840795\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 081 ****\n",
            "----0-----\n",
            "mean loss: 0.181837\n",
            "accuracy: 0.941895\n",
            "----1-----\n",
            "mean loss: 0.168236\n",
            "accuracy: 0.939941\n",
            "----2-----\n",
            "mean loss: 0.191954\n",
            "accuracy: 0.931152\n",
            "----3-----\n",
            "mean loss: 0.210598\n",
            "accuracy: 0.933594\n",
            "----4-----\n",
            "mean loss: 0.161765\n",
            "accuracy: 0.944661\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.425040\n",
            "eval accuracy: 0.888158\n",
            "eval avg class acc: 0.848491\n",
            "**** EPOCH 082 ****\n",
            "----0-----\n",
            "mean loss: 0.175954\n",
            "accuracy: 0.944824\n",
            "----1-----\n",
            "mean loss: 0.180210\n",
            "accuracy: 0.937988\n",
            "----2-----\n",
            "mean loss: 0.168788\n",
            "accuracy: 0.940104\n",
            "----3-----\n",
            "mean loss: 0.175776\n",
            "accuracy: 0.939453\n",
            "----4-----\n",
            "mean loss: 0.174888\n",
            "accuracy: 0.937012\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.409235\n",
            "eval accuracy: 0.889803\n",
            "eval avg class acc: 0.846638\n",
            "**** EPOCH 083 ****\n",
            "----0-----\n",
            "mean loss: 0.159060\n",
            "accuracy: 0.944336\n",
            "----1-----\n",
            "mean loss: 0.172971\n",
            "accuracy: 0.940430\n",
            "----2-----\n",
            "mean loss: 0.179284\n",
            "accuracy: 0.939941\n",
            "----3-----\n",
            "mean loss: 0.171268\n",
            "accuracy: 0.940755\n",
            "----4-----\n",
            "mean loss: 0.168183\n",
            "accuracy: 0.943848\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.409284\n",
            "eval accuracy: 0.893503\n",
            "eval avg class acc: 0.849175\n",
            "**** EPOCH 084 ****\n",
            "----0-----\n",
            "mean loss: 0.153014\n",
            "accuracy: 0.947917\n",
            "----1-----\n",
            "mean loss: 0.155961\n",
            "accuracy: 0.946289\n",
            "----2-----\n",
            "mean loss: 0.161488\n",
            "accuracy: 0.943848\n",
            "----3-----\n",
            "mean loss: 0.169915\n",
            "accuracy: 0.938965\n",
            "----4-----\n",
            "mean loss: 0.178817\n",
            "accuracy: 0.937988\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.419218\n",
            "eval accuracy: 0.889803\n",
            "eval avg class acc: 0.853527\n",
            "**** EPOCH 085 ****\n",
            "----0-----\n",
            "mean loss: 0.143494\n",
            "accuracy: 0.953125\n",
            "----1-----\n",
            "mean loss: 0.166152\n",
            "accuracy: 0.945964\n",
            "----2-----\n",
            "mean loss: 0.156223\n",
            "accuracy: 0.951172\n",
            "----3-----\n",
            "mean loss: 0.165842\n",
            "accuracy: 0.945801\n",
            "----4-----\n",
            "mean loss: 0.159564\n",
            "accuracy: 0.949219\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.443122\n",
            "eval accuracy: 0.885280\n",
            "eval avg class acc: 0.851204\n",
            "**** EPOCH 086 ****\n",
            "----0-----\n",
            "mean loss: 0.168109\n",
            "accuracy: 0.942057\n",
            "----1-----\n",
            "mean loss: 0.166441\n",
            "accuracy: 0.947266\n",
            "----2-----\n",
            "mean loss: 0.171296\n",
            "accuracy: 0.940918\n",
            "----3-----\n",
            "mean loss: 0.167297\n",
            "accuracy: 0.947754\n",
            "----4-----\n",
            "mean loss: 0.149052\n",
            "accuracy: 0.953125\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.403811\n",
            "eval accuracy: 0.898849\n",
            "eval avg class acc: 0.863160\n",
            "**** EPOCH 087 ****\n",
            "----0-----\n",
            "mean loss: 0.132148\n",
            "accuracy: 0.953613\n",
            "----1-----\n",
            "mean loss: 0.152120\n",
            "accuracy: 0.947266\n",
            "----2-----\n",
            "mean loss: 0.160879\n",
            "accuracy: 0.942057\n",
            "----3-----\n",
            "mean loss: 0.151043\n",
            "accuracy: 0.948730\n",
            "----4-----\n",
            "mean loss: 0.141208\n",
            "accuracy: 0.951660\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.390946\n",
            "eval accuracy: 0.898849\n",
            "eval avg class acc: 0.855990\n",
            "**** EPOCH 088 ****\n",
            "----0-----\n",
            "mean loss: 0.157876\n",
            "accuracy: 0.943848\n",
            "----1-----\n",
            "mean loss: 0.154769\n",
            "accuracy: 0.943848\n",
            "----2-----\n",
            "mean loss: 0.153778\n",
            "accuracy: 0.945801\n",
            "----3-----\n",
            "mean loss: 0.166537\n",
            "accuracy: 0.942871\n",
            "----4-----\n",
            "mean loss: 0.162394\n",
            "accuracy: 0.945964\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.405188\n",
            "eval accuracy: 0.888158\n",
            "eval avg class acc: 0.852425\n",
            "**** EPOCH 089 ****\n",
            "----0-----\n",
            "mean loss: 0.140033\n",
            "accuracy: 0.955566\n",
            "----1-----\n",
            "mean loss: 0.149882\n",
            "accuracy: 0.946777\n",
            "----2-----\n",
            "mean loss: 0.147241\n",
            "accuracy: 0.949219\n",
            "----3-----\n",
            "mean loss: 0.159435\n",
            "accuracy: 0.944336\n",
            "----4-----\n",
            "mean loss: 0.147738\n",
            "accuracy: 0.952637\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.409428\n",
            "eval accuracy: 0.895559\n",
            "eval avg class acc: 0.858481\n",
            "**** EPOCH 090 ****\n",
            "----0-----\n",
            "mean loss: 0.133303\n",
            "accuracy: 0.946615\n",
            "----1-----\n",
            "mean loss: 0.143742\n",
            "accuracy: 0.947754\n",
            "----2-----\n",
            "mean loss: 0.157944\n",
            "accuracy: 0.943359\n",
            "----3-----\n",
            "mean loss: 0.171020\n",
            "accuracy: 0.940430\n",
            "----4-----\n",
            "mean loss: 0.149380\n",
            "accuracy: 0.946777\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.414213\n",
            "eval accuracy: 0.888980\n",
            "eval avg class acc: 0.848786\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 091 ****\n",
            "----0-----\n",
            "mean loss: 0.150873\n",
            "accuracy: 0.944661\n",
            "----1-----\n",
            "mean loss: 0.150820\n",
            "accuracy: 0.948242\n",
            "----2-----\n",
            "mean loss: 0.147616\n",
            "accuracy: 0.953125\n",
            "----3-----\n",
            "mean loss: 0.151132\n",
            "accuracy: 0.942871\n",
            "----4-----\n",
            "mean loss: 0.153861\n",
            "accuracy: 0.942871\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.423782\n",
            "eval accuracy: 0.891036\n",
            "eval avg class acc: 0.855177\n",
            "**** EPOCH 092 ****\n",
            "----0-----\n",
            "mean loss: 0.154333\n",
            "accuracy: 0.949219\n",
            "----1-----\n",
            "mean loss: 0.135605\n",
            "accuracy: 0.957031\n",
            "----2-----\n",
            "mean loss: 0.157235\n",
            "accuracy: 0.945312\n",
            "----3-----\n",
            "mean loss: 0.153161\n",
            "accuracy: 0.945312\n",
            "----4-----\n",
            "mean loss: 0.163947\n",
            "accuracy: 0.945312\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.419156\n",
            "eval accuracy: 0.891447\n",
            "eval avg class acc: 0.855002\n",
            "**** EPOCH 093 ****\n",
            "----0-----\n",
            "mean loss: 0.160702\n",
            "accuracy: 0.946289\n",
            "----1-----\n",
            "mean loss: 0.153811\n",
            "accuracy: 0.943848\n",
            "----2-----\n",
            "mean loss: 0.150055\n",
            "accuracy: 0.949707\n",
            "----3-----\n",
            "mean loss: 0.149743\n",
            "accuracy: 0.947266\n",
            "----4-----\n",
            "mean loss: 0.162269\n",
            "accuracy: 0.944661\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.430437\n",
            "eval accuracy: 0.887336\n",
            "eval avg class acc: 0.852357\n",
            "**** EPOCH 094 ****\n",
            "----0-----\n",
            "mean loss: 0.159236\n",
            "accuracy: 0.945801\n",
            "----1-----\n",
            "mean loss: 0.146808\n",
            "accuracy: 0.949219\n",
            "----2-----\n",
            "mean loss: 0.147824\n",
            "accuracy: 0.950684\n",
            "----3-----\n",
            "mean loss: 0.153724\n",
            "accuracy: 0.945801\n",
            "----4-----\n",
            "mean loss: 0.153102\n",
            "accuracy: 0.949219\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.445514\n",
            "eval accuracy: 0.888158\n",
            "eval avg class acc: 0.851682\n",
            "**** EPOCH 095 ****\n",
            "----0-----\n",
            "mean loss: 0.148025\n",
            "accuracy: 0.948730\n",
            "----1-----\n",
            "mean loss: 0.139368\n",
            "accuracy: 0.944824\n",
            "----2-----\n",
            "mean loss: 0.154818\n",
            "accuracy: 0.947266\n",
            "----3-----\n",
            "mean loss: 0.144317\n",
            "accuracy: 0.945964\n",
            "----4-----\n",
            "mean loss: 0.147292\n",
            "accuracy: 0.951172\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.432925\n",
            "eval accuracy: 0.891036\n",
            "eval avg class acc: 0.854896\n",
            "**** EPOCH 096 ****\n",
            "----0-----\n",
            "mean loss: 0.133416\n",
            "accuracy: 0.953613\n",
            "----1-----\n",
            "mean loss: 0.170001\n",
            "accuracy: 0.938477\n",
            "----2-----\n",
            "mean loss: 0.148257\n",
            "accuracy: 0.947266\n",
            "----3-----\n",
            "mean loss: 0.137159\n",
            "accuracy: 0.955729\n",
            "----4-----\n",
            "mean loss: 0.156115\n",
            "accuracy: 0.942871\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.435120\n",
            "eval accuracy: 0.892270\n",
            "eval avg class acc: 0.850920\n",
            "**** EPOCH 097 ****\n",
            "----0-----\n",
            "mean loss: 0.140204\n",
            "accuracy: 0.951172\n",
            "----1-----\n",
            "mean loss: 0.140226\n",
            "accuracy: 0.949870\n",
            "----2-----\n",
            "mean loss: 0.132167\n",
            "accuracy: 0.956055\n",
            "----3-----\n",
            "mean loss: 0.134673\n",
            "accuracy: 0.956055\n",
            "----4-----\n",
            "mean loss: 0.147690\n",
            "accuracy: 0.946289\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.439825\n",
            "eval accuracy: 0.890625\n",
            "eval avg class acc: 0.851303\n",
            "**** EPOCH 098 ****\n",
            "----0-----\n",
            "mean loss: 0.156705\n",
            "accuracy: 0.940430\n",
            "----1-----\n",
            "mean loss: 0.132773\n",
            "accuracy: 0.950684\n",
            "----2-----\n",
            "mean loss: 0.143088\n",
            "accuracy: 0.951172\n",
            "----3-----\n",
            "mean loss: 0.151424\n",
            "accuracy: 0.949219\n",
            "----4-----\n",
            "mean loss: 0.159611\n",
            "accuracy: 0.946615\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.442331\n",
            "eval accuracy: 0.890625\n",
            "eval avg class acc: 0.851579\n",
            "**** EPOCH 099 ****\n",
            "----0-----\n",
            "mean loss: 0.133354\n",
            "accuracy: 0.952637\n",
            "----1-----\n",
            "mean loss: 0.136278\n",
            "accuracy: 0.954102\n",
            "----2-----\n",
            "mean loss: 0.142831\n",
            "accuracy: 0.947266\n",
            "----3-----\n",
            "mean loss: 0.137392\n",
            "accuracy: 0.956055\n",
            "----4-----\n",
            "mean loss: 0.161065\n",
            "accuracy: 0.942057\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.436828\n",
            "eval accuracy: 0.887336\n",
            "eval avg class acc: 0.851180\n",
            "**** EPOCH 100 ****\n",
            "----0-----\n",
            "mean loss: 0.127700\n",
            "accuracy: 0.954590\n",
            "----1-----\n",
            "mean loss: 0.137373\n",
            "accuracy: 0.951823\n",
            "----2-----\n",
            "mean loss: 0.152454\n",
            "accuracy: 0.945312\n",
            "----3-----\n",
            "mean loss: 0.149233\n",
            "accuracy: 0.949707\n",
            "----4-----\n",
            "mean loss: 0.173045\n",
            "accuracy: 0.941895\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.425669\n",
            "eval accuracy: 0.888569\n",
            "eval avg class acc: 0.854894\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 101 ****\n",
            "----0-----\n",
            "mean loss: 0.126631\n",
            "accuracy: 0.955566\n",
            "----1-----\n",
            "mean loss: 0.136899\n",
            "accuracy: 0.956055\n",
            "----2-----\n",
            "mean loss: 0.159292\n",
            "accuracy: 0.940104\n",
            "----3-----\n",
            "mean loss: 0.147060\n",
            "accuracy: 0.950195\n",
            "----4-----\n",
            "mean loss: 0.161333\n",
            "accuracy: 0.949219\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.414381\n",
            "eval accuracy: 0.889803\n",
            "eval avg class acc: 0.853475\n",
            "**** EPOCH 102 ****\n",
            "----0-----\n",
            "mean loss: 0.131546\n",
            "accuracy: 0.953613\n",
            "----1-----\n",
            "mean loss: 0.142426\n",
            "accuracy: 0.953613\n",
            "----2-----\n",
            "mean loss: 0.130011\n",
            "accuracy: 0.956543\n",
            "----3-----\n",
            "mean loss: 0.160567\n",
            "accuracy: 0.947266\n",
            "----4-----\n",
            "mean loss: 0.129441\n",
            "accuracy: 0.954102\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.436050\n",
            "eval accuracy: 0.894737\n",
            "eval avg class acc: 0.858654\n",
            "**** EPOCH 103 ****\n",
            "----0-----\n",
            "mean loss: 0.138691\n",
            "accuracy: 0.951660\n",
            "----1-----\n",
            "mean loss: 0.135818\n",
            "accuracy: 0.955566\n",
            "----2-----\n",
            "mean loss: 0.147653\n",
            "accuracy: 0.949219\n",
            "----3-----\n",
            "mean loss: 0.134723\n",
            "accuracy: 0.952637\n",
            "----4-----\n",
            "mean loss: 0.118021\n",
            "accuracy: 0.959635\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.439290\n",
            "eval accuracy: 0.887747\n",
            "eval avg class acc: 0.849373\n",
            "**** EPOCH 104 ****\n",
            "----0-----\n",
            "mean loss: 0.119618\n",
            "accuracy: 0.957682\n",
            "----1-----\n",
            "mean loss: 0.133597\n",
            "accuracy: 0.953125\n",
            "----2-----\n",
            "mean loss: 0.126092\n",
            "accuracy: 0.958984\n",
            "----3-----\n",
            "mean loss: 0.152651\n",
            "accuracy: 0.947754\n",
            "----4-----\n",
            "mean loss: 0.124284\n",
            "accuracy: 0.955078\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.444903\n",
            "eval accuracy: 0.885691\n",
            "eval avg class acc: 0.854434\n",
            "**** EPOCH 105 ****\n",
            "----0-----\n",
            "mean loss: 0.113005\n",
            "accuracy: 0.958984\n",
            "----1-----\n",
            "mean loss: 0.146787\n",
            "accuracy: 0.950684\n",
            "----2-----\n",
            "mean loss: 0.139531\n",
            "accuracy: 0.946777\n",
            "----3-----\n",
            "mean loss: 0.125802\n",
            "accuracy: 0.952637\n",
            "----4-----\n",
            "mean loss: 0.128992\n",
            "accuracy: 0.954102\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.428975\n",
            "eval accuracy: 0.893914\n",
            "eval avg class acc: 0.857271\n",
            "**** EPOCH 106 ****\n",
            "----0-----\n",
            "mean loss: 0.121867\n",
            "accuracy: 0.958333\n",
            "----1-----\n",
            "mean loss: 0.120942\n",
            "accuracy: 0.958496\n",
            "----2-----\n",
            "mean loss: 0.123925\n",
            "accuracy: 0.958008\n",
            "----3-----\n",
            "mean loss: 0.117147\n",
            "accuracy: 0.959473\n",
            "----4-----\n",
            "mean loss: 0.124320\n",
            "accuracy: 0.952148\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.437204\n",
            "eval accuracy: 0.885280\n",
            "eval avg class acc: 0.843146\n",
            "**** EPOCH 107 ****\n",
            "----0-----\n",
            "mean loss: 0.109001\n",
            "accuracy: 0.962891\n",
            "----1-----\n",
            "mean loss: 0.134656\n",
            "accuracy: 0.953613\n",
            "----2-----\n",
            "mean loss: 0.132935\n",
            "accuracy: 0.954102\n",
            "----3-----\n",
            "mean loss: 0.120348\n",
            "accuracy: 0.958333\n",
            "----4-----\n",
            "mean loss: 0.118337\n",
            "accuracy: 0.955566\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.436124\n",
            "eval accuracy: 0.893503\n",
            "eval avg class acc: 0.849825\n",
            "**** EPOCH 108 ****\n",
            "----0-----\n",
            "mean loss: 0.127216\n",
            "accuracy: 0.951823\n",
            "----1-----\n",
            "mean loss: 0.116003\n",
            "accuracy: 0.960938\n",
            "----2-----\n",
            "mean loss: 0.127852\n",
            "accuracy: 0.959961\n",
            "----3-----\n",
            "mean loss: 0.123459\n",
            "accuracy: 0.955078\n",
            "----4-----\n",
            "mean loss: 0.125780\n",
            "accuracy: 0.958008\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.447150\n",
            "eval accuracy: 0.891859\n",
            "eval avg class acc: 0.855925\n",
            "**** EPOCH 109 ****\n",
            "----0-----\n",
            "mean loss: 0.137695\n",
            "accuracy: 0.949219\n",
            "----1-----\n",
            "mean loss: 0.128884\n",
            "accuracy: 0.958008\n",
            "----2-----\n",
            "mean loss: 0.130910\n",
            "accuracy: 0.954590\n",
            "----3-----\n",
            "mean loss: 0.119043\n",
            "accuracy: 0.960286\n",
            "----4-----\n",
            "mean loss: 0.106711\n",
            "accuracy: 0.963867\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.440571\n",
            "eval accuracy: 0.892270\n",
            "eval avg class acc: 0.856402\n",
            "**** EPOCH 110 ****\n",
            "----0-----\n",
            "mean loss: 0.099399\n",
            "accuracy: 0.960938\n",
            "----1-----\n",
            "mean loss: 0.130186\n",
            "accuracy: 0.958008\n",
            "----2-----\n",
            "mean loss: 0.118665\n",
            "accuracy: 0.960938\n",
            "----3-----\n",
            "mean loss: 0.118630\n",
            "accuracy: 0.964193\n",
            "----4-----\n",
            "mean loss: 0.126666\n",
            "accuracy: 0.949707\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.413468\n",
            "eval accuracy: 0.891859\n",
            "eval avg class acc: 0.859310\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 111 ****\n",
            "----0-----\n",
            "mean loss: 0.122981\n",
            "accuracy: 0.953125\n",
            "----1-----\n",
            "mean loss: 0.120922\n",
            "accuracy: 0.955078\n",
            "----2-----\n",
            "mean loss: 0.116760\n",
            "accuracy: 0.959473\n",
            "----3-----\n",
            "mean loss: 0.124003\n",
            "accuracy: 0.955566\n",
            "----4-----\n",
            "mean loss: 0.129328\n",
            "accuracy: 0.954102\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.439949\n",
            "eval accuracy: 0.892681\n",
            "eval avg class acc: 0.860135\n",
            "**** EPOCH 112 ****\n",
            "----0-----\n",
            "mean loss: 0.126090\n",
            "accuracy: 0.957520\n",
            "----1-----\n",
            "mean loss: 0.128255\n",
            "accuracy: 0.954590\n",
            "----2-----\n",
            "mean loss: 0.108519\n",
            "accuracy: 0.964844\n",
            "----3-----\n",
            "mean loss: 0.131061\n",
            "accuracy: 0.953125\n",
            "----4-----\n",
            "mean loss: 0.117347\n",
            "accuracy: 0.957682\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.457280\n",
            "eval accuracy: 0.882401\n",
            "eval avg class acc: 0.848394\n",
            "**** EPOCH 113 ****\n",
            "----0-----\n",
            "mean loss: 0.110386\n",
            "accuracy: 0.961914\n",
            "----1-----\n",
            "mean loss: 0.122728\n",
            "accuracy: 0.958008\n",
            "----2-----\n",
            "mean loss: 0.129417\n",
            "accuracy: 0.955078\n",
            "----3-----\n",
            "mean loss: 0.111587\n",
            "accuracy: 0.964844\n",
            "----4-----\n",
            "mean loss: 0.126869\n",
            "accuracy: 0.957520\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.467307\n",
            "eval accuracy: 0.888980\n",
            "eval avg class acc: 0.852076\n",
            "**** EPOCH 114 ****\n",
            "----0-----\n",
            "mean loss: 0.145030\n",
            "accuracy: 0.949219\n",
            "----1-----\n",
            "mean loss: 0.116560\n",
            "accuracy: 0.960449\n",
            "----2-----\n",
            "mean loss: 0.122027\n",
            "accuracy: 0.955078\n",
            "----3-----\n",
            "mean loss: 0.112989\n",
            "accuracy: 0.958984\n",
            "----4-----\n",
            "mean loss: 0.131238\n",
            "accuracy: 0.958984\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.435756\n",
            "eval accuracy: 0.891447\n",
            "eval avg class acc: 0.850895\n",
            "**** EPOCH 115 ****\n",
            "----0-----\n",
            "mean loss: 0.100509\n",
            "accuracy: 0.964355\n",
            "----1-----\n",
            "mean loss: 0.124923\n",
            "accuracy: 0.958984\n",
            "----2-----\n",
            "mean loss: 0.131379\n",
            "accuracy: 0.953125\n",
            "----3-----\n",
            "mean loss: 0.134154\n",
            "accuracy: 0.952148\n",
            "----4-----\n",
            "mean loss: 0.138084\n",
            "accuracy: 0.951660\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.445575\n",
            "eval accuracy: 0.891859\n",
            "eval avg class acc: 0.848914\n",
            "**** EPOCH 116 ****\n",
            "----0-----\n",
            "mean loss: 0.132729\n",
            "accuracy: 0.947754\n",
            "----1-----\n",
            "mean loss: 0.100468\n",
            "accuracy: 0.964844\n",
            "----2-----\n",
            "mean loss: 0.124887\n",
            "accuracy: 0.956543\n",
            "----3-----\n",
            "mean loss: 0.103397\n",
            "accuracy: 0.967773\n",
            "----4-----\n",
            "mean loss: 0.116013\n",
            "accuracy: 0.958984\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.454909\n",
            "eval accuracy: 0.884868\n",
            "eval avg class acc: 0.843021\n",
            "**** EPOCH 117 ****\n",
            "----0-----\n",
            "mean loss: 0.132922\n",
            "accuracy: 0.956543\n",
            "----1-----\n",
            "mean loss: 0.131559\n",
            "accuracy: 0.951823\n",
            "----2-----\n",
            "mean loss: 0.122520\n",
            "accuracy: 0.956543\n",
            "----3-----\n",
            "mean loss: 0.130015\n",
            "accuracy: 0.955078\n",
            "----4-----\n",
            "mean loss: 0.125959\n",
            "accuracy: 0.955566\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.440920\n",
            "eval accuracy: 0.891447\n",
            "eval avg class acc: 0.851096\n",
            "**** EPOCH 118 ****\n",
            "----0-----\n",
            "mean loss: 0.117586\n",
            "accuracy: 0.960449\n",
            "----1-----\n",
            "mean loss: 0.120901\n",
            "accuracy: 0.960449\n",
            "----2-----\n",
            "mean loss: 0.112649\n",
            "accuracy: 0.956543\n",
            "----3-----\n",
            "mean loss: 0.112315\n",
            "accuracy: 0.958984\n",
            "----4-----\n",
            "mean loss: 0.118835\n",
            "accuracy: 0.955078\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.452554\n",
            "eval accuracy: 0.887747\n",
            "eval avg class acc: 0.856685\n",
            "**** EPOCH 119 ****\n",
            "----0-----\n",
            "mean loss: 0.128671\n",
            "accuracy: 0.954427\n",
            "----1-----\n",
            "mean loss: 0.106433\n",
            "accuracy: 0.961426\n",
            "----2-----\n",
            "mean loss: 0.101190\n",
            "accuracy: 0.966797\n",
            "----3-----\n",
            "mean loss: 0.125458\n",
            "accuracy: 0.960449\n",
            "----4-----\n",
            "mean loss: 0.119531\n",
            "accuracy: 0.958496\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.462105\n",
            "eval accuracy: 0.884457\n",
            "eval avg class acc: 0.849603\n",
            "**** EPOCH 120 ****\n",
            "----0-----\n",
            "mean loss: 0.117184\n",
            "accuracy: 0.960449\n",
            "----1-----\n",
            "mean loss: 0.100716\n",
            "accuracy: 0.962891\n",
            "----2-----\n",
            "mean loss: 0.116975\n",
            "accuracy: 0.960938\n",
            "----3-----\n",
            "mean loss: 0.126494\n",
            "accuracy: 0.956055\n",
            "----4-----\n",
            "mean loss: 0.125889\n",
            "accuracy: 0.954102\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.442514\n",
            "eval accuracy: 0.893092\n",
            "eval avg class acc: 0.849353\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 121 ****\n",
            "----0-----\n",
            "mean loss: 0.119965\n",
            "accuracy: 0.958984\n",
            "----1-----\n",
            "mean loss: 0.117149\n",
            "accuracy: 0.960449\n",
            "----2-----\n",
            "mean loss: 0.120532\n",
            "accuracy: 0.958333\n",
            "----3-----\n",
            "mean loss: 0.114448\n",
            "accuracy: 0.961426\n",
            "----4-----\n",
            "mean loss: 0.109560\n",
            "accuracy: 0.959473\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.433263\n",
            "eval accuracy: 0.893092\n",
            "eval avg class acc: 0.852542\n",
            "**** EPOCH 122 ****\n",
            "----0-----\n",
            "mean loss: 0.114044\n",
            "accuracy: 0.960938\n",
            "----1-----\n",
            "mean loss: 0.129864\n",
            "accuracy: 0.956380\n",
            "----2-----\n",
            "mean loss: 0.121445\n",
            "accuracy: 0.959473\n",
            "----3-----\n",
            "mean loss: 0.124405\n",
            "accuracy: 0.957031\n",
            "----4-----\n",
            "mean loss: 0.127562\n",
            "accuracy: 0.951660\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.437807\n",
            "eval accuracy: 0.891036\n",
            "eval avg class acc: 0.851320\n",
            "**** EPOCH 123 ****\n",
            "----0-----\n",
            "mean loss: 0.119182\n",
            "accuracy: 0.960286\n",
            "----1-----\n",
            "mean loss: 0.126660\n",
            "accuracy: 0.957031\n",
            "----2-----\n",
            "mean loss: 0.126201\n",
            "accuracy: 0.958984\n",
            "----3-----\n",
            "mean loss: 0.118322\n",
            "accuracy: 0.958496\n",
            "----4-----\n",
            "mean loss: 0.106862\n",
            "accuracy: 0.962402\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.440380\n",
            "eval accuracy: 0.893092\n",
            "eval avg class acc: 0.856200\n",
            "**** EPOCH 124 ****\n",
            "----0-----\n",
            "mean loss: 0.096468\n",
            "accuracy: 0.967448\n",
            "----1-----\n",
            "mean loss: 0.098822\n",
            "accuracy: 0.961914\n",
            "----2-----\n",
            "mean loss: 0.109723\n",
            "accuracy: 0.963379\n",
            "----3-----\n",
            "mean loss: 0.099940\n",
            "accuracy: 0.961426\n",
            "----4-----\n",
            "mean loss: 0.089031\n",
            "accuracy: 0.971680\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.443168\n",
            "eval accuracy: 0.893092\n",
            "eval avg class acc: 0.849941\n",
            "**** EPOCH 125 ****\n",
            "----0-----\n",
            "mean loss: 0.114768\n",
            "accuracy: 0.959961\n",
            "----1-----\n",
            "mean loss: 0.110459\n",
            "accuracy: 0.965495\n",
            "----2-----\n",
            "mean loss: 0.101244\n",
            "accuracy: 0.964844\n",
            "----3-----\n",
            "mean loss: 0.105141\n",
            "accuracy: 0.965332\n",
            "----4-----\n",
            "mean loss: 0.096323\n",
            "accuracy: 0.963867\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.463821\n",
            "eval accuracy: 0.891859\n",
            "eval avg class acc: 0.851665\n",
            "**** EPOCH 126 ****\n",
            "----0-----\n",
            "mean loss: 0.110452\n",
            "accuracy: 0.961914\n",
            "----1-----\n",
            "mean loss: 0.104995\n",
            "accuracy: 0.961426\n",
            "----2-----\n",
            "mean loss: 0.115141\n",
            "accuracy: 0.960449\n",
            "----3-----\n",
            "mean loss: 0.110395\n",
            "accuracy: 0.962240\n",
            "----4-----\n",
            "mean loss: 0.110788\n",
            "accuracy: 0.966797\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.451829\n",
            "eval accuracy: 0.891859\n",
            "eval avg class acc: 0.859944\n",
            "**** EPOCH 127 ****\n",
            "----0-----\n",
            "mean loss: 0.126271\n",
            "accuracy: 0.958984\n",
            "----1-----\n",
            "mean loss: 0.104075\n",
            "accuracy: 0.962891\n",
            "----2-----\n",
            "mean loss: 0.097134\n",
            "accuracy: 0.964844\n",
            "----3-----\n",
            "mean loss: 0.097583\n",
            "accuracy: 0.964355\n",
            "----4-----\n",
            "mean loss: 0.113191\n",
            "accuracy: 0.960938\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.476960\n",
            "eval accuracy: 0.889803\n",
            "eval avg class acc: 0.861140\n",
            "**** EPOCH 128 ****\n",
            "----0-----\n",
            "mean loss: 0.095769\n",
            "accuracy: 0.963867\n",
            "----1-----\n",
            "mean loss: 0.095880\n",
            "accuracy: 0.963379\n",
            "----2-----\n",
            "mean loss: 0.093803\n",
            "accuracy: 0.963379\n",
            "----3-----\n",
            "mean loss: 0.104252\n",
            "accuracy: 0.964844\n",
            "----4-----\n",
            "mean loss: 0.113747\n",
            "accuracy: 0.958984\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.477998\n",
            "eval accuracy: 0.891859\n",
            "eval avg class acc: 0.855235\n",
            "**** EPOCH 129 ****\n",
            "----0-----\n",
            "mean loss: 0.100196\n",
            "accuracy: 0.967773\n",
            "----1-----\n",
            "mean loss: 0.106527\n",
            "accuracy: 0.962891\n",
            "----2-----\n",
            "mean loss: 0.106033\n",
            "accuracy: 0.965332\n",
            "----3-----\n",
            "mean loss: 0.106349\n",
            "accuracy: 0.960449\n",
            "----4-----\n",
            "mean loss: 0.108875\n",
            "accuracy: 0.961426\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.435983\n",
            "eval accuracy: 0.899260\n",
            "eval avg class acc: 0.862051\n",
            "**** EPOCH 130 ****\n",
            "----0-----\n",
            "mean loss: 0.093928\n",
            "accuracy: 0.967448\n",
            "----1-----\n",
            "mean loss: 0.092088\n",
            "accuracy: 0.968750\n",
            "----2-----\n",
            "mean loss: 0.093591\n",
            "accuracy: 0.969238\n",
            "----3-----\n",
            "mean loss: 0.101818\n",
            "accuracy: 0.967285\n",
            "----4-----\n",
            "mean loss: 0.119488\n",
            "accuracy: 0.959961\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.458837\n",
            "eval accuracy: 0.893914\n",
            "eval avg class acc: 0.858575\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 131 ****\n",
            "----0-----\n",
            "mean loss: 0.100965\n",
            "accuracy: 0.964355\n",
            "----1-----\n",
            "mean loss: 0.106565\n",
            "accuracy: 0.964844\n",
            "----2-----\n",
            "mean loss: 0.102167\n",
            "accuracy: 0.966309\n",
            "----3-----\n",
            "mean loss: 0.103660\n",
            "accuracy: 0.958984\n",
            "----4-----\n",
            "mean loss: 0.110931\n",
            "accuracy: 0.964844\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.448332\n",
            "eval accuracy: 0.896382\n",
            "eval avg class acc: 0.861426\n",
            "**** EPOCH 132 ****\n",
            "----0-----\n",
            "mean loss: 0.103449\n",
            "accuracy: 0.964844\n",
            "----1-----\n",
            "mean loss: 0.097944\n",
            "accuracy: 0.963542\n",
            "----2-----\n",
            "mean loss: 0.107266\n",
            "accuracy: 0.963379\n",
            "----3-----\n",
            "mean loss: 0.096786\n",
            "accuracy: 0.964844\n",
            "----4-----\n",
            "mean loss: 0.098044\n",
            "accuracy: 0.963379\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.446203\n",
            "eval accuracy: 0.895970\n",
            "eval avg class acc: 0.856324\n",
            "**** EPOCH 133 ****\n",
            "----0-----\n",
            "mean loss: 0.101704\n",
            "accuracy: 0.963379\n",
            "----1-----\n",
            "mean loss: 0.102984\n",
            "accuracy: 0.965820\n",
            "----2-----\n",
            "mean loss: 0.110862\n",
            "accuracy: 0.955078\n",
            "----3-----\n",
            "mean loss: 0.109181\n",
            "accuracy: 0.957682\n",
            "----4-----\n",
            "mean loss: 0.113032\n",
            "accuracy: 0.958496\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.432210\n",
            "eval accuracy: 0.898026\n",
            "eval avg class acc: 0.859844\n",
            "**** EPOCH 134 ****\n",
            "----0-----\n",
            "mean loss: 0.109854\n",
            "accuracy: 0.966309\n",
            "----1-----\n",
            "mean loss: 0.095875\n",
            "accuracy: 0.967773\n",
            "----2-----\n",
            "mean loss: 0.115144\n",
            "accuracy: 0.960938\n",
            "----3-----\n",
            "mean loss: 0.108326\n",
            "accuracy: 0.967773\n",
            "----4-----\n",
            "mean loss: 0.112832\n",
            "accuracy: 0.963379\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.468128\n",
            "eval accuracy: 0.897615\n",
            "eval avg class acc: 0.861098\n",
            "**** EPOCH 135 ****\n",
            "----0-----\n",
            "mean loss: 0.097535\n",
            "accuracy: 0.964844\n",
            "----1-----\n",
            "mean loss: 0.105864\n",
            "accuracy: 0.961426\n",
            "----2-----\n",
            "mean loss: 0.107643\n",
            "accuracy: 0.956543\n",
            "----3-----\n",
            "mean loss: 0.102099\n",
            "accuracy: 0.964844\n",
            "----4-----\n",
            "mean loss: 0.096180\n",
            "accuracy: 0.963867\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.465818\n",
            "eval accuracy: 0.887747\n",
            "eval avg class acc: 0.847320\n",
            "**** EPOCH 136 ****\n",
            "----0-----\n",
            "mean loss: 0.108156\n",
            "accuracy: 0.964355\n",
            "----1-----\n",
            "mean loss: 0.091172\n",
            "accuracy: 0.966309\n",
            "----2-----\n",
            "mean loss: 0.108526\n",
            "accuracy: 0.956543\n",
            "----3-----\n",
            "mean loss: 0.106549\n",
            "accuracy: 0.960449\n",
            "----4-----\n",
            "mean loss: 0.113228\n",
            "accuracy: 0.958333\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.469048\n",
            "eval accuracy: 0.891447\n",
            "eval avg class acc: 0.859057\n",
            "**** EPOCH 137 ****\n",
            "----0-----\n",
            "mean loss: 0.087954\n",
            "accuracy: 0.965820\n",
            "----1-----\n",
            "mean loss: 0.079366\n",
            "accuracy: 0.971191\n",
            "----2-----\n",
            "mean loss: 0.102235\n",
            "accuracy: 0.960938\n",
            "----3-----\n",
            "mean loss: 0.113521\n",
            "accuracy: 0.953613\n",
            "----4-----\n",
            "mean loss: 0.108263\n",
            "accuracy: 0.961426\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.443683\n",
            "eval accuracy: 0.895970\n",
            "eval avg class acc: 0.857448\n",
            "**** EPOCH 138 ****\n",
            "----0-----\n",
            "mean loss: 0.093971\n",
            "accuracy: 0.967773\n",
            "----1-----\n",
            "mean loss: 0.107954\n",
            "accuracy: 0.958984\n",
            "----2-----\n",
            "mean loss: 0.094497\n",
            "accuracy: 0.966797\n",
            "----3-----\n",
            "mean loss: 0.101245\n",
            "accuracy: 0.964193\n",
            "----4-----\n",
            "mean loss: 0.109559\n",
            "accuracy: 0.962891\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.450012\n",
            "eval accuracy: 0.895148\n",
            "eval avg class acc: 0.862498\n",
            "**** EPOCH 139 ****\n",
            "----0-----\n",
            "mean loss: 0.086553\n",
            "accuracy: 0.968750\n",
            "----1-----\n",
            "mean loss: 0.082322\n",
            "accuracy: 0.968099\n",
            "----2-----\n",
            "mean loss: 0.108821\n",
            "accuracy: 0.958008\n",
            "----3-----\n",
            "mean loss: 0.100385\n",
            "accuracy: 0.966797\n",
            "----4-----\n",
            "mean loss: 0.090872\n",
            "accuracy: 0.969238\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.463007\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.865320\n",
            "**** EPOCH 140 ****\n",
            "----0-----\n",
            "mean loss: 0.096444\n",
            "accuracy: 0.964844\n",
            "----1-----\n",
            "mean loss: 0.092479\n",
            "accuracy: 0.964844\n",
            "----2-----\n",
            "mean loss: 0.108131\n",
            "accuracy: 0.960938\n",
            "----3-----\n",
            "mean loss: 0.094181\n",
            "accuracy: 0.965820\n",
            "----4-----\n",
            "mean loss: 0.103760\n",
            "accuracy: 0.960938\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.458295\n",
            "eval accuracy: 0.895148\n",
            "eval avg class acc: 0.854262\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 141 ****\n",
            "----0-----\n",
            "mean loss: 0.098316\n",
            "accuracy: 0.970215\n",
            "----1-----\n",
            "mean loss: 0.099454\n",
            "accuracy: 0.968262\n",
            "----2-----\n",
            "mean loss: 0.103262\n",
            "accuracy: 0.963542\n",
            "----3-----\n",
            "mean loss: 0.089915\n",
            "accuracy: 0.967285\n",
            "----4-----\n",
            "mean loss: 0.095964\n",
            "accuracy: 0.964844\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.466219\n",
            "eval accuracy: 0.891859\n",
            "eval avg class acc: 0.854908\n",
            "**** EPOCH 142 ****\n",
            "----0-----\n",
            "mean loss: 0.087724\n",
            "accuracy: 0.970215\n",
            "----1-----\n",
            "mean loss: 0.086779\n",
            "accuracy: 0.967448\n",
            "----2-----\n",
            "mean loss: 0.117729\n",
            "accuracy: 0.959473\n",
            "----3-----\n",
            "mean loss: 0.107182\n",
            "accuracy: 0.961426\n",
            "----4-----\n",
            "mean loss: 0.097657\n",
            "accuracy: 0.962891\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.460295\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.861658\n",
            "**** EPOCH 143 ****\n",
            "----0-----\n",
            "mean loss: 0.091180\n",
            "accuracy: 0.963867\n",
            "----1-----\n",
            "mean loss: 0.095618\n",
            "accuracy: 0.967773\n",
            "----2-----\n",
            "mean loss: 0.088548\n",
            "accuracy: 0.969727\n",
            "----3-----\n",
            "mean loss: 0.099962\n",
            "accuracy: 0.965820\n",
            "----4-----\n",
            "mean loss: 0.088759\n",
            "accuracy: 0.973307\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.458931\n",
            "eval accuracy: 0.892270\n",
            "eval avg class acc: 0.860213\n",
            "**** EPOCH 144 ****\n",
            "----0-----\n",
            "mean loss: 0.088570\n",
            "accuracy: 0.963379\n",
            "----1-----\n",
            "mean loss: 0.070378\n",
            "accuracy: 0.972656\n",
            "----2-----\n",
            "mean loss: 0.096684\n",
            "accuracy: 0.967773\n",
            "----3-----\n",
            "mean loss: 0.094558\n",
            "accuracy: 0.967285\n",
            "----4-----\n",
            "mean loss: 0.097841\n",
            "accuracy: 0.961589\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.461044\n",
            "eval accuracy: 0.893092\n",
            "eval avg class acc: 0.860662\n",
            "**** EPOCH 145 ****\n",
            "----0-----\n",
            "mean loss: 0.091107\n",
            "accuracy: 0.966309\n",
            "----1-----\n",
            "mean loss: 0.101651\n",
            "accuracy: 0.963542\n",
            "----2-----\n",
            "mean loss: 0.081017\n",
            "accuracy: 0.968262\n",
            "----3-----\n",
            "mean loss: 0.095466\n",
            "accuracy: 0.964355\n",
            "----4-----\n",
            "mean loss: 0.090575\n",
            "accuracy: 0.967285\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.463766\n",
            "eval accuracy: 0.893092\n",
            "eval avg class acc: 0.859006\n",
            "**** EPOCH 146 ****\n",
            "----0-----\n",
            "mean loss: 0.084454\n",
            "accuracy: 0.972656\n",
            "----1-----\n",
            "mean loss: 0.086544\n",
            "accuracy: 0.966797\n",
            "----2-----\n",
            "mean loss: 0.090073\n",
            "accuracy: 0.963867\n",
            "----3-----\n",
            "mean loss: 0.089056\n",
            "accuracy: 0.966797\n",
            "----4-----\n",
            "mean loss: 0.077764\n",
            "accuracy: 0.971354\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.458717\n",
            "eval accuracy: 0.897615\n",
            "eval avg class acc: 0.861477\n",
            "**** EPOCH 147 ****\n",
            "----0-----\n",
            "mean loss: 0.081033\n",
            "accuracy: 0.971191\n",
            "----1-----\n",
            "mean loss: 0.083467\n",
            "accuracy: 0.971191\n",
            "----2-----\n",
            "mean loss: 0.085337\n",
            "accuracy: 0.965332\n",
            "----3-----\n",
            "mean loss: 0.089817\n",
            "accuracy: 0.968750\n",
            "----4-----\n",
            "mean loss: 0.098744\n",
            "accuracy: 0.964355\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.486766\n",
            "eval accuracy: 0.890214\n",
            "eval avg class acc: 0.854803\n",
            "**** EPOCH 148 ****\n",
            "----0-----\n",
            "mean loss: 0.075623\n",
            "accuracy: 0.973958\n",
            "----1-----\n",
            "mean loss: 0.103583\n",
            "accuracy: 0.967773\n",
            "----2-----\n",
            "mean loss: 0.080419\n",
            "accuracy: 0.971191\n",
            "----3-----\n",
            "mean loss: 0.080611\n",
            "accuracy: 0.972168\n",
            "----4-----\n",
            "mean loss: 0.092076\n",
            "accuracy: 0.965332\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.484232\n",
            "eval accuracy: 0.895559\n",
            "eval avg class acc: 0.864916\n",
            "**** EPOCH 149 ****\n",
            "----0-----\n",
            "mean loss: 0.085474\n",
            "accuracy: 0.968750\n",
            "----1-----\n",
            "mean loss: 0.093743\n",
            "accuracy: 0.969238\n",
            "----2-----\n",
            "mean loss: 0.084249\n",
            "accuracy: 0.966797\n",
            "----3-----\n",
            "mean loss: 0.088744\n",
            "accuracy: 0.965495\n",
            "----4-----\n",
            "mean loss: 0.083834\n",
            "accuracy: 0.970215\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.476010\n",
            "eval accuracy: 0.893503\n",
            "eval avg class acc: 0.860793\n",
            "**** EPOCH 150 ****\n",
            "----0-----\n",
            "mean loss: 0.084007\n",
            "accuracy: 0.970215\n",
            "----1-----\n",
            "mean loss: 0.098478\n",
            "accuracy: 0.965332\n",
            "----2-----\n",
            "mean loss: 0.098969\n",
            "accuracy: 0.963379\n",
            "----3-----\n",
            "mean loss: 0.071598\n",
            "accuracy: 0.972168\n",
            "----4-----\n",
            "mean loss: 0.081253\n",
            "accuracy: 0.972656\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.473478\n",
            "eval accuracy: 0.892681\n",
            "eval avg class acc: 0.860778\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 151 ****\n",
            "----0-----\n",
            "mean loss: 0.080753\n",
            "accuracy: 0.969238\n",
            "----1-----\n",
            "mean loss: 0.093589\n",
            "accuracy: 0.969401\n",
            "----2-----\n",
            "mean loss: 0.081229\n",
            "accuracy: 0.968750\n",
            "----3-----\n",
            "mean loss: 0.085344\n",
            "accuracy: 0.972168\n",
            "----4-----\n",
            "mean loss: 0.091707\n",
            "accuracy: 0.968262\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.471739\n",
            "eval accuracy: 0.896793\n",
            "eval avg class acc: 0.864549\n",
            "**** EPOCH 152 ****\n",
            "----0-----\n",
            "mean loss: 0.087026\n",
            "accuracy: 0.967285\n",
            "----1-----\n",
            "mean loss: 0.090331\n",
            "accuracy: 0.965820\n",
            "----2-----\n",
            "mean loss: 0.095369\n",
            "accuracy: 0.966309\n",
            "----3-----\n",
            "mean loss: 0.083244\n",
            "accuracy: 0.968750\n",
            "----4-----\n",
            "mean loss: 0.093958\n",
            "accuracy: 0.968099\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.464110\n",
            "eval accuracy: 0.892270\n",
            "eval avg class acc: 0.858712\n",
            "**** EPOCH 153 ****\n",
            "----0-----\n",
            "mean loss: 0.084540\n",
            "accuracy: 0.968750\n",
            "----1-----\n",
            "mean loss: 0.103460\n",
            "accuracy: 0.962891\n",
            "----2-----\n",
            "mean loss: 0.087697\n",
            "accuracy: 0.965332\n",
            "----3-----\n",
            "mean loss: 0.071225\n",
            "accuracy: 0.977051\n",
            "----4-----\n",
            "mean loss: 0.089801\n",
            "accuracy: 0.970703\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.471020\n",
            "eval accuracy: 0.896382\n",
            "eval avg class acc: 0.860475\n",
            "**** EPOCH 154 ****\n",
            "----0-----\n",
            "mean loss: 0.082792\n",
            "accuracy: 0.971680\n",
            "----1-----\n",
            "mean loss: 0.092942\n",
            "accuracy: 0.967773\n",
            "----2-----\n",
            "mean loss: 0.092902\n",
            "accuracy: 0.968262\n",
            "----3-----\n",
            "mean loss: 0.092185\n",
            "accuracy: 0.971354\n",
            "----4-----\n",
            "mean loss: 0.094052\n",
            "accuracy: 0.965820\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.464058\n",
            "eval accuracy: 0.895148\n",
            "eval avg class acc: 0.862702\n",
            "**** EPOCH 155 ****\n",
            "----0-----\n",
            "mean loss: 0.084644\n",
            "accuracy: 0.973633\n",
            "----1-----\n",
            "mean loss: 0.078293\n",
            "accuracy: 0.970703\n",
            "----2-----\n",
            "mean loss: 0.071548\n",
            "accuracy: 0.975098\n",
            "----3-----\n",
            "mean loss: 0.101219\n",
            "accuracy: 0.966309\n",
            "----4-----\n",
            "mean loss: 0.093188\n",
            "accuracy: 0.966309\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.487154\n",
            "eval accuracy: 0.888980\n",
            "eval avg class acc: 0.857756\n",
            "**** EPOCH 156 ****\n",
            "----0-----\n",
            "mean loss: 0.091146\n",
            "accuracy: 0.966309\n",
            "----1-----\n",
            "mean loss: 0.081498\n",
            "accuracy: 0.972168\n",
            "----2-----\n",
            "mean loss: 0.092973\n",
            "accuracy: 0.963867\n",
            "----3-----\n",
            "mean loss: 0.072562\n",
            "accuracy: 0.975098\n",
            "----4-----\n",
            "mean loss: 0.086927\n",
            "accuracy: 0.968750\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.478799\n",
            "eval accuracy: 0.892270\n",
            "eval avg class acc: 0.861622\n",
            "**** EPOCH 157 ****\n",
            "----0-----\n",
            "mean loss: 0.084236\n",
            "accuracy: 0.968262\n",
            "----1-----\n",
            "mean loss: 0.092340\n",
            "accuracy: 0.967773\n",
            "----2-----\n",
            "mean loss: 0.086419\n",
            "accuracy: 0.972168\n",
            "----3-----\n",
            "mean loss: 0.074967\n",
            "accuracy: 0.975911\n",
            "----4-----\n",
            "mean loss: 0.089283\n",
            "accuracy: 0.965332\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.472790\n",
            "eval accuracy: 0.895148\n",
            "eval avg class acc: 0.865545\n",
            "**** EPOCH 158 ****\n",
            "----0-----\n",
            "mean loss: 0.076719\n",
            "accuracy: 0.975586\n",
            "----1-----\n",
            "mean loss: 0.085601\n",
            "accuracy: 0.968262\n",
            "----2-----\n",
            "mean loss: 0.093874\n",
            "accuracy: 0.968099\n",
            "----3-----\n",
            "mean loss: 0.078638\n",
            "accuracy: 0.967285\n",
            "----4-----\n",
            "mean loss: 0.085002\n",
            "accuracy: 0.970215\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.475877\n",
            "eval accuracy: 0.899260\n",
            "eval avg class acc: 0.861545\n",
            "**** EPOCH 159 ****\n",
            "----0-----\n",
            "mean loss: 0.077441\n",
            "accuracy: 0.973145\n",
            "----1-----\n",
            "mean loss: 0.091165\n",
            "accuracy: 0.967285\n",
            "----2-----\n",
            "mean loss: 0.079342\n",
            "accuracy: 0.975098\n",
            "----3-----\n",
            "mean loss: 0.096487\n",
            "accuracy: 0.963542\n",
            "----4-----\n",
            "mean loss: 0.084241\n",
            "accuracy: 0.969727\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.465411\n",
            "eval accuracy: 0.894737\n",
            "eval avg class acc: 0.863011\n",
            "**** EPOCH 160 ****\n",
            "----0-----\n",
            "mean loss: 0.079583\n",
            "accuracy: 0.973307\n",
            "----1-----\n",
            "mean loss: 0.082244\n",
            "accuracy: 0.974609\n",
            "----2-----\n",
            "mean loss: 0.084524\n",
            "accuracy: 0.971191\n",
            "----3-----\n",
            "mean loss: 0.084916\n",
            "accuracy: 0.970215\n",
            "----4-----\n",
            "mean loss: 0.078302\n",
            "accuracy: 0.974121\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.464864\n",
            "eval accuracy: 0.896793\n",
            "eval avg class acc: 0.862253\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 161 ****\n",
            "----0-----\n",
            "mean loss: 0.087028\n",
            "accuracy: 0.968262\n",
            "----1-----\n",
            "mean loss: 0.093521\n",
            "accuracy: 0.968262\n",
            "----2-----\n",
            "mean loss: 0.086411\n",
            "accuracy: 0.968750\n",
            "----3-----\n",
            "mean loss: 0.082570\n",
            "accuracy: 0.969727\n",
            "----4-----\n",
            "mean loss: 0.085974\n",
            "accuracy: 0.970703\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.471082\n",
            "eval accuracy: 0.894737\n",
            "eval avg class acc: 0.863478\n",
            "**** EPOCH 162 ****\n",
            "----0-----\n",
            "mean loss: 0.078551\n",
            "accuracy: 0.970215\n",
            "----1-----\n",
            "mean loss: 0.094513\n",
            "accuracy: 0.964355\n",
            "----2-----\n",
            "mean loss: 0.087512\n",
            "accuracy: 0.972656\n",
            "----3-----\n",
            "mean loss: 0.084947\n",
            "accuracy: 0.970703\n",
            "----4-----\n",
            "mean loss: 0.079365\n",
            "accuracy: 0.968262\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.482718\n",
            "eval accuracy: 0.893914\n",
            "eval avg class acc: 0.860106\n",
            "**** EPOCH 163 ****\n",
            "----0-----\n",
            "mean loss: 0.085473\n",
            "accuracy: 0.975098\n",
            "----1-----\n",
            "mean loss: 0.086571\n",
            "accuracy: 0.967773\n",
            "----2-----\n",
            "mean loss: 0.084594\n",
            "accuracy: 0.967773\n",
            "----3-----\n",
            "mean loss: 0.074701\n",
            "accuracy: 0.972656\n",
            "----4-----\n",
            "mean loss: 0.070320\n",
            "accuracy: 0.979167\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.486405\n",
            "eval accuracy: 0.895148\n",
            "eval avg class acc: 0.859408\n",
            "**** EPOCH 164 ****\n",
            "----0-----\n",
            "mean loss: 0.089237\n",
            "accuracy: 0.969238\n",
            "----1-----\n",
            "mean loss: 0.090513\n",
            "accuracy: 0.966146\n",
            "----2-----\n",
            "mean loss: 0.077372\n",
            "accuracy: 0.969238\n",
            "----3-----\n",
            "mean loss: 0.090214\n",
            "accuracy: 0.968262\n",
            "----4-----\n",
            "mean loss: 0.071780\n",
            "accuracy: 0.972168\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.472371\n",
            "eval accuracy: 0.895559\n",
            "eval avg class acc: 0.863525\n",
            "**** EPOCH 165 ****\n",
            "----0-----\n",
            "mean loss: 0.067728\n",
            "accuracy: 0.973307\n",
            "----1-----\n",
            "mean loss: 0.078181\n",
            "accuracy: 0.970215\n",
            "----2-----\n",
            "mean loss: 0.065939\n",
            "accuracy: 0.978516\n",
            "----3-----\n",
            "mean loss: 0.079964\n",
            "accuracy: 0.973633\n",
            "----4-----\n",
            "mean loss: 0.077282\n",
            "accuracy: 0.970703\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.474467\n",
            "eval accuracy: 0.891036\n",
            "eval avg class acc: 0.860863\n",
            "**** EPOCH 166 ****\n",
            "----0-----\n",
            "mean loss: 0.087892\n",
            "accuracy: 0.969727\n",
            "----1-----\n",
            "mean loss: 0.062995\n",
            "accuracy: 0.977051\n",
            "----2-----\n",
            "mean loss: 0.081859\n",
            "accuracy: 0.972656\n",
            "----3-----\n",
            "mean loss: 0.084923\n",
            "accuracy: 0.967285\n",
            "----4-----\n",
            "mean loss: 0.070273\n",
            "accuracy: 0.975098\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.486279\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.865410\n",
            "**** EPOCH 167 ****\n",
            "----0-----\n",
            "mean loss: 0.081127\n",
            "accuracy: 0.974121\n",
            "----1-----\n",
            "mean loss: 0.077094\n",
            "accuracy: 0.973145\n",
            "----2-----\n",
            "mean loss: 0.080305\n",
            "accuracy: 0.968099\n",
            "----3-----\n",
            "mean loss: 0.070637\n",
            "accuracy: 0.975098\n",
            "----4-----\n",
            "mean loss: 0.076875\n",
            "accuracy: 0.975586\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.478343\n",
            "eval accuracy: 0.895148\n",
            "eval avg class acc: 0.862105\n",
            "**** EPOCH 168 ****\n",
            "----0-----\n",
            "mean loss: 0.070075\n",
            "accuracy: 0.974609\n",
            "----1-----\n",
            "mean loss: 0.072999\n",
            "accuracy: 0.974609\n",
            "----2-----\n",
            "mean loss: 0.087073\n",
            "accuracy: 0.972005\n",
            "----3-----\n",
            "mean loss: 0.082971\n",
            "accuracy: 0.968262\n",
            "----4-----\n",
            "mean loss: 0.059174\n",
            "accuracy: 0.975586\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.485847\n",
            "eval accuracy: 0.896382\n",
            "eval avg class acc: 0.860488\n",
            "**** EPOCH 169 ****\n",
            "----0-----\n",
            "mean loss: 0.088564\n",
            "accuracy: 0.968262\n",
            "----1-----\n",
            "mean loss: 0.072999\n",
            "accuracy: 0.974609\n",
            "----2-----\n",
            "mean loss: 0.079914\n",
            "accuracy: 0.974609\n",
            "----3-----\n",
            "mean loss: 0.072127\n",
            "accuracy: 0.976562\n",
            "----4-----\n",
            "mean loss: 0.084547\n",
            "accuracy: 0.969727\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.485243\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.858524\n",
            "**** EPOCH 170 ****\n",
            "----0-----\n",
            "mean loss: 0.081525\n",
            "accuracy: 0.970703\n",
            "----1-----\n",
            "mean loss: 0.059157\n",
            "accuracy: 0.979167\n",
            "----2-----\n",
            "mean loss: 0.070708\n",
            "accuracy: 0.973633\n",
            "----3-----\n",
            "mean loss: 0.076840\n",
            "accuracy: 0.970215\n",
            "----4-----\n",
            "mean loss: 0.076813\n",
            "accuracy: 0.971191\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.498533\n",
            "eval accuracy: 0.895559\n",
            "eval avg class acc: 0.862007\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 171 ****\n",
            "----0-----\n",
            "mean loss: 0.060694\n",
            "accuracy: 0.977539\n",
            "----1-----\n",
            "mean loss: 0.085651\n",
            "accuracy: 0.966797\n",
            "----2-----\n",
            "mean loss: 0.067920\n",
            "accuracy: 0.977539\n",
            "----3-----\n",
            "mean loss: 0.067563\n",
            "accuracy: 0.973633\n",
            "----4-----\n",
            "mean loss: 0.085007\n",
            "accuracy: 0.970215\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.497616\n",
            "eval accuracy: 0.895559\n",
            "eval avg class acc: 0.867149\n",
            "**** EPOCH 172 ****\n",
            "----0-----\n",
            "mean loss: 0.077344\n",
            "accuracy: 0.974609\n",
            "----1-----\n",
            "mean loss: 0.072785\n",
            "accuracy: 0.975098\n",
            "----2-----\n",
            "mean loss: 0.065920\n",
            "accuracy: 0.978516\n",
            "----3-----\n",
            "mean loss: 0.079261\n",
            "accuracy: 0.972168\n",
            "----4-----\n",
            "mean loss: 0.080561\n",
            "accuracy: 0.973145\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.488634\n",
            "eval accuracy: 0.893503\n",
            "eval avg class acc: 0.861202\n",
            "**** EPOCH 173 ****\n",
            "----0-----\n",
            "mean loss: 0.078374\n",
            "accuracy: 0.971680\n",
            "----1-----\n",
            "mean loss: 0.075464\n",
            "accuracy: 0.973633\n",
            "----2-----\n",
            "mean loss: 0.070912\n",
            "accuracy: 0.975098\n",
            "----3-----\n",
            "mean loss: 0.065522\n",
            "accuracy: 0.977539\n",
            "----4-----\n",
            "mean loss: 0.077770\n",
            "accuracy: 0.966797\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.486063\n",
            "eval accuracy: 0.895970\n",
            "eval avg class acc: 0.861487\n",
            "**** EPOCH 174 ****\n",
            "----0-----\n",
            "mean loss: 0.074700\n",
            "accuracy: 0.975586\n",
            "----1-----\n",
            "mean loss: 0.072234\n",
            "accuracy: 0.972005\n",
            "----2-----\n",
            "mean loss: 0.082921\n",
            "accuracy: 0.970703\n",
            "----3-----\n",
            "mean loss: 0.080514\n",
            "accuracy: 0.970703\n",
            "----4-----\n",
            "mean loss: 0.085772\n",
            "accuracy: 0.966309\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.493729\n",
            "eval accuracy: 0.896382\n",
            "eval avg class acc: 0.862978\n",
            "**** EPOCH 175 ****\n",
            "----0-----\n",
            "mean loss: 0.060885\n",
            "accuracy: 0.977051\n",
            "----1-----\n",
            "mean loss: 0.068746\n",
            "accuracy: 0.974121\n",
            "----2-----\n",
            "mean loss: 0.089562\n",
            "accuracy: 0.972656\n",
            "----3-----\n",
            "mean loss: 0.080613\n",
            "accuracy: 0.972656\n",
            "----4-----\n",
            "mean loss: 0.073562\n",
            "accuracy: 0.977051\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.486925\n",
            "eval accuracy: 0.893914\n",
            "eval avg class acc: 0.859824\n",
            "**** EPOCH 176 ****\n",
            "----0-----\n",
            "mean loss: 0.063572\n",
            "accuracy: 0.975586\n",
            "----1-----\n",
            "mean loss: 0.079160\n",
            "accuracy: 0.971680\n",
            "----2-----\n",
            "mean loss: 0.083714\n",
            "accuracy: 0.971191\n",
            "----3-----\n",
            "mean loss: 0.076148\n",
            "accuracy: 0.972656\n",
            "----4-----\n",
            "mean loss: 0.082761\n",
            "accuracy: 0.969238\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.482648\n",
            "eval accuracy: 0.895970\n",
            "eval avg class acc: 0.866430\n",
            "**** EPOCH 177 ****\n",
            "----0-----\n",
            "mean loss: 0.076404\n",
            "accuracy: 0.967773\n",
            "----1-----\n",
            "mean loss: 0.065952\n",
            "accuracy: 0.976074\n",
            "----2-----\n",
            "mean loss: 0.075586\n",
            "accuracy: 0.974121\n",
            "----3-----\n",
            "mean loss: 0.069611\n",
            "accuracy: 0.973633\n",
            "----4-----\n",
            "mean loss: 0.065593\n",
            "accuracy: 0.973307\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.483000\n",
            "eval accuracy: 0.896793\n",
            "eval avg class acc: 0.863828\n",
            "**** EPOCH 178 ****\n",
            "----0-----\n",
            "mean loss: 0.069818\n",
            "accuracy: 0.972656\n",
            "----1-----\n",
            "mean loss: 0.074806\n",
            "accuracy: 0.972168\n",
            "----2-----\n",
            "mean loss: 0.069950\n",
            "accuracy: 0.975098\n",
            "----3-----\n",
            "mean loss: 0.075997\n",
            "accuracy: 0.969238\n",
            "----4-----\n",
            "mean loss: 0.089324\n",
            "accuracy: 0.966309\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.485280\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.862023\n",
            "**** EPOCH 179 ****\n",
            "----0-----\n",
            "mean loss: 0.072238\n",
            "accuracy: 0.973633\n",
            "----1-----\n",
            "mean loss: 0.084136\n",
            "accuracy: 0.972168\n",
            "----2-----\n",
            "mean loss: 0.087430\n",
            "accuracy: 0.970215\n",
            "----3-----\n",
            "mean loss: 0.079580\n",
            "accuracy: 0.974609\n",
            "----4-----\n",
            "mean loss: 0.076524\n",
            "accuracy: 0.973145\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.498723\n",
            "eval accuracy: 0.893092\n",
            "eval avg class acc: 0.861863\n",
            "**** EPOCH 180 ****\n",
            "----0-----\n",
            "mean loss: 0.069896\n",
            "accuracy: 0.971354\n",
            "----1-----\n",
            "mean loss: 0.082541\n",
            "accuracy: 0.968750\n",
            "----2-----\n",
            "mean loss: 0.074097\n",
            "accuracy: 0.973145\n",
            "----3-----\n",
            "mean loss: 0.065858\n",
            "accuracy: 0.977051\n",
            "----4-----\n",
            "mean loss: 0.052966\n",
            "accuracy: 0.980957\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.491696\n",
            "eval accuracy: 0.894326\n",
            "eval avg class acc: 0.856553\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 181 ****\n",
            "----0-----\n",
            "mean loss: 0.070812\n",
            "accuracy: 0.975098\n",
            "----1-----\n",
            "mean loss: 0.068366\n",
            "accuracy: 0.974609\n",
            "----2-----\n",
            "mean loss: 0.068439\n",
            "accuracy: 0.975260\n",
            "----3-----\n",
            "mean loss: 0.081174\n",
            "accuracy: 0.972656\n",
            "----4-----\n",
            "mean loss: 0.084838\n",
            "accuracy: 0.972168\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.498432\n",
            "eval accuracy: 0.895970\n",
            "eval avg class acc: 0.860245\n",
            "**** EPOCH 182 ****\n",
            "----0-----\n",
            "mean loss: 0.066479\n",
            "accuracy: 0.976074\n",
            "----1-----\n",
            "mean loss: 0.061438\n",
            "accuracy: 0.976562\n",
            "----2-----\n",
            "mean loss: 0.077123\n",
            "accuracy: 0.970052\n",
            "----3-----\n",
            "mean loss: 0.080893\n",
            "accuracy: 0.971191\n",
            "----4-----\n",
            "mean loss: 0.088034\n",
            "accuracy: 0.969727\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.490835\n",
            "eval accuracy: 0.895970\n",
            "eval avg class acc: 0.863962\n",
            "**** EPOCH 183 ****\n",
            "----0-----\n",
            "mean loss: 0.068288\n",
            "accuracy: 0.976562\n",
            "----1-----\n",
            "mean loss: 0.064797\n",
            "accuracy: 0.975098\n",
            "----2-----\n",
            "mean loss: 0.065119\n",
            "accuracy: 0.975911\n",
            "----3-----\n",
            "mean loss: 0.073060\n",
            "accuracy: 0.974609\n",
            "----4-----\n",
            "mean loss: 0.083362\n",
            "accuracy: 0.967285\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.490278\n",
            "eval accuracy: 0.898026\n",
            "eval avg class acc: 0.863948\n",
            "**** EPOCH 184 ****\n",
            "----0-----\n",
            "mean loss: 0.081270\n",
            "accuracy: 0.970703\n",
            "----1-----\n",
            "mean loss: 0.064822\n",
            "accuracy: 0.977539\n",
            "----2-----\n",
            "mean loss: 0.076381\n",
            "accuracy: 0.970703\n",
            "----3-----\n",
            "mean loss: 0.080891\n",
            "accuracy: 0.970703\n",
            "----4-----\n",
            "mean loss: 0.077368\n",
            "accuracy: 0.972005\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.493230\n",
            "eval accuracy: 0.896382\n",
            "eval avg class acc: 0.857861\n",
            "**** EPOCH 185 ****\n",
            "----0-----\n",
            "mean loss: 0.077559\n",
            "accuracy: 0.975911\n",
            "----1-----\n",
            "mean loss: 0.070692\n",
            "accuracy: 0.974121\n",
            "----2-----\n",
            "mean loss: 0.086072\n",
            "accuracy: 0.972656\n",
            "----3-----\n",
            "mean loss: 0.083173\n",
            "accuracy: 0.969238\n",
            "----4-----\n",
            "mean loss: 0.064734\n",
            "accuracy: 0.979004\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.492106\n",
            "eval accuracy: 0.898026\n",
            "eval avg class acc: 0.863515\n",
            "**** EPOCH 186 ****\n",
            "----0-----\n",
            "mean loss: 0.066945\n",
            "accuracy: 0.976562\n",
            "----1-----\n",
            "mean loss: 0.077270\n",
            "accuracy: 0.970703\n",
            "----2-----\n",
            "mean loss: 0.078869\n",
            "accuracy: 0.971680\n",
            "----3-----\n",
            "mean loss: 0.064507\n",
            "accuracy: 0.974609\n",
            "----4-----\n",
            "mean loss: 0.066603\n",
            "accuracy: 0.975586\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.494197\n",
            "eval accuracy: 0.897204\n",
            "eval avg class acc: 0.864009\n",
            "**** EPOCH 187 ****\n",
            "----0-----\n",
            "mean loss: 0.067476\n",
            "accuracy: 0.973307\n",
            "----1-----\n",
            "mean loss: 0.066479\n",
            "accuracy: 0.973633\n",
            "----2-----\n",
            "mean loss: 0.067425\n",
            "accuracy: 0.973633\n",
            "----3-----\n",
            "mean loss: 0.062976\n",
            "accuracy: 0.978516\n",
            "----4-----\n",
            "mean loss: 0.067065\n",
            "accuracy: 0.976074\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.493944\n",
            "eval accuracy: 0.895559\n",
            "eval avg class acc: 0.859616\n",
            "**** EPOCH 188 ****\n",
            "----0-----\n",
            "mean loss: 0.062534\n",
            "accuracy: 0.977051\n",
            "----1-----\n",
            "mean loss: 0.070199\n",
            "accuracy: 0.976562\n",
            "----2-----\n",
            "mean loss: 0.073319\n",
            "accuracy: 0.972168\n",
            "----3-----\n",
            "mean loss: 0.080232\n",
            "accuracy: 0.969727\n",
            "----4-----\n",
            "mean loss: 0.064135\n",
            "accuracy: 0.977865\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.489470\n",
            "eval accuracy: 0.893503\n",
            "eval avg class acc: 0.859249\n",
            "**** EPOCH 189 ****\n",
            "----0-----\n",
            "mean loss: 0.061215\n",
            "accuracy: 0.977051\n",
            "----1-----\n",
            "mean loss: 0.069685\n",
            "accuracy: 0.975260\n",
            "----2-----\n",
            "mean loss: 0.066900\n",
            "accuracy: 0.975586\n",
            "----3-----\n",
            "mean loss: 0.067289\n",
            "accuracy: 0.973633\n",
            "----4-----\n",
            "mean loss: 0.074025\n",
            "accuracy: 0.974121\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.488764\n",
            "eval accuracy: 0.897204\n",
            "eval avg class acc: 0.859628\n",
            "**** EPOCH 190 ****\n",
            "----0-----\n",
            "mean loss: 0.070680\n",
            "accuracy: 0.973958\n",
            "----1-----\n",
            "mean loss: 0.054849\n",
            "accuracy: 0.981934\n",
            "----2-----\n",
            "mean loss: 0.068689\n",
            "accuracy: 0.974609\n",
            "----3-----\n",
            "mean loss: 0.079727\n",
            "accuracy: 0.968262\n",
            "----4-----\n",
            "mean loss: 0.076210\n",
            "accuracy: 0.970703\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.490880\n",
            "eval accuracy: 0.897204\n",
            "eval avg class acc: 0.864581\n",
            "Model saved in file: log/modelnet40/3dmfv_net_cls/grid5_log_trial/8/model.ckpt\n",
            "**** EPOCH 191 ****\n",
            "----0-----\n",
            "mean loss: 0.069987\n",
            "accuracy: 0.974609\n",
            "----1-----\n",
            "mean loss: 0.061942\n",
            "accuracy: 0.974121\n",
            "----2-----\n",
            "mean loss: 0.073677\n",
            "accuracy: 0.976074\n",
            "----3-----\n",
            "mean loss: 0.084757\n",
            "accuracy: 0.972656\n",
            "----4-----\n",
            "mean loss: 0.072562\n",
            "accuracy: 0.973633\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.489852\n",
            "eval accuracy: 0.899671\n",
            "eval avg class acc: 0.866225\n",
            "**** EPOCH 192 ****\n",
            "----0-----\n",
            "mean loss: 0.065882\n",
            "accuracy: 0.974609\n",
            "----1-----\n",
            "mean loss: 0.073479\n",
            "accuracy: 0.974609\n",
            "----2-----\n",
            "mean loss: 0.072486\n",
            "accuracy: 0.977051\n",
            "----3-----\n",
            "mean loss: 0.077265\n",
            "accuracy: 0.972656\n",
            "----4-----\n",
            "mean loss: 0.068565\n",
            "accuracy: 0.975586\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.487994\n",
            "eval accuracy: 0.899671\n",
            "eval avg class acc: 0.865162\n",
            "**** EPOCH 193 ****\n",
            "----0-----\n",
            "mean loss: 0.069327\n",
            "accuracy: 0.974609\n",
            "----1-----\n",
            "mean loss: 0.067264\n",
            "accuracy: 0.970215\n",
            "----2-----\n",
            "mean loss: 0.079497\n",
            "accuracy: 0.972168\n",
            "----3-----\n",
            "mean loss: 0.074381\n",
            "accuracy: 0.974121\n",
            "----4-----\n",
            "mean loss: 0.066804\n",
            "accuracy: 0.973145\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.492546\n",
            "eval accuracy: 0.898438\n",
            "eval avg class acc: 0.867780\n",
            "**** EPOCH 194 ****\n",
            "----0-----\n",
            "mean loss: 0.063521\n",
            "accuracy: 0.976074\n",
            "----1-----\n",
            "mean loss: 0.074271\n",
            "accuracy: 0.970703\n",
            "----2-----\n",
            "mean loss: 0.060138\n",
            "accuracy: 0.975586\n",
            "----3-----\n",
            "mean loss: 0.074879\n",
            "accuracy: 0.972656\n",
            "----4-----\n",
            "mean loss: 0.072894\n",
            "accuracy: 0.974609\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.493085\n",
            "eval accuracy: 0.895970\n",
            "eval avg class acc: 0.864996\n",
            "**** EPOCH 195 ****\n",
            "----0-----\n",
            "mean loss: 0.059163\n",
            "accuracy: 0.977539\n",
            "----1-----\n",
            "mean loss: 0.058525\n",
            "accuracy: 0.980469\n",
            "----2-----\n",
            "mean loss: 0.071920\n",
            "accuracy: 0.973307\n",
            "----3-----\n",
            "mean loss: 0.067322\n",
            "accuracy: 0.974121\n",
            "----4-----\n",
            "mean loss: 0.085693\n",
            "accuracy: 0.970215\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.490172\n",
            "eval accuracy: 0.898438\n",
            "eval avg class acc: 0.870004\n",
            "**** EPOCH 196 ****\n",
            "----0-----\n",
            "mean loss: 0.064882\n",
            "accuracy: 0.976074\n",
            "----1-----\n",
            "mean loss: 0.085275\n",
            "accuracy: 0.973145\n",
            "----2-----\n",
            "mean loss: 0.075934\n",
            "accuracy: 0.973958\n",
            "----3-----\n",
            "mean loss: 0.065957\n",
            "accuracy: 0.975098\n",
            "----4-----\n",
            "mean loss: 0.063821\n",
            "accuracy: 0.976074\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.488370\n",
            "eval accuracy: 0.896382\n",
            "eval avg class acc: 0.865931\n",
            "**** EPOCH 197 ****\n",
            "----0-----\n",
            "mean loss: 0.080871\n",
            "accuracy: 0.970215\n",
            "----1-----\n",
            "mean loss: 0.072563\n",
            "accuracy: 0.973145\n",
            "----2-----\n",
            "mean loss: 0.058491\n",
            "accuracy: 0.977051\n",
            "----3-----\n",
            "mean loss: 0.070495\n",
            "accuracy: 0.974609\n",
            "----4-----\n",
            "mean loss: 0.071024\n",
            "accuracy: 0.974609\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.487978\n",
            "eval accuracy: 0.895970\n",
            "eval avg class acc: 0.862279\n",
            "**** EPOCH 198 ****\n",
            "----0-----\n",
            "mean loss: 0.064630\n",
            "accuracy: 0.976074\n",
            "----1-----\n",
            "mean loss: 0.056770\n",
            "accuracy: 0.978516\n",
            "----2-----\n",
            "mean loss: 0.060999\n",
            "accuracy: 0.978516\n",
            "----3-----\n",
            "mean loss: 0.077134\n",
            "accuracy: 0.972005\n",
            "----4-----\n",
            "mean loss: 0.066490\n",
            "accuracy: 0.972656\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.490580\n",
            "eval accuracy: 0.897204\n",
            "eval avg class acc: 0.870231\n",
            "**** EPOCH 199 ****\n",
            "----0-----\n",
            "mean loss: 0.059720\n",
            "accuracy: 0.979980\n",
            "----1-----\n",
            "mean loss: 0.069769\n",
            "accuracy: 0.970703\n",
            "----2-----\n",
            "mean loss: 0.071536\n",
            "accuracy: 0.974609\n",
            "----3-----\n",
            "mean loss: 0.066452\n",
            "accuracy: 0.974609\n",
            "----4-----\n",
            "mean loss: 0.078969\n",
            "accuracy: 0.971191\n",
            "----0-----\n",
            "----1-----\n",
            "eval mean loss: 0.496893\n",
            "eval accuracy: 0.896382\n",
            "eval avg class acc: 0.867523\n",
            "Best test accuracy: 0.900082\n",
            "Best test class accuracy: 0.857521\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}